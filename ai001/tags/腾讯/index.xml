<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>腾讯 on 知识铺的博客</title>
    <link>https://index.zshipu.com/ai001/tags/%E8%85%BE%E8%AE%AF/</link>
    <description>Recent content in 腾讯 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 10 Oct 2025 05:38:08 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/ai001/tags/%E8%85%BE%E8%AE%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>腾讯发布1.58Bit大模型量化新算法Tequila！突破死区陷阱，效果性能刷新SOTA --知识铺</title>
      <link>https://index.zshipu.com/ai001/post/20251010/%E8%85%BE%E8%AE%AF%E5%8F%91%E5%B8%831.58Bit%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%E6%96%B0%E7%AE%97%E6%B3%95Tequila%E7%AA%81%E7%A0%B4%E6%AD%BB%E5%8C%BA%E9%99%B7%E9%98%B1%E6%95%88%E6%9E%9C%E6%80%A7%E8%83%BD%E5%88%B7%E6%96%B0SOTA/</link>
      <pubDate>Fri, 10 Oct 2025 05:38:08 +0000</pubDate>
      <guid>https://index.zshipu.com/ai001/post/20251010/%E8%85%BE%E8%AE%AF%E5%8F%91%E5%B8%831.58Bit%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%E6%96%B0%E7%AE%97%E6%B3%95Tequila%E7%AA%81%E7%A0%B4%E6%AD%BB%E5%8C%BA%E9%99%B7%E9%98%B1%E6%95%88%E6%9E%9C%E6%80%A7%E8%83%BD%E5%88%B7%E6%96%B0SOTA/</guid>
      <description>针对大语言模型(LLM)的量化方法层出不穷，近期三值量化（1.58Bit）在LLM中使用的越来越广，比如BitNet等方法。腾讯近期发布了1.58Bit量化的新算法 Tequila，提出一种QAT阶段解决“死区陷阱”的新算法，性能效果达到新SOTA。模型使用 1.58Bit 的位宽达到的性能，能对</description>
    </item>
  </channel>
</rss>
