<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>模型推理 on 知识铺的博客</title>
    <link>https://index.zshipu.com/ai/tags/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/</link>
    <description>Recent content in 模型推理 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 05 Oct 2025 14:38:42 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/ai/tags/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>可能是目前效果最好的开源生图模型，混元生图3.0来了 - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E5%8F%AF%E8%83%BD%E6%98%AF%E7%9B%AE%E5%89%8D%E6%95%88%E6%9E%9C%E6%9C%80%E5%A5%BD%E7%9A%84%E5%BC%80%E6%BA%90%E7%94%9F%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%85%83%E7%94%9F%E5%9B%BE3.0%E6%9D%A5%E4%BA%86/</link>
      <pubDate>Sun, 05 Oct 2025 14:38:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E5%8F%AF%E8%83%BD%E6%98%AF%E7%9B%AE%E5%89%8D%E6%95%88%E6%9E%9C%E6%9C%80%E5%A5%BD%E7%9A%84%E5%BC%80%E6%BA%90%E7%94%9F%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%85%83%E7%94%9F%E5%9B%BE3.0%E6%9D%A5%E4%BA%86/</guid>
      <description>允中 发自 凹非寺 量子位 | 公众号 QbitAI 腾讯混元最新发布并开源原生多模态生图模型——混元图像3.0（HunyuanImage 3.0）！ 模型参数规模高达80B，是目前参数量最大的开源生图模型。 同时，HunyuanImage 3.0将理解与生成一体化融合，也是首个开源工业级原生多模态生图模型，效</description>
    </item>
    <item>
      <title>全球用户盲选！混元生图3.0登顶榜一 - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E5%85%A8%E7%90%83%E7%94%A8%E6%88%B7%E7%9B%B2%E9%80%89%E6%B7%B7%E5%85%83%E7%94%9F%E5%9B%BE3.0%E7%99%BB%E9%A1%B6%E6%A6%9C%E4%B8%80/</link>
      <pubDate>Sun, 05 Oct 2025 14:32:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E5%85%A8%E7%90%83%E7%94%A8%E6%88%B7%E7%9B%B2%E9%80%89%E6%B7%B7%E5%85%83%E7%94%9F%E5%9B%BE3.0%E7%99%BB%E9%A1%B6%E6%A6%9C%E4%B8%80/</guid>
      <description>假期和大家分享个好消息！ 刚刚，文生图领域的“权威竞技场” LMArena放榜 —— 发布仅一周的混元图像3.0，从全球26个大模型里突围，登顶第一。实打实赢过了 Nano Banana等可敬的对手。 这个排名没有任何“算法滤镜”，靠的是全球用户们两两对比投票选出，每一票都藏着用户的真实体验和偏好。</description>
    </item>
    <item>
      <title>实测开源版 nano banana：更聪明的超长文本渲染，彻底告别 AI 汉字鬼画符 - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E5%AE%9E%E6%B5%8B%E5%BC%80%E6%BA%90%E7%89%88-nano-banana%E6%9B%B4%E8%81%AA%E6%98%8E%E7%9A%84%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC%E6%B8%B2%E6%9F%93%E5%BD%BB%E5%BA%95%E5%91%8A%E5%88%AB-AI-%E6%B1%89%E5%AD%97%E9%AC%BC%E7%94%BB%E7%AC%A6/</link>
      <pubDate>Sun, 05 Oct 2025 14:29:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E5%AE%9E%E6%B5%8B%E5%BC%80%E6%BA%90%E7%89%88-nano-banana%E6%9B%B4%E8%81%AA%E6%98%8E%E7%9A%84%E8%B6%85%E9%95%BF%E6%96%87%E6%9C%AC%E6%B8%B2%E6%9F%93%E5%BD%BB%E5%BA%95%E5%91%8A%E5%88%AB-AI-%E6%B1%89%E5%AD%97%E9%AC%BC%E7%94%BB%E7%AC%A6/</guid>
      <description>最近腾讯开源了一个新模型——混元图像 3.0。 它的宣传点很直白：不仅能画图，还能准确「理解」，和利用世界知识「推理」。比如我们想做一张广告海报，它能把商品画出来，还顺手把文字排版好；想做一套漫画，输入一句话，它就能帮我们画好分镜。 听起来是很强，但也让人好奇，它真能替代设计师吗？还是</description>
    </item>
    <item>
      <title>重磅！混元图像 3.0 开源，是首个开源的工业级原生多模态生图模型。 - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E9%87%8D%E7%A3%85%E6%B7%B7%E5%85%83%E5%9B%BE%E5%83%8F-3.0-%E5%BC%80%E6%BA%90%E6%98%AF%E9%A6%96%E4%B8%AA%E5%BC%80%E6%BA%90%E7%9A%84%E5%B7%A5%E4%B8%9A%E7%BA%A7%E5%8E%9F%E7%94%9F%E5%A4%9A%E6%A8%A1%E6%80%81%E7%94%9F%E5%9B%BE%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 05 Oct 2025 14:26:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E9%87%8D%E7%A3%85%E6%B7%B7%E5%85%83%E5%9B%BE%E5%83%8F-3.0-%E5%BC%80%E6%BA%90%E6%98%AF%E9%A6%96%E4%B8%AA%E5%BC%80%E6%BA%90%E7%9A%84%E5%B7%A5%E4%B8%9A%E7%BA%A7%E5%8E%9F%E7%94%9F%E5%A4%9A%E6%A8%A1%E6%80%81%E7%94%9F%E5%9B%BE%E6%A8%A1%E5%9E%8B/</guid>
      <description>这意味着模型自身就具备了世界知识和推理能力，感觉特别适合绘制一些小科普的插图（当然还是需要专家校对） ▶ 混元官网：https://hunyuan.tencent.com/image ▶ Huggin Face：https://huggingface.co/tencent/HunyuanImage-</description>
    </item>
    <item>
      <title>推理网博客  渗透结构 0 6b --- Inference.net Blog  Osmosis Structure 0 6b - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E6%B8%97%E9%80%8F%E7%BB%93%E6%9E%84-0-6b---Inference.net-Blog-Osmosis-Structure-0-6b/</link>
      <pubDate>Sun, 05 Oct 2025 14:24:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E6%B8%97%E9%80%8F%E7%BB%93%E6%9E%84-0-6b---Inference.net-Blog-Osmosis-Structure-0-6b/</guid>
      <description>昨天，Osmosis AI 发布了一项特别的内容：一个拥有 6 亿参数的模型，它解决了生产 AI 中最令人沮丧的问题之一——结构化输出会削弱你的智能模型。 如果你曾经尝试过强制 GPT-4 或 Claude 输出 JSON，你就知道有多痛苦。你的准确率会大幅下降。当你强制 GPT-4.1 输出结构化输出时，它在 AIME 数学问题上的准确率仅为 2.7</description>
    </item>
    <item>
      <title>推理网博客  异步请求：降低 LLM 成本的缺失模式 --- Inference.net Blog  Asynchronous Requests The Missing Mode That Slashes Llm Costs - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82%E9%99%8D%E4%BD%8E-LLM-%E6%88%90%E6%9C%AC%E7%9A%84%E7%BC%BA%E5%A4%B1%E6%A8%A1%E5%BC%8F---Inference.net-Blog-Asynchronous-Requests-The-Missing-Mode-That-Slashes-Llm-Costs/</link>
      <pubDate>Sun, 05 Oct 2025 14:23:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82%E9%99%8D%E4%BD%8E-LLM-%E6%88%90%E6%9C%AC%E7%9A%84%E7%BC%BA%E5%A4%B1%E6%A8%A1%E5%BC%8F---Inference.net-Blog-Asynchronous-Requests-The-Missing-Mode-That-Slashes-Llm-Costs/</guid>
      <description>大多数团队将 LLM 调用视为要么是同步的 （现在给我答案）要么是批量的 （今晚运行整个数据集）。然而，对于某些工作负载来说，批量推理并不适用，这就是我们为什么要引入一种新的 LLM 请求类型：一个_异步的_请求。 异步请求 – 一旦空闲 GPU 可用，就会完成。 以下是关于为什么这很重要以及如何今天使用 Inference.net 来实现它</description>
    </item>
    <item>
      <title>推理网博客  你需要模型蒸馏吗 --- Inference.net Blog  Do You Need Model Distillation - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%90%97---Inference.net-Blog-Do-You-Need-Model-Distillation/</link>
      <pubDate>Sun, 05 Oct 2025 14:22:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F%E5%90%97---Inference.net-Blog-Do-You-Need-Model-Distillation/</guid>
      <description>引言 模型蒸馏，也称为知识蒸馏，是一种机器学习技术，它将知识从一个大型的复杂模型（“教师”模型）转移到一个小型、更高效的模型（“学生”模型）。它已成为优化 AI 模型的关键技术，尤其是在计算资源、速度或成本成为限制因素时。大型模型，如大型语言模型（LLMs）或视觉语言模型（VLMs），在</description>
    </item>
    <item>
      <title>Inference.net 博客  批量与实时 LLM API 何时使用 --- Inference.net Blog  Batch Vs Real Time Llm Apis When To Use Each - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2-%E6%89%B9%E9%87%8F%E4%B8%8E%E5%AE%9E%E6%97%B6-LLM-API-%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8---Inference.net-Blog-Batch-Vs-Real-Time-Llm-Apis-When-To-Use-Each/</link>
      <pubDate>Sun, 05 Oct 2025 14:21:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2-%E6%89%B9%E9%87%8F%E4%B8%8E%E5%AE%9E%E6%97%B6-LLM-API-%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8---Inference.net-Blog-Batch-Vs-Real-Time-Llm-Apis-When-To-Use-Each/</guid>
      <description>并非每个 LLM 请求都需要立即响应。聊天界面需要实时响应。但数据提取、丰富化和后台工作可以等待数小时。这种时间灵活性可以解锁巨大的成本节省，尽管简单的实现会创造可靠性噩梦。 这种模式非常常见。一个团队需要处理数十万份文档，所以他们编写了一个循环，等待每个响应。然后脚本在请求 1000 次时失败，他</description>
    </item>
    <item>
      <title>推理网博客  开源模型经济学 --- Inference.net Blog  Open Source Model Economics - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B%E7%BB%8F%E6%B5%8E%E5%AD%A6---Inference.net-Blog-Open-Source-Model-Economics/</link>
      <pubDate>Sun, 05 Oct 2025 14:20:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E6%8E%A8%E7%90%86%E7%BD%91%E5%8D%9A%E5%AE%A2-%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B%E7%BB%8F%E6%B5%8E%E5%AD%A6---Inference.net-Blog-Open-Source-Model-Economics/</guid>
      <description>阿里巴巴研究团队最近发布了 Wan 2.2，这是其著名 Wan 系列的继任者。截至 2025 年 7 月，它是可用的最佳视频生成模型之一，与海浪最小-最大 2.0、Seedance 1.0 Pro 和 Kling 2.1 Master 等巨头一同进入了一个竞争激烈的领域。虽然它在顶级 Veo 3 之下，但该模型在价格昂贵和缺乏开放式的图像到视频生成方面也存在问题。</description>
    </item>
    <item>
      <title>Inference.net 博客  剩下的就是蒸馏 --- Inference.net Blog  What S Left Is Distillation - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2-%E5%89%A9%E4%B8%8B%E7%9A%84%E5%B0%B1%E6%98%AF%E8%92%B8%E9%A6%8F---Inference.net-Blog-What-S-Left-Is-Distillation/</link>
      <pubDate>Sun, 05 Oct 2025 14:19:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2-%E5%89%A9%E4%B8%8B%E7%9A%84%E5%B0%B1%E6%98%AF%E8%92%B8%E9%A6%8F---Inference.net-Blog-What-S-Left-Is-Distillation/</guid>
      <description>坊间传闻，OpenAI 现在仅在 LLM 训练上就花费了超过 5000 万美元。在没有国家规模资源的情况下，试图在超级智能领域竞争几乎是徒劳的。尽管如此，大规模的训练运行和强大但昂贵的模型意味着另一种技术开始占据主导地位：蒸馏。 2024 年是浪费 AI 企业支出的年份。财富 500 强公司会花费数千万美元，并自豪地宣布他</description>
    </item>
    <item>
      <title>Inference.net 博客Cliptagger 12b --- Inference.net Blog  Cliptagger 12b - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2Cliptagger-12b---Inference.net-Blog-Cliptagger-12b/</link>
      <pubDate>Sun, 05 Oct 2025 14:18:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2Cliptagger-12b---Inference.net-Blog-Cliptagger-12b/</guid>
      <description>引言 今天，我们激动地推出 ClipTagger-12B：一个 12B 参数的强大 VLM，在视频帧标题生成方面击败了 Claude 4 Sonnet，同时成本仅为 17 倍。 Inference.net 和 Grass 合作开发了这个开源模型，代表了人工智能的新类别：专为互联网规模的生产工作负载构建的劳模模型。 问题：视频理解成本过高 每天，数十亿个视频帧</description>
    </item>
    <item>
      <title>Inference.net 博客将 LLM 推理成本降低到电费水平 --- Inference.net Blog  Arbitraging Down Llm Inference To The Cost Of Electricity - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2%E5%B0%86-LLM-%E6%8E%A8%E7%90%86%E6%88%90%E6%9C%AC%E9%99%8D%E4%BD%8E%E5%88%B0%E7%94%B5%E8%B4%B9%E6%B0%B4%E5%B9%B3---Inference.net-Blog-Arbitraging-Down-Llm-Inference-To-The-Cost-Of-Electricity/</link>
      <pubDate>Sun, 05 Oct 2025 14:17:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/Inference.net-%E5%8D%9A%E5%AE%A2%E5%B0%86-LLM-%E6%8E%A8%E7%90%86%E6%88%90%E6%9C%AC%E9%99%8D%E4%BD%8E%E5%88%B0%E7%94%B5%E8%B4%B9%E6%B0%B4%E5%B9%B3---Inference.net-Blog-Arbitraging-Down-Llm-Inference-To-The-Cost-Of-Electricity/</guid>
      <description>无服务器 LLM 推理市场已经爆发，数十家提供商提供各种价格、延迟、可靠性和浮点精度级别的专有和开源模型。虽然选择理想的提供商和 LLM 并不简单，但大多数提供商提供与 OpenAI 兼容的端点，使集成变得简单。这种标准化使得成本成为无服务器开源模型推理的主要差异化因素。随着新的开源模型每周都取得最先进的性能</description>
    </item>
    <item>
      <title>推理网博客  智能体搜索 --- Inference.net Blog  Agentic Search - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/RAG-%E5%B7%B2%E8%BF%87%E6%97%B6RL-%E6%99%BA%E8%83%BD%E4%BD%93%E6%88%90%E4%B8%BA%E6%96%B0%E7%9A%84%E6%A3%80%E7%B4%A2%E5%A0%86%E6%A0%88/</link>
      <pubDate>Sun, 05 Oct 2025 14:16:42 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/RAG-%E5%B7%B2%E8%BF%87%E6%97%B6RL-%E6%99%BA%E8%83%BD%E4%BD%93%E6%88%90%E4%B8%BA%E6%96%B0%E7%9A%84%E6%A3%80%E7%B4%A2%E5%A0%86%E6%A0%88/</guid>
      <description>RAG 已经触及了天花板，而 RL 训练的智能体刚刚超越了它。 一段时间内，我们只需通过更好的嵌入和重新排序器就能持续改进检索。当时的最佳实践相对简单：通常你会进行稀疏搜索（BM25/SPLADE），密集嵌入搜索，然后使用 RRF（互逆排名融合） 或交叉编码器进行重新排序。这已经足够将搜索质量提升</description>
    </item>
    <item>
      <title>AI 代理的有效上下文工程  Killer Code - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/AI-%E4%BB%A3%E7%90%86%E7%9A%84%E6%9C%89%E6%95%88%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 05 Oct 2025 14:05:19 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/AI-%E4%BB%A3%E7%90%86%E7%9A%84%E6%9C%89%E6%95%88%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>AI 代理的有效上下文工程 在应用 AI 领域关注提示工程几年后，一个新术语开始崭露头角：上下文工程。使用语言模型构建应用的重点正在从寻找正确的词语和短语转向回答更广泛的问题：&amp;ldquo;什么样的上下文配置最有可能产生我们期望的模型行为？&amp;rdquo; 上下文指的是在对大语言模型（LLM）进</description>
    </item>
    <item>
      <title>Andrej Karpathy 谈 LLM 辅助编程的演进：哲学与实践的融合  Killer Code - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/Andrej-Karpathy-%E8%B0%88-LLM-%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%9A%84%E6%BC%94%E8%BF%9B%E5%93%B2%E5%AD%A6%E4%B8%8E%E5%AE%9E%E8%B7%B5%E7%9A%84%E8%9E%8D%E5%90%88-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 05 Oct 2025 14:04:19 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/Andrej-Karpathy-%E8%B0%88-LLM-%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%9A%84%E6%BC%94%E8%BF%9B%E5%93%B2%E5%AD%A6%E4%B8%8E%E5%AE%9E%E8%B7%B5%E7%9A%84%E8%9E%8D%E5%90%88-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>Andrej Karpathy 谈 LLM 辅助编程的演进：哲学与实践的融合 AI 传奇人物 Andrej Karpathy 对多层次 LLM 编程工作流的深度洞察，结合实用的 Claude Code 技巧和策略，探索最佳 AI 辅助开发方案。 Andrej Karpathy 谈 LLM 辅助编程的演进：哲学与实践的融合 &amp;ldquo;编程感觉完全被可能性所开启，涵盖了多种&amp;rsquo;编程类型&amp;rsquo;，然后是各种工具</description>
    </item>
    <item>
      <title>一个半月高强度 Claude Code 使用后感受  Killer Code - 知识铺</title>
      <link>https://index.zshipu.com/ai/post/202510/%E4%B8%80%E4%B8%AA%E5%8D%8A%E6%9C%88%E9%AB%98%E5%BC%BA%E5%BA%A6-Claude-Code-%E4%BD%BF%E7%94%A8%E5%90%8E%E6%84%9F%E5%8F%97-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 05 Oct 2025 13:59:19 +0000</pubDate>
      <guid>https://index.zshipu.com/ai/post/202510/%E4%B8%80%E4%B8%AA%E5%8D%8A%E6%9C%88%E9%AB%98%E5%BC%BA%E5%BA%A6-Claude-Code-%E4%BD%BF%E7%94%A8%E5%90%8E%E6%84%9F%E5%8F%97-Killer-Code--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>六月中旬某个闷热的夜晚，在初浅尝试使用 API Key 帮我迅速完成了一个任务后，我毫不犹豫地点下了 Claude Max 的订阅按钮。作为一个&amp;quot;买断制&amp;quot;时代的遗老，每月一两百美金的订阅对当时的我来说还是太超前了。但是在一个半月之后回头望去，看着那些按照 API 计价的被我烧掉的价值 3000 多美金的 toke</description>
    </item>
  </channel>
</rss>
