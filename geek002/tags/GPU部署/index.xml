<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPU部署 on 知识铺的博客</title>
    <link>https://index.zshipu.com/geek002/tags/GPU%E9%83%A8%E7%BD%B2/</link>
    <description>Recent content in GPU部署 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 11 Nov 2024 06:02:51 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/geek002/tags/GPU%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dify与Xinference GPU环境部署全流程 -- 知识铺</title>
      <link>https://index.zshipu.com/geek002/post/202411/Dify%E4%B8%8EXinference-GPU%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E5%85%A8%E6%B5%81%E7%A8%8B--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Mon, 11 Nov 2024 06:02:51 +0000</pubDate>
      <guid>https://index.zshipu.com/geek002/post/202411/Dify%E4%B8%8EXinference-GPU%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E5%85%A8%E6%B5%81%E7%A8%8B--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>在本地 GPU 上部署 Dify 服务 在之前的文章《RAG 项目对比》中，我们探讨了多个RAG框架，并最终确定Dify作为最适合的选项。接下来，本文将详细介绍如何在本地GPU设备上部署Dify服务。 选择模型加载框架 Dify的设计理念之一是将模型的加载过程独立出来，这意味着我们需要选择一个合适的模型加</description>
    </item>
  </channel>
</rss>
