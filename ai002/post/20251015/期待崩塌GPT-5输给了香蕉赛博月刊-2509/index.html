<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>期待崩塌：GPT-5，输给了香蕉｜赛博月刊 2509 --知识铺 | 知识铺的博客</title>
    <meta property="og:title" content="期待崩塌：GPT-5，输给了香蕉｜赛博月刊 2509 --知识铺 - 知识铺的博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2025-10-15T14:29:17&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2025-10-15T14:29:17&#43;08:00'>
        
    <meta name="Keywords" content="golang,go语言,go语言笔记,知识铺,java,android,博客,项目管理,python,软件架构,公众号,小程序">
    <meta name="description" content="期待崩塌：GPT-5，输给了香蕉｜赛博月刊 2509 --知识铺">
        
    <meta name="author" content="知识铺">
    <meta property="og:url" content="https://index.zshipu.com/ai002/post/20251015/%E6%9C%9F%E5%BE%85%E5%B4%A9%E5%A1%8CGPT-5%E8%BE%93%E7%BB%99%E4%BA%86%E9%A6%99%E8%95%89%E8%B5%9B%E5%8D%9A%E6%9C%88%E5%88%8A-2509/">
    <link rel="shortcut icon" href='/ai002/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/ai002/css/normalize.css'>
    <link rel="stylesheet" href='/ai002/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    <script data-ad-client="ca-pub-2874221941555456" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    
    
    
    
    
    
    
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WLWJSST');</script>
    
</head>


<body>

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WLWJSST"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://index.zshipu.com/ai002/">
                        知识铺的博客
                    </a>
                
                <p class="description">专注于Android、Java、Go语言(golang)、移动互联网、项目管理、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://index.zshipu.com/ai002/">首页</a>
                    
                    <a  href="https://index.zshipu.com/ai001/" title="AI技术">AI技术</a>
                    
                    <a  href="https://index.zshipu.com" title="总站">总站</a>
                    
                    <a  href="https://index.zshipu.com/ai002/archives/" title="归档">归档</a>
                    
                    <a  href="https://index.zshipu.com/ai002/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#genspark">Genspark</a>
      <ul>
        <li><a href="#multi-agent-orchestration-多智能体编排实现跨应用协同">Multi-Agent Orchestration 多智能体编排，实现跨应用协同</a></li>
      </ul>
    </li>
    <li><a href="#360">360</a>
      <ul>
        <li><a href="#纳米-ai-多智能体蜂群系统l4-级智能体协同平台">纳米 AI 多智能体蜂群系统，L4 级智能体协同平台</a></li>
      </ul>
    </li>
    <li><a href="#adobe">Adobe</a>
      <ul>
        <li><a href="#photoshop-多项-ai-功能更新实现更智能高效的创意编辑">Photoshop 多项 AI 功能更新，实现更智能高效的创意编辑</a></li>
      </ul>
    </li>
    <li><a href="#fal">fal</a>
      <ul>
        <li><a href="#完成-125-亿美元-c-轮融资">完成 1.25 亿美元 C 轮融资</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#腾讯">腾讯</a>
      <ul>
        <li><a href="#hunyuan-小尺寸融合推理模型051847b-多版本消费级显卡可以运行开源">Hunyuan 小尺寸融合推理模型，0.5/1.8/4/7B 多版本，消费级显卡可以运行（开源）</a></li>
      </ul>
    </li>
    <li><a href="#小米">小米</a>
      <ul>
        <li><a href="#midashenglm-7b-声音理解大模型统一理解语音环境声与音乐开源">MiDashengLM-7B 声音理解大模型，统一理解语音、环境声与音乐（开源）</a></li>
      </ul>
    </li>
    <li><a href="#金山办公">金山办公</a>
      <ul>
        <li><a href="#wps-灵犀原生-office-办公智能体用对话重塑生产力">WPS 灵犀，原生 Office 办公智能体，用对话重塑生产力</a></li>
      </ul>
    </li>
    <li><a href="#阿里巴巴">阿里巴巴</a>
      <ul>
        <li><a href="#高德地图-2025全球首个基于地图的-ai-native-应用">高德地图 2025，全球首个基于地图的 AI Native 应用</a></li>
      </ul>
    </li>
    <li><a href="#characterai">Character.AI</a>
      <ul>
        <li><a href="#feed全球首个-ai-native-社交信息流丰富-ai-娱乐的互动性和创造性">Feed，全球首个 AI Native 社交信息流，丰富 AI 娱乐的互动性和创造性</a></li>
      </ul>
    </li>
    <li><a href="#perplexityxopentable">Perplexity X OpenTable</a>
      <ul>
        <li><a href="#餐厅智能搜索与一键预订使用自然语言塑造流畅体验">餐厅智能搜索与一键预订，使用自然语言塑造流畅体验</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#阿里巴巴-1">阿里巴巴</a>
      <ul>
        <li><a href="#qwen-image-图像生成模型--qwen-image-edit-图像编辑模型文本渲染与编辑能力卓越开源">Qwen-Image 图像生成模型 &amp;&amp; Qwen-Image-Edit 图像编辑模型，文本渲染与编辑能力卓越（开源）</a></li>
      </ul>
    </li>
    <li><a href="#leonardo">Leonardo</a>
      <ul>
        <li><a href="#lucid-origin-图像生成模型具备高清画质与鲜活色彩">Lucid Origin 图像生成模型，具备高清画质与鲜活色彩</a></li>
      </ul>
    </li>
    <li><a href="#eleven-labs">Eleven Labs</a>
      <ul>
        <li><a href="#eleven-music-音乐生成模型支持多语言人声与精细化编辑">Eleven Music 音乐生成模型，支持多语言人声与精细化编辑</a></li>
      </ul>
    </li>
    <li><a href="#google">Google</a>
      <ul>
        <li><a href="#genie-3-通用世界模型实时生成高一致性的动态交互环境">Genie 3 通用世界模型，实时生成高一致性的动态交互环境</a></li>
      </ul>
    </li>
    <li><a href="#智谱">智谱</a>
      <ul>
        <li><a href="#zread-一站式代码理解与技术文档生成工具基于-glm-45-模型构建">Zread 一站式代码理解与技术文档生成工具，基于 GLM-4.5 模型构建</a></li>
      </ul>
    </li>
    <li><a href="#googlexkaggle">Google X Kaggle</a>
      <ul>
        <li><a href="#game-arena-大模型策略竞技场用游戏对决评测智能体推理与适应能力">Game Arena 大模型策略竞技场，用游戏对决评测智能体推理与适应能力</a></li>
      </ul>
    </li>
    <li><a href="#腾讯-1">腾讯</a>
      <ul>
        <li><a href="#ai-播客一键生成流畅自然的双人对话播客">AI 播客，一键生成流畅自然的双人对话播客</a></li>
      </ul>
    </li>
    <li><a href="#华为">华为</a>
      <ul>
        <li><a href="#全面开源-cann挑战英伟达-cuda-主导地位">全面开源 CANN，挑战英伟达 CUDA 主导地位</a></li>
      </ul>
    </li>
    <li><a href="#eu-ai-act-正式生效">EU AI Act 正式生效</a>
      <ul>
        <li><a href="#成全球首部全面性-ai-法律">成全球首部全面性 AI 法律</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#anthropic">Anthropic</a>
      <ul>
        <li><a href="#claude-opus-41-基础模型增强推理与编程能力">Claude Opus 4.1 基础模型，增强推理与编程能力</a></li>
      </ul>
    </li>
    <li><a href="#openai">OpenAI</a>
      <ul>
        <li><a href="#gpt-oss-120b-gpt-oss-20bopenai-重返开源模型生态开源">gpt-oss-120b &amp;&amp; gpt-oss-20b，OpenAI 重返开源模型生态（开源）</a></li>
      </ul>
    </li>
    <li><a href="#面壁智能">面壁智能</a>
      <ul>
        <li><a href="#minicpm-v-40-端侧多模态模型在手机上稳定流畅运行开源">MiniCPM-V 4.0 端侧多模态模型，在手机上稳定流畅运行（开源）</a></li>
      </ul>
    </li>
    <li><a href="#cohere">Cohere</a>
      <ul>
        <li><a href="#north-企业级智能体平台私有化部署多源集成流程自动化">North 企业级智能体平台，私有化部署 + 多源集成 + 流程自动化</a></li>
      </ul>
    </li>
    <li><a href="#langchain">LangChain</a>
      <ul>
        <li><a href="#open-swe-异步云端编程智能体适合复杂长程的开发任务开源">Open SWE 异步云端编程智能体，适合复杂长程的开发任务（开源）</a></li>
      </ul>
    </li>
    <li><a href="#google-1">Google</a>
      <ul>
        <li><a href="#gemini-storybook-故事书一键生成个性化有声童话自定义插画与风格">Gemini Storybook 故事书，一键生成个性化有声童话，自定义插画与风格</a></li>
      </ul>
    </li>
    <li><a href="#nvidia">NVIDIA</a>
      <ul>
        <li><a href="#回应称芯片不存在后门终止开关和监控软件">回应称，芯片不存在后门、终止开关和监控软件</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#minimax">MiniMax</a>
      <ul>
        <li><a href="#speech-25-语音生成模型增强多语种表现力与音色复刻能力">Speech 2.5 语音生成模型，增强多语种表现力与音色复刻能力</a></li>
      </ul>
    </li>
    <li><a href="#anysphere">Anysphere</a>
      <ul>
        <li><a href="#cursor-cli-编程智能体命令行工具满足不同-ide-用户需求">Cursor CLI 编程智能体命令行工具，满足不同 IDE 用户需求</a></li>
      </ul>
    </li>
    <li><a href="#google-2">Google</a>
      <ul>
        <li><a href="#gemini-系列学习功能提供视觉化与互动式的-ai-学习体验">Gemini 系列学习功能，提供视觉化与互动式的 AI 学习体验</a></li>
      </ul>
    </li>
    <li><a href="#上海人工智能实验室">上海人工智能实验室</a>
      <ul>
        <li><a href="#mineru2-高精度文档解析引擎开源-mineruchem-化学信息提取工具">MinerU2 高精度文档解析引擎（开源）&amp;&amp; MinerU.Chem 化学信息提取工具</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#openai-1">OpenAI</a>
      <ul>
        <li><a href="#gpt-5-新一代统一模型实现智能跃升与效率突破">GPT-5 新一代统一模型，实现智能跃升与效率突破</a></li>
      </ul>
    </li>
    <li><a href="#google-3">Google</a>
      <ul>
        <li><a href="#magenta-realtime-实时音乐生成模型支持音频注入与风格控制开源">Magenta RealTime 实时音乐生成模型，支持音频注入与风格控制（开源）</a></li>
      </ul>
    </li>
    <li><a href="#nvidia-1">NVIDIA</a>
      <ul>
        <li><a href="#nvidia-cosmos-世界基础模型开发平台适用于物理-ai开源">NVIDIA Cosmos 世界基础模型开发平台，适用于物理 AI（开源）</a></li>
      </ul>
    </li>
    <li><a href="#2025-世界机器人大会2025wrc">2025 世界机器人大会（2025WRC）</a>
      <ul>
        <li><a href="#在北京亦庄举行">在北京亦庄举行</a></li>
      </ul>
    </li>
    <li><a href="#meta">Meta</a>
      <ul>
        <li><a href="#收购-ai-音频初创公司-waveforms">收购 AI 音频初创公司 WaveForms</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#智谱-1">智谱</a>
      <ul>
        <li><a href="#glm-45v-106b-视觉推理模型全场景视觉能力卓越开源">GLM-4.5V-106B 视觉推理模型，全场景视觉能力卓越（开源）</a></li>
      </ul>
    </li>
    <li><a href="#百川">百川</a>
      <ul>
        <li><a href="#baichuan-m2-医疗增强大模型单卡即可私有化部署开源">Baichuan-M2 医疗增强大模型，单卡即可私有化部署（开源）</a></li>
      </ul>
    </li>
    <li><a href="#昆仑万维">昆仑万维</a>
      <ul>
        <li><a href="#skyreels-a3-音频驱动数字人生成模型让数字人说话-60s开源">SkyReels-A3 音频驱动数字人生成模型，让数字人说话 60s（开源）</a></li>
      </ul>
    </li>
    <li><a href="#harveyximanage">Harvey X iManage</a>
      <ul>
        <li><a href="#深度融合-imanage-知识库实现安全高效的-ai-法律内容交互">深度融合 iManage 知识库，实现安全高效的 AI 法律内容交互</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#腾讯-2">腾讯</a>
      <ul>
        <li><a href="#混元-large-vision-多模态理解模型多语言能力出众">混元 Large-Vision 多模态理解模型，多语言能力出众</a></li>
      </ul>
    </li>
    <li><a href="#昆仑万维-1">昆仑万维</a>
      <ul>
        <li><a href="#matrix-3d-世界模型生成自由探索全景覆盖的-3d-场景开源">Matrix-3D 世界模型，生成自由探索、全景覆盖的 3D 场景（开源）</a></li>
      </ul>
    </li>
    <li><a href="#昆仑万维-2">昆仑万维</a>
      <ul>
        <li><a href="#matrix-game-20-交互式世界模型实时生成长序列视频开源">Matrix-Game 2.0 交互式世界模型，实时生成长序列视频（开源）</a></li>
      </ul>
    </li>
    <li><a href="#genspark-1">Genspark</a>
      <ul>
        <li><a href="#ai-meeting-notes全球首款支持-apple-watch-的一键-ai-会议纪要应用">AI Meeting Notes，全球首款支持 Apple Watch 的一键 AI 会议纪要应用</a></li>
      </ul>
    </li>
    <li><a href="#anthropic-1">Anthropic</a>
      <ul>
        <li><a href="#claude-上线记忆功能打造更智能的个性化-ai-助手">Claude 上线记忆功能，打造更智能的个性化 AI 助手</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#anthropic-2">Anthropic</a>
      <ul>
        <li><a href="#claude-sonnet-4-api-支持-1m-token-超长上下文">Claude Sonnet 4 API 支持 1M Token 超长上下文</a></li>
      </ul>
    </li>
    <li><a href="#higgsfield-ai">Higgsfield AI</a>
      <ul>
        <li><a href="#draw-to-video-视频生成功能无需文本提示">Draw-to-Video 视频生成功能，无需文本提示</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#腾讯-3">腾讯</a>
      <ul>
        <li><a href="#hunyuan-gamecraft-游戏视频生成工具实时打造动态游戏场景">Hunyuan-GameCraft 游戏视频生成工具，实时打造动态游戏场景</a></li>
      </ul>
    </li>
    <li><a href="#腾讯-4">腾讯</a>
      <ul>
        <li><a href="#元宝全面接入腾讯生态应用实现能力调用数据互通与内容融合">元宝全面接入腾讯生态应用，实现能力调用、数据互通与内容融合</a></li>
      </ul>
    </li>
    <li><a href="#google-4">Google</a>
      <ul>
        <li><a href="#gemini-更新个性化上下文与临时聊天功能增强个性化聊天体验">Gemini 更新「个性化上下文」与「临时聊天」功能，增强个性化聊天体验</a></li>
      </ul>
    </li>
    <li><a href="#2025世界人形机器人运动会">2025世界人形机器人运动会</a>
      <ul>
        <li><a href="#在北京国家速滑馆举行">在北京国家速滑馆举行</a></li>
      </ul>
    </li>
    <li><a href="#美国政府收购英特尔-10-股份">美国政府收购英特尔 10% 股份</a>
      <ul>
        <li><a href="#强化本土芯片制造控制权">强化本土芯片制造控制权</a></li>
      </ul>
    </li>
    <li><a href="#cohere-1">Cohere</a>
      <ul>
        <li><a href="#完成-5-亿美元融资">完成 5 亿美元融资</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#阿里巴巴-2">阿里巴巴</a>
      <ul>
        <li><a href="#webwatcher-多模态-deep-research-agent开源">WebWatcher 多模态 Deep Research Agent（开源）</a></li>
      </ul>
    </li>
    <li><a href="#anthropic-3">Anthropic</a>
      <ul>
        <li><a href="#claude-code-和-claude-双双更新学习模式促进深度理解与技能培养">Claude Code 和 Claude 双双更新学习模式，促进深度理解与技能培养</a></li>
      </ul>
    </li>
    <li><a href="#whispers-from-the-sta">Whispers from the Sta</a>
      <ul>
        <li><a href="#首款国产-ai-驱动的对话式生存游戏正式上线-steam">首款国产 AI 驱动的对话式生存游戏，正式上线 Steam</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#nvidia-2">NVIDIA</a>
      <ul>
        <li><a href="#nemotron-nano-2-端侧模型兼具高精度与高效率开源">Nemotron Nano 2 端侧模型，兼具高精度与高效率（开源）</a></li>
      </ul>
    </li>
    <li><a href="#meshy-ai">Meshy AI</a>
      <ul>
        <li><a href="#meshy-5-新一代模型全方位增强-3d-内容生成与编辑能力">Meshy 5 新一代模型，全方位增强 3D 内容生成与编辑能力</a></li>
      </ul>
    </li>
    <li><a href="#百度文库x百度网盘">百度文库 X 百度网盘</a>
      <ul>
        <li><a href="#genflow-20-全球首个全端通用智能体百个专家-agent-协同生成多模态内容">GenFlow 2.0 全球首个全端通用智能体，百个专家 Agent 协同生成多模态内容</a></li>
      </ul>
    </li>
    <li><a href="#microsoft">Microsoft</a>
      <ul>
        <li><a href="#excel-新增-copilot-函数将大模型能力引入电子表格">Excel 新增 COPILOT 函数，将大模型能力引入电子表格</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#jetbrains">JetBrains</a>
      <ul>
        <li><a href="#ai-assistant-引入-next-edit-suggestions提供全局性的智能修改建议">AI Assistant 引入 Next Edit Suggestions，提供全局性的智能修改建议</a></li>
      </ul>
    </li>
    <li><a href="#字节跳动">字节跳动</a>
      <ul>
        <li><a href="#飞书多维表格独立版上线支持跨平台集成">飞书多维表格独立版上线，支持跨平台集成</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#tripo">TRIPO</a>
      <ul>
        <li><a href="#tripo-30-新一代模型几何精度与纹理质量全面升级">TRIPO 3.0 新一代模型，几何精度与纹理质量全面升级</a></li>
      </ul>
    </li>
    <li><a href="#智谱-2">智谱</a>
      <ul>
        <li><a href="#autoglm-20-手机智能体全球首个可在云端自主运行的通用-agent">AutoGLM 2.0 手机智能体，全球首个可在云端自主运行的通用 Agent</a></li>
      </ul>
    </li>
    <li><a href="#macaron">Macaron</a>
      <ul>
        <li><a href="#全球首个生活伙伴型智能体贴心生成专属应用">全球首个生活伙伴型智能体，贴心生成专属应用</a></li>
      </ul>
    </li>
    <li><a href="#腾讯-5">腾讯</a>
      <ul>
        <li><a href="#企业微信-50全面融入-ai-能力的办公平台">企业微信 5.0，全面融入 AI 能力的办公平台</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#deepseek">DeepSeek</a>
      <ul>
        <li><a href="#deepseek-v31-语言模型agent-能力与思考效率提升开源">DeepSeek-V3.1 语言模型，Agent 能力与思考效率提升（开源）</a></li>
      </ul>
    </li>
    <li><a href="#字节跳动-1">字节跳动</a>
      <ul>
        <li><a href="#seed-oss-36b-语言模型原生支持-512k-长上下文开源">Seed-OSS-36B 语言模型，原生支持 512K 长上下文（开源）</a></li>
      </ul>
    </li>
    <li><a href="#cursorxlinear">Cursor X Linear</a>
      <ul>
        <li><a href="#智能编程助手与项目管理无缝协同实现自动任务处理">智能编程助手与项目管理无缝协同，实现自动任务处理</a></li>
      </ul>
    </li>
    <li><a href="#runway">Runway</a>
      <ul>
        <li><a href="#game-worlds-交互式叙事体验平台实时生成个性化剧情">Game Worlds 交互式叙事体验平台，实时生成个性化剧情</a></li>
      </ul>
    </li>
    <li><a href="#made-by-google-2025">Made  by  Google 2025</a>
      <ul>
        <li><a href="#pixel-10-系列-ai-旗舰手机--pixel-watch-4-智能手表--gemini-for-home-智能家居助手">Pixel 10 系列 AI 旗舰手机 &amp;&amp; Pixel Watch 4 智能手表 &amp;&amp; Gemini for Home 智能家居助手</a></li>
      </ul>
    </li>
    <li><a href="#国务院">国务院</a>
      <ul>
        <li><a href="#深入实施人工智能行动的意见">深入实施“人工智能+”行动的意见</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#dynamics-lab">Dynamics Lab</a>
      <ul>
        <li><a href="#mirage-2-实时生成式世界引擎上传图片即可步入其中">Mirage 2 实时生成式世界引擎，上传图片即可步入其中</a></li>
      </ul>
    </li>
    <li><a href="#深势科技x上海交通大学x上海算法创新院">深势科技 X 上海交通大学 X 上海算法创新院</a>
      <ul>
        <li><a href="#scimaster-全球首个通用科研智能体基于-x-master-开源框架打造">SciMaster 全球首个通用科研智能体，基于 X-Master 开源框架打造</a></li>
      </ul>
    </li>
    <li><a href="#阿里巴巴-3">阿里巴巴</a>
      <ul>
        <li><a href="#qoder-智能体编程平台支持-10-万文件检索">Qoder 智能体编程平台，支持 10 万文件检索</a></li>
      </ul>
    </li>
    <li><a href="#metaxmidjourney">Meta X Midjourney</a>
      <ul>
        <li><a href="#建立技术合作伙伴关系">建立技术合作伙伴关系</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#xai">xAI</a>
      <ul>
        <li><a href="#grok-2grok-25基础模型开源预告-grok-3-即将开源">Grok 2（Grok 2.5）基础模型开源，预告 Grok 3 即将开源</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#群核科技">群核科技</a>
      <ul>
        <li><a href="#spatiallm-15-空间语言模型--spatialgen-多视角图像生成模型">SpatiallM 1.5 空间语言模型 &amp;&amp; SpatialGen 多视角图像生成模型</a></li>
      </ul>
    </li>
    <li><a href="#nvidia-3">NVIDIA</a>
      <ul>
        <li><a href="#jetson-thor-开发套件为通用机器人解锁实时推理">Jetson Thor 开发套件，为通用机器人解锁实时推理</a></li>
      </ul>
    </li>
    <li><a href="#阿里巴巴-4">阿里巴巴</a>
      <ul>
        <li><a href="#ai-钉钉-10全面迈入-ai-原生时代重构办公产品的形态">AI 钉钉 1.0，全面迈入 AI 原生时代，重构办公产品的形态</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#面壁智能-1">面壁智能</a>
      <ul>
        <li><a href="#minicpm-v-45-端侧多模态模型实现高刷视频理解突破开源">MiniCPM-V 4.5 端侧多模态模型，实现「高刷」视频理解突破（开源）</a></li>
      </ul>
    </li>
    <li><a href="#characterai-1">Character.AI</a>
      <ul>
        <li><a href="#pipsqueak-角色模型显著提升用户参与度与留存率">PipSqueak 角色模型，显著提升用户参与度与留存率</a></li>
      </ul>
    </li>
    <li><a href="#ai2">Ai2</a>
      <ul>
        <li><a href="#asta-智能体研究助手系统加速科学发现开源">Asta 智能体研究助手系统，加速科学发现（开源）</a></li>
      </ul>
    </li>
    <li><a href="#google-5">Google</a>
      <ul>
        <li><a href="#gemini-25-flash-image-图像编辑模型角色一致性与创意构图能力增强nano-banana-">Gemini 2.5 Flash Image 图像编辑模型，角色一致性与创意构图能力增强（nano banana 🍌）</a></li>
      </ul>
    </li>
    <li><a href="#heygen">HeyGen</a>
      <ul>
        <li><a href="#avatar-iv-数字人模型精准复刻真人神态与动作">Avatar IV 数字人模型，精准复刻真人神态与动作</a></li>
      </ul>
    </li>
    <li><a href="#sync">sync</a>
      <ul>
        <li><a href="#lipsync-2-pro-唇形同步模型支持-4k-高分辨率">lipsync-2-pro 唇形同步模型，支持 4K 高分辨率</a></li>
      </ul>
    </li>
    <li><a href="#阿里巴巴-5">阿里巴巴</a>
      <ul>
        <li><a href="#wan22-s2v-多模态视频生成模型音频驱动生成电影级数字人">Wan2.2-S2V 多模态视频生成模型，音频驱动生成电影级数字人</a></li>
      </ul>
    </li>
    <li><a href="#阿里巴巴-6">阿里巴巴</a>
      <ul>
        <li><a href="#dingtalk-ai钉钉首款智能硬件支持实时转写与智能总结">DingTalk AI，钉钉首款智能硬件，支持实时转写与智能总结</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#爱诗科技-aisphere">爱诗科技 AIsphere</a>
      <ul>
        <li><a href="#pixverse-v5-视频生成模型更稳更真更灵动">PixVerse V5 视频生成模型，更稳，更真，更灵动</a></li>
      </ul>
    </li>
    <li><a href="#anthropic-4">Anthropic</a>
      <ul>
        <li><a href="#claude-浏览器插件直接在浏览器中执行操作的智能体">Claude 浏览器插件，直接在浏览器中执行操作的智能体</a></li>
      </ul>
    </li>
    <li><a href="#plaud">Plaud</a>
      <ul>
        <li><a href="#plaud-note-pro-智能笔记设备再升级智能双模录音与要点标记按钮成亮点">Plaud Note Pro 智能笔记设备再升级，智能双模录音与要点标记按钮成亮点</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#microsoft-1">Microsoft</a>
      <ul>
        <li><a href="#mai-voice-1-语音生成模型--mai-1-preview-基础模型微软-ai-的独立宣言">MAI-Voice-1 语音生成模型 &amp;&amp; MAI-1-preview 基础模型，微软 AI 的独立宣言</a></li>
      </ul>
    </li>
    <li><a href="#腾讯-6">腾讯</a>
      <ul>
        <li><a href="#hunyuan-foley-视频音效生成模型为无声视频精准配音开源">Hunyuan-Foley 视频音效生成模型，为无声视频精准配音（开源）</a></li>
      </ul>
    </li>
    <li><a href="#openai-2">OpenAI</a>
      <ul>
        <li><a href="#codex-智能编程助手实现跨平台无缝协作">Codex 智能编程助手，实现跨平台无缝协作</a></li>
      </ul>
    </li>
    <li><a href="#time100-ai-2025">TIME100 AI 2025</a>
      <ul>
        <li><a href="#全球人工智能领域最具影响力的百大人物">全球人工智能领域最具影响力的百大人物</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#xai-1">xAI</a>
      <ul>
        <li><a href="#grok-code-fast-1-编程推理模型专为智能体编程优化">Grok Code Fast 1 编程推理模型，专为智能体编程优化</a></li>
      </ul>
    </li>
    <li><a href="#microsoft-2">Microsoft</a>
      <ul>
        <li><a href="#copilot-上线深度研究功能自动化研究并生成结构化报告">Copilot 上线深度研究功能，自动化研究并生成结构化报告</a></li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#perplexity">Perplexity</a>
      <ul>
        <li><a href="#study-mode学习模式个性化引导式学习与进度测验">Study Mode（学习模式），个性化引导式学习与进度测验</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">期待崩塌：GPT-5，输给了香蕉｜赛博月刊 2509 --知识铺</h1>
        </header>
        <date class="post-meta meta-date">
            2025年10月15日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <h1 id="-趋势观察">👀 趋势观察</h1>
<h6 id="1-语言模型">1. 语言模型</h6>
<p>✦ 8 月可谓语言模型的集中更新月：OpenAI 发布了 GPT-5 和开源的 GPT-OSS 系列，Claude 上线 Opus-4.1，DeepSeek 推出混合推理模型 V3.1；腾讯、字节、智谱、面壁智能等国内厂商也接连发布了各类开源模型。</p>
<p>✦ 然而，这些新模型的问世，并未给 AI 行业带来质的变化——它们更多只是让现有产品在体验上「好用了一点」。模型能力提升带来的边际价值，正持续递减。</p>
<p>✦在新的技术范式出现之前，如何有效降低推理成本，或将成为整个行业的重要趋势。尤其是在垂直领域，针对特定任务的小参数模型，其潜力依然远未被充分挖掘。</p>
<h6 id="2-图像">2. 图像</h6>
<p>✦ Qwen-Image 刚问世不久，风头便被 Nano-Banana（Gemini-2.5-Flash-Image-Preview）抢走。后者在图像一致性上的进步，几乎真真切切地「杀死」了过去大部分的 ComfyUI 工作流。如果说 gpt-image-1 还只是个「玩具」，那么 Nano-Banana 已经具备了作为生产力工具的实力。</p>
<p>✦ 按这个节奏推测，国产模型大概率会在一个月内追平。届时，图片编辑领域将被 AI 完全接管——门槛降至极低，甚至可能免费普及。</p>
<p>✦ 我们或将迎来这样一个互联网：90% 的图片都由 AI 生成，摄影与设计的传统界限将被彻底重塑。</p>
<h6 id="3-视频">3. 视频</h6>
<p>✦ 本月一个明显的趋势是，数字人模型更新与开源的速度明显加快，但基础视频模型变化不大。</p>
<p>✦可以预见，数字人技术的成熟也会催生出海量的 AI 商品讲解员与 AI 主播。但问题是——在屏幕另一端的我们，真的想看那么多数字人吗？</p>
<h6 id="4-音频">4. 音频</h6>
<p>✦ 音频领域有点像几个月前的图像领域的状态 —— 缓步前进。AI 音频生成其实还是存在一些小瑕疵——情绪控制、音色一致性、多语种的自然度等。</p>
<p>✦ 正如 Nano-Banana 的出现带来的变革，音频领域的这些问题被完全后，可能会诞生一些我们现在没有想象到的应用。</p>
<h6 id="5-3d">5. 3D</h6>
<p>✦ 3D 领域可以分为两个方向来看：单物体生成和世界生成。</p>
<p>✦ 单物体生成，持续在往更精细的工业化生产进步。</p>
<p>✦ 世界生成，又分化为了 2 个派别：一个本质是视频生成（例如 Genie3），一个本质是 3D 生成（例如 Hunyuan-World）。近几个月，这两个方向都有了不小的进展，但最终哪条道路能够胜出，仍难下定论。</p>
<h6 id="6-具身智能">6. 具身智能</h6>
<p>✦ 人形机器人的进展依旧缓慢，其「大脑」——核心模型尚未成熟。</p>
<p>✦ 英伟达 Jetson Thor 开发套件揭示了它的本质：一台会走路的 AI 一体机。而以现有的硬件参数来看，当前的 AI 算力仍不足以支撑一台人形机器人的全部需求。</p>
<h6 id="7-agent">7. Agent</h6>
<p>✦ 通用 Agent 正在向多 Agent 协作的方向演进。通俗来说，就是让不同垂直的 Agent 以串行和并行的方式，共同解决同一个问题。</p>
<p>✦ 前两个月还颇为火热的 AI 浏览器赛道，本月却明显降温。值得注意的是，Claude 选择推出的是浏览器插件，而非完整浏览器。作为头部模型厂商，这一取舍是否会对其他厂商的战略方向产生直接影响，值得观察。</p>
<h6 id="8-coding">8. Coding</h6>
<p>✦ AI Coding 领域本月呈现出三个值得关注的趋势：</p>
<p>✦Coding Agent 云端化——如 OpenAI Codex，以及本月推出的 Open SWE。</p>
<p>✦Coding Agent 终端化——如 Claude Code，以及本月上线的 Cursor CLI。</p>
<p>✦Agent 交互模式进化——如 JetBrains 推出的跨行自动补全功能和 Claude Code 的解释性编程教学。</p>
<h6 id="9-应用">9. 应用</h6>
<p>✦ 应用方向，国内和海外的公司展示出了完全不同的两种风格：</p>
<p>✦国内公司，纷纷为自家产品加上 AI 功能，比如飞书、钉钉、企微，同时悄然收紧了数据权限。</p>
<p>✦海外公司，则更注重「集成」，如 Perplexity、Harvey、Cursor 等，对数据共享的态度似乎更加开放。</p>
<p>✦ 商业上，国内巨头这样做无可厚非；可对用户来说，这或许是在悄悄夺走他们的选择权。</p>
<h6 id="10-新闻融资">10. 新闻/融资</h6>
<p>✦本月最振奋人心的消息，来自国务院——以十年为周期，为中国 AI 产业的短期、中期和长期发展划定了清晰路线。无数「黄金」正埋藏其中，等待着从业者去探寻与挖掘。</p>
<p>✦ 相比之下，海外市场显得平淡许多。除了 Meta 仍在持续「买买买」外，几乎没有出现新的大额收购。</p>
<h1 id="-时光机">🧭 时光机</h1>
<h6 id="8-月-1-日">8 月 1 日</h6>
<p>| Agent | Genspark上线 Multi-Agent Orchestration 多智能体编排，实现跨应用协同 → 多 Agent 协作不再是串行，而是可以并行了</p>
<p>| Agent | 360发布纳米 AI 多智能体蜂群系统，L4 级智能体协同平台</p>
<p>| 应用 | AdobePhotoshop更新多项 AI 功能，实现更智能高效的创意编辑 → 在图片编辑模型越来越强大的时代，PS 必须从专业使用的角度，来做出一些差异性了</p>
<p>| 新闻 | fal 完成 1.25 亿美元 C 轮融资</p>
<h6 id="8-月-2-日无">8 月 2 日（无）</h6>
<h6 id="8-月-3-日无">8 月 3 日（无）</h6>
<h6 id="8-月-4-日">8 月 4 日</h6>
<p>| 语言模型 | 腾讯Hunyuan 小尺寸融合推理模型，0.5/1.8/4/7B 多版本，消费级显卡可以运行（开源）→ 腾讯在大模型领域不算亮眼，去做端侧小模型也算是错位竞争 📌</p>
<p>| 音频 | 小米MiDashengLM-7B 声音理解大模型，统一理解语音、环境声与音乐（开源）→ 小米这个模型，和传统的 STT 模型风格完全不同，可以说是为明确场景「定制的」</p>
<p>| Agent | 金山办公推出 WPS 灵犀，原生 Office 办公智能体，用对话重塑生产力 → 支持 Word 和 PPT，期待尽快支持 Excel</p>
<p>| 应用 | 阿里巴巴发布高德地图 2025，全球首个基于地图的 AI Native 应用 → 体验下来，对话助手并不是地图应用 AI 的最佳实践，并没有比目的地搜索框体验好 ❌</p>
<p>| 应用 | Character.AIFeed，全球首个 AI Native 社交信息流，丰富 AI 娱乐的互动性和创造性 → 把 AI 陪伴的形式，从对话扩展到了信息流，会更有沉浸感</p>
<p>| 应用 | Perplexity X OpenTable联合推出餐厅智能搜索与一键预订，使用自然语言塑造流畅体验 → 有意思的是，海外是 AI 公司和传统应用公司合作，国内是传统应用公司直接在内部加 AI 能力</p>
<h6 id="8-月-5-日">8 月 5 日</h6>
<p>| 图像 | 阿里巴巴Qwen-Image 图像生成模型 &amp;&amp; Qwen-Image-Edit 图像编辑模型，文本渲染与编辑能力卓越（开源）→ 真正的 gpt-image-1 国产替代品，甚至在中文渲染能力上大大超越</p>
<p>| 图像 | Leonardo 推出 Lucid Origin 图像生成模型，具备高清画质与鲜活色彩 → 生成的图片摄影感很强，在众多生图模型里显得挺特别的</p>
<p>| 音频 | Eleven Labs发布 Eleven Music 音乐生成模型，支持多语言人声与精细化编辑 → Suno 的有力竞争者来了，AI 音乐生成的 API 不再那么难获得了</p>
<p>| 世界模型 | GoogleGenie 3 通用世界模型，实时生成高一致性的动态交互环境 → 撕开了一道可以窥见未来虚拟世界的缝隙，令人印象深刻  💥</p>
<p>| Coding | 智谱Zread 一站式代码理解与技术文档生成工具，基于 GLM-4.5 模型构建 → 智谱版的 deepwiki。近期有种感觉，智谱越来越重视应用开发了</p>
<p>| 应用 | Google X Kaggle联合推出 Game Arena 大模型策略竞技场，用游戏对决评测智能体推理与适应能力 → 挺新颖的测评方式，确实会比大众问答盲测更能看出模型的推理能力</p>
<p>| 应用 | 腾讯混元AI 播客，一键生成流畅自然的双人对话播客</p>
<p>| 新闻 | 华为全面开源 CANN，挑战英伟达 CUDA 主导地位 → 希望可以尽快看到，越来越多的国产模型使用我们自己的显卡来进行训练和推理 💪</p>
<p>| 新闻 |- EU AI Act 正式生效，成全球首部全面性 AI 法律 → 全世界开始对 AI 立法，这会对 AI 企业有更高的标准</p>
<h6 id="8-月-6-日">8 月 6 日</h6>
<p>| 语言模型 | Anthropic升级 Claude Opus 4.1 基础模型，增强推理与编程能力 → Claude 为了狙击 GPT-5，放出了 Opus 4.1，其实功能没有什么更新，就是一些小的进步</p>
<p>| 语言模型 | OpenAI 重返开源模型生态，发布 gpt-oss-120b &amp;&amp; gpt-oss-20b 两款模型（开源）→ 受到 DeepSeek 的影响，OpenAI 终于 Open 了一次。有意思的是，他们只提供了 MXFP4 量化版本 👀</p>
<p>| 语言模型 | 面壁智能MiniCPM-V 4.0 端侧多模态模型，在手机上稳定流畅运行（开源）</p>
<p>| Agent |- CohereNorth 企业级智能体平台，私有化部署 + 多源集成 + 流程自动化 → 越来越多的非头部模型企业，不再是只提供模型，而是开始关注更落地的事情了 </p>
<p>| Coding |- LangChain开源 Open SWE 异步云端编程智能体，适合复杂长程的开发任务（开源）→ 异步、云托管的 Agent，可能会是 Agent 的新趋势 📈</p>
<p>| 应用 | GoogleGemini Storybook 故事书，一键生成个性化有声童话，自定义插画与风格 → Google 对于 AI 应用的开发能力和产品敏锐度，确实是世界一流的</p>
<p>| 新闻 | NVIDIA 回应称，芯片不存在后门、终止开关和监控软件</p>
<h6 id="8-月-7-日">8 月 7 日</h6>
<p>| 音频 | MiniMaxSpeech 2.5 语音生成模型，增强多语种表现力与音色复刻能力 → Minimax 的多模态生成模型，相较于其语言模型，更有竞争力</p>
<p>| Coding | Anysphere推出 Cursor CLI 编程智能体命令行工具，满足不同 IDE 用户需求 → Cursor CLI 相比 Claude Code，可以使用非 Claude 的模型，也算是一种差异化竞争</p>
<p>| 应用 | GoogleGemini 上线一系列学习功能，提供视觉化与互动式的 AI 学习体验</p>
<p>| 应用 | 上海人工智能实验室开源 MinerU2 高精度文档解析引擎（开源）&amp;&amp; MinerU.Chem 化学信息提取工具 → 文档解析是 RAG 的刚需，而 MinerU 作为开源方案，真真切切帮助了不少企业 👊</p>
<h6 id="8-月-8-日">8 月 8 日</h6>
<p>| 语言模型 | OpenAIGPT-5 新一代统一模型，实现智能跃升与效率突破 → 预告了很久的 GPT-5 终于来了，但似乎不像一个大的升级，而更像多个模型的集成</p>
<p>| 音频 | GoogleMagenta RealTime 实时音乐生成模型，支持音频注入与风格控制（开源）→ 音乐生成居然已经被 Google 卷到了实时生成 🎵</p>
<p>| 世界模型 | NVIDIACosmos世界基础模型开发平台，适用于物理 AI（开源）→ 这就是自动驾驶行业最近很火热的 VLA 模型</p>
<p>| 新闻 | 2025 世界机器人大会（2025WRC）</p>
<p>| 新闻 | Meta 收购 AI 音频初创公司 WaveForms → Meta 又采购了，这次还是音频领域，下一次是不是视频了 📺</p>
<h6 id="8-月-9-日无">8 月 9 日（无）</h6>
<h6 id="8-月-10-日无">8 月 10 日（无）</h6>
<h6 id="8-月-11-日">8 月 11 日</h6>
<p>| 语言模型 | 智谱GLM-4.5V-106B 视觉推理模型，全场景视觉能力卓越（开源）→ 多模态能力属于全球第一梯队，期待 GLM-5 可以是一个真正的全模态模型 😎</p>
<p>| 语言模型 | 百川 Baichuan-M2 医疗增强大模型，单卡即可私有化部署（开源）→ 小参数的模型在垂直领域打败大模型的案例会越来越多</p>
<p>| 视频 | 昆仑万维 SkyReels-A3 音频驱动数字人生成模型，让数字人说话 60s（开源）→ 越来越多的公司推出数字人模型了，数字人领域也不再有门槛</p>
<p>| 应用 | Harvey 深度融合 iManage 知识库，实现安全高效的 AI 法律内容交互 → 海外应用对于互相集成的态度还是比较开放的 🤝</p>
<h6 id="8-月-12-日">8 月 12 日</h6>
<p>| 语言模型 | 腾讯混元 Large-Vision 多模态理解模型，多语言能力出众</p>
<p>| 3 D | 昆仑万维Matrix-3D 世界模型，生成自由探索、全景覆盖的 3D 场景（开源）→ 3D 世界模型开始越来越多，本质还是基于 AI 3D 生成模型</p>
<p>| 世界模型 | 昆仑万维Matrix-Game 2.0 交互式世界模型，实时生成长序列视频（开源）→ 相比 Google Genie 3，缺乏最重要的一个特性：对场景的记忆 🧠</p>
<p>| Agent | Genspark推出 AI Meeting Notes，全球首款支持 Apple Watch 的一键 AI 会议纪要应用 → Genspark 的开发能力令人佩服，已经发展为了一个大而全的 Agent 产品 ⛓</p>
<p>| 应用 | Anthropic Claude 上线记忆功能，打造更智能的个性化 AI 助手 → Claude 终于也有了自己的记忆功能，期待看到他们关于记忆的技术分享</p>
<h6 id="8-月-13-日">8 月 13 日</h6>
<p>| 语言模型 | Anthropic升级 Claude Sonnet 4 API，支持 1M Token 超长上下文 → OpenAI、Claude 和 Gemini 主流模型上下文都来到了 1M，国产厂商们抓紧跟进了 💪</p>
<p>| 视频 | Higgsfield AI升级 Draw-to-Video 视频生成功能，无需文本提示 → 大胆猜测一下，原理应该是使用多模态模型分析画面，来生成对应的 I2V 视频提示词，而非直接对视频进行编辑</p>
<h6 id="8-月-14-日">8 月 14 日</h6>
<p>| 视频 | 腾讯Hunyuan-GameCraft 游戏视频生成工具，实时打造动态游戏场景 → 所以对于玩家来说，未来的游戏不再是预设好的场景，而是不同的平行宇宙</p>
<p>| 应用 | 腾讯元宝全面接入腾讯生态应用，实现能力调用、数据互通与内容融合 → 元宝在整合腾讯生态的数据和产品</p>
<p>| 应用 | Google Gemini 更新 个性化上下文 与 临时聊天 功能，增强个性化聊天体验 → 个性化上下文本质就是记忆，跨会话的记忆已经成为了 Chatbot 的标配 🔑</p>
<p>| 新闻 | 2025世界人形机器人运动会</p>
<p>| 新闻 | 美国政府收购英特尔 10% 股份，强化本土芯片制造控制权</p>
<p>| 新闻 | Cohere 完成 5 亿美元融资 → Cohere 很明显不再只讲大模型的故事了，而他们的新故事也受到了资本市场的认可</p>
<h6 id="8-月-15-日">8 月 15 日</h6>
<p>| Agent | 阿里巴巴WebWatcher 多模态 Deep Research Agent（开源）</p>
<p>| Coding | Anthropic更新 Claude Code 和 Claude 学习模式，促进深度理解与技能培养 → Vibe Coding 确实需要更好的人机协作的模式</p>
<p>| 应用 |- Whispers from the Star正式上线 Steam，首款国产 AI 驱动的对话式生存游戏</p>
<h6 id="8-月-16-日无">8 月 16 日（无）</h6>
<h6 id="8-月-17-日无">8 月 17 日（无）</h6>
<h6 id="8-月-18-日">8 月 18 日</h6>
<p>| 语言模型 | NVIDIA开源 Nemotron Nano 2 端侧模型，兼具高精度与高效率（开源）→ 明显感觉到，近期各个公司小模型的发布频率，比大模型高多了</p>
<p>| 3 D | Meshy 5 新一代模型，全方位增强 3D 内容生成与编辑能力 → 这个月 3D 生成模型不约而同的迎来了小升级</p>
<p>| Agent | 百度文库 X 百度网盘联合发布 GenFlow 2.0 全球首个全端通用智能体，百个专家 Agent 协同生成多模态内容</p>
<p>| 应用 | MicrosoftExcel 新增 COPILOT 函数，将大模型能力引入电子表格 → 把 AI 作为一个函数公式放到 Excel 里，真是一个既优雅又实用的方案 💎</p>
<h6 id="8-月-19-日">8 月 19 日</h6>
<p>| Coding | JetBrains为 AI Assistant 引入 Next Edit Suggestions，提供全局性的智能修改建议 → 跨行的自动补全，这种操作更贴近程序员真实的使用习惯</p>
<p>| 应用 | 字节跳动飞书多维表格独立版上线，支持跨平台集成 → 飞书表格本质其实不是表格，而是个数据库可视化+自动化工具</p>
<h6 id="8-月-20-日">8 月 20 日</h6>
<p>| 3 D | TRIPO 3.0 新一代模型，几何精度与纹理质量全面升级 → AI 3D 生成又向工业化落地迈进了一步 👣</p>
<p>| Agent | 智谱 AutoGLM 2.0 手机智能体，全球首个可在云端自主运行的通用 Agent → 操作云电脑的 Agent 听多了，操作云手机的 Agent 是第一次见</p>
<p>| Agent | Macaron全球首个生活伙伴型智能体，贴心生成专属应用 → AI 陪伴 + Vibe Coding，一种出乎意料的搭配</p>
<p>| 应用 | 腾讯企业微信 5.0，全面融入 AI 能力的办公平台 → 所有的企业级 IM 都在增加 AI 功能，可是要把效果做好，才能真的让用户用起来</p>
<h6 id="8-月-21-日">8 月 21 日</h6>
<p>| 语言模型 | DeepSeekV3.1 语言模型，Agent 能力与思考效率提升（开源）→ DeepSeek 在 V3.1 将思考模型和非思考融合了，所以应该不会有 R2 了，而是 V4 🧐</p>
<p>| 语言模型 | 字节跳动Seed-OSS-36B 语言模型，原生支持 512K 长上下文（开源）→ 在这个小模型都玩 MoE 的年代，字节这个模型更像是一次技术展示</p>
<p>| Coding | Cursor X Linear 实现自动任务处理，智能编程助手与项目管理无缝协同</p>
<p>| 应用 | Runway开放 Game Worlds 交互式叙事体验平台，实时生成个性化剧情 → 十年后是不是就不存在电视剧了，每个人都是导演 🎥</p>
<p>| 硬件 | Made  by  Google 2025 发布Pixel 10 系列 AI 旗舰手机 &amp;&amp;Pixel Watch 4 智能手表 &amp;&amp;Gemini for Home 智能家居助手 → Gemini is watching you</p>
<p>| 新闻 | 国务院关于深入实施“人工智能+”行动的意见 → 一份可能会改变未来 10 年的文件，让所有 AI 从业者为之振奋</p>
<h6 id="8-月-22-日">8 月 22 日</h6>
<p>| 世界模型 | Dynamics Lab开放 Mirage 2 实时生成式世界引擎，上传图片即可步入其中 →  Mirage 2 比 Genie 3 更早实现了可玩性，生成式世界模型在这个月也开始井喷</p>
<p>| Agent | 深势科技 X 上海交通大学 X 上海算法创新院推出 SciMaster 全球首个通用科研智能体，基于 X-Master 开源框架打造</p>
<p>| Coding | 阿里巴巴 Qoder 智能体编程平台，支持 10 万文件检索</p>
<p>| 新闻 | Meta X Midjourney 建立技术合作伙伴关系 → 令人意外的是，Meta 并没有买下 Midjourney</p>
<h6 id="8-月-23-日无">8 月 23 日（无）</h6>
<h6 id="8-月-24-日">8 月 24 日</h6>
<p>| 语言模型 | xAI开源 Grok 2（Grok 2.5）基础模型，预告 Grok 3 即将开源 → 马斯克的大模型开源进展，跟火星移民计划的一样慢悠悠的</p>
<h6 id="8-月-25-日">8 月 25 日</h6>
<p>| 世界模型 | 群核科技发布 SpatiallM 1.5 空间语言模型 &amp;&amp; SpatialGen 多视角图像生成模型</p>
<p>| 具身智能 | NVIDIAJetson Thor 开发套件，为通用机器人解锁实时推理 → 看参数非常适合跑语言模型，期待这个开发套件未来可以变成可以购买的商品</p>
<p>| 应用 | 阿里巴巴发布AI 钉钉 1.0，宣告全面迈入 AI 原生时代，重构办公产品的形态</p>
<h6 id="8-月-26-日">8 月 26 日</h6>
<p>| 语言模型 | 面壁智能 MiniCPM-V 4.5 端侧多模态模型，实现「高刷」视频理解突破（开源）→ 挺适合本地部署一个用来做视频理解任务，然后自动剪辑视频 </p>
<p>| 语言模型 | Character.AI上线PipSqueak 角色模型，显著提升用户参与度与留存率</p>
<p>| 语言模型 | Ai2全面开源 Asta 智能体研究助手系统，加速科学发现（开源）</p>
<p>| 图像 | GoogleGemini 2.5 Flash Image 图像编辑模型，增强角色一致性与创意构图能力（nano banana 🍌）→ 这个模型在一致性上又有了新的突破，AI 图片编辑不再是玩具，而是工具了 🎨</p>
<p>| 视频 | HeyGenAvatar IV 数字人模型，精准复刻真人神态与动作 → 作为最早做数字人的公司，现在的领先幅度已经越来越小 💢</p>
<p>| 视频 | sync发布 lipsync-2-pro 唇形同步模型，支持 4K 高分辨率</p>
<p>| 视频 | 阿里巴巴 Wan2.2-S2V 多模态视频生成模型，音频驱动生成电影级数字人 → 通义每次开源，基本代表这个领域的门槛被真正打下来了</p>
<p>| 硬件 | 阿里巴巴DingTalk AI，钉钉首款智能硬件，支持实时转写与智能总结 → 又一个 Plaud 的竞争对手，这次是来自阿里</p>
<h6 id="8-月-27-日">8 月 27 日</h6>
<p>| 视频 | 爱诗科技 AIsphere发布 PixVerse V5 视频生成模型，更稳，更真，更灵动</p>
<p>| Agent | Anthropic内测Claude 浏览器插件，直接在浏览器中执行操作的智能体 → Claude 这个浏览器插件，会不会直接干掉了那些 AI 浏览器呢 ⚡</p>
<p>| 硬件 | Plaud Note Pro 智能笔记设备再升级，智能双模录音与要点标记按钮成亮点 → AI 录音笔的原版终于迎来更新，但整体看来，它并未展现出仿制品更为独特的优势</p>
<h6 id="8-月-28-日">8 月 28 日</h6>
<p>| 语言模型 | Microsoft推出 MAI-Voice-1 语音生成模型 &amp;&amp; MAI-1-preview 基础模型，微软 AI 的独立宣言</p>
<p>| 视频 | 腾讯 Hunyuan-Foley 视频音效生成模型，为无声视频精准配音（开源）→ 无法生成人声，离 Veo3 音效能力还是有很大差距</p>
<p>| Coding | OpenAI Codex 智能编程助手，实现跨平台无缝协作 → Claude Code 太成功了，OpenAI 也按耐不住出手了</p>
<p>| 新闻 | TIME100 AI 2025，评选全球人工智能领域最具影响力的百大人物</p>
<h6 id="8-月-29-日">8 月 29 日</h6>
<p>| 语言模型 | xAI推出 Grok Code Fast 1 编程推理模型，专为智能体编程优化 → Grok 也迫不及待的加入了 AI Coding 的战场</p>
<p>| 应用 | MicrosoftCopilot 上线深度研究功能，自动化研究并生成结构化报告</p>
<h6 id="8-月-30-日无">8 月 30 日（无）</h6>
<h6 id="8-月-31-日">8 月 31 日</h6>
<p>| 应用 | Perplexity上线Study Mode（学习模式），个性化引导式学习与进度测验 → 几个大厂都推出了「学习模式」，这也算是 AI 应用的一个新趋势</p>
<h1 id="8-月-1-日-1">8 月 1 日</h1>
<h2 id="genspark">Genspark</h2>
<h3 id="multi-agent-orchestration-多智能体编排实现跨应用协同">Multi-Agent Orchestration 多智能体编排，实现跨应用协同</h3>
<p>Multi-Agent Orchestration 是 Genspark 一款多智能体协同的任务编排平台，其核心是一个具备学习与调度能力的 Super Agent。</p>
<p>该平台可以智能协调多个专用子智能体——例如 AI Sheet Agent、AI Slides Agent、AI Document Agent、Call for Me 及 Code Agent 等，它们分别运行在独立优化的环境中，共同构建出一个高效协作网络。通过端到端的任务处理机制，Genspark 能够无缝集成复杂操作，为用户提供统一而流畅的体验。</p>
<p>使用入口：前往 Genspark 官网体验（genspark.ai）。</p>
<p>权威信源：https://mainfunc.ai/blog/genspark_multiagent_orchestration</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9026720251015223548LsETICl3.png" />   
    </p>
<h4 id="-业内解读--多-agent-协作不再是串行而是可以并行了-">&gt; “业内解读 → 多 Agent 协作不再是串行，而是可以并行了 🔀”</h4>
<h2 id="360">360</h2>
<h3 id="纳米-ai-多智能体蜂群系统l4-级智能体协同平台">纳米 AI 多智能体蜂群系统，L4 级智能体协同平台</h3>
<p>纳米 AI 升级为多智能体蜂群系统，支持多个智能体灵活拉群、多层嵌套与协同组队，将不同专长的推理型智能体组合起来，共同完成复杂任务。</p>
<p>作为全球首个达到 L4 级别的智能体系统，它已在视频制作、内容创作、行业研究、电商带货及旅行规划等 10 余类场景中实现应用，为用户提供更高效、更精准的成果交付服务。</p>
<p>使用入口：前往 纳米 官网体验（n.cn）；或者前往应用平台下载 纳米AI 移动端。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzIwMDE1NTI2NA==&amp;mid=2651899541&amp;idx=1&amp;sn=77866f3caf39f0f3038a21ce59f022ab&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2344620251015223548Skvg2Pef.png" />   
    </p>
<h4 id="-360-在-ai-应用开发的速度上算是名列前茅了-">&gt; “360 在 AI 应用开发的速度上，算是名列前茅了 ⚡”</h4>
<h2 id="adobe">Adobe</h2>
<h3 id="photoshop-多项-ai-功能更新实现更智能高效的创意编辑">Photoshop 多项 AI 功能更新，实现更智能高效的创意编辑</h3>
<p>Adobe Photoshop 推出了多项 AI 创新功能，全面优化创意工作流程，使图像编辑更加高效与直观。</p>
<ul>
<li>Harmonize（协调）：智能匹配新元素的颜色与光照，实现自然无缝的合成效果；</li>
<li>Generative Upscale（生成式放大）：在保持图像清晰的前提下，将分辨率提升至 800 万像素；</li>
<li>Remove tool（移除工具）：精准地清除冗余内容并生成逼真填充；</li>
<li>Projects（项目）：提供一个共享协作空间，有效管理及组织素材，解决文件分散与团队协作不便的痛点。</li>
</ul>
<p>使用入口：前往 Photoshop 官网了解详情（adobe.com/products/photoshop.html）；。</p>
<p>权威信源：https://blog.adobe.com/en/publish/2025/07/29/powerful-new-photoshop-innovations-creators-creative-pros</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2410820251015223549AET5smgx.png" />   
    </p>
<h4 id="-在图片编辑模型越来越强大的时代ps-必须从专业使用的角度来做出一些差异性了-">&gt; “在图片编辑模型越来越强大的时代，PS 必须从专业使用的角度，来做出一些差异性了 🎨”</h4>
<h2 id="fal">fal</h2>
<h3 id="完成-125-亿美元-c-轮融资">完成 1.25 亿美元 C 轮融资</h3>
<p>人工智能计算平台 fal 宣布完成 1.25 亿美元 C 轮融资，本轮由 Meritech 领投，Salesforce Ventures、Shopify Ventures 及 Google AI Futures Fund 等新老投资者共同参与。融资将主要用于扩大团队规模、加强市场推广、扩展 GPU 集群，并进一步推广其面向定制模型部署的 fal Serverless 服务。</p>
<p>fal 成立于 2021 年，早期致力于提升 Python 的计算扩展能力，随后迅速把握生成式 AI 的发展机遇，专注于优化如 Stable Diffusion 等模型的运行效率，并逐步拓展至视频生成领域。凭借在技术方面的前瞻布局与持续聚焦，fal 在过去 12 个月内实现了收入增长 60 倍的显著成绩。</p>
<p>权威信源：https://blog.fal.ai/series-c</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2055420251015223549jJi6ddhp.png" />   
    </p>
<h1 id="8-月-4-日-1">8 月 4 日</h1>
<h2 id="腾讯">腾讯</h2>
<h3 id="hunyuan-小尺寸融合推理模型051847b-多版本消费级显卡可以运行开源">Hunyuan 小尺寸融合推理模型，0.5/1.8/4/7B 多版本，消费级显卡可以运行（开源）</h3>
<p>腾讯开源了 4 款小尺寸模型，参数量分别为 0.5B、1.8B、4B 和 7B，专为笔记本电脑与手机等低功耗场景设计，可以在消费级显卡上流畅运行。</p>
<p>这些模型原生支持 256k 长上下文窗口，推理速度快，性价比高，还支持「快思考」与「慢思考」两种模式，能灵活应对不同复杂程度的任务需求。</p>
<p>目前，这些模型已在腾讯会议 AI 小助手、微信读书 AI 问书、腾讯手机管家等多个内部业务中投入使用。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/tencent/Hunyuan-7B-Instruct）；前往 Github 获取代码（github.com/Tencent-Hunyuan/Hunyuan-7B）。前往 腾讯混元 官网体验（hunyuan.tencent.com/modelSquare/home/list）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkwODU2OTQyNQ==&amp;mid=2247495295&amp;idx=1&amp;sn=a80664d65365f830bbbad678d6649a7f&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/42715202510152235491w4SffmJ.png" />   
    </p>
<h4 id="-腾讯在大模型领域不算亮眼去做端侧小模型也算是错位竞争-">&gt; “腾讯在大模型领域不算亮眼，去做端侧小模型也算是错位竞争 📌”</h4>
<h2 id="小米">小米</h2>
<h3 id="midashenglm-7b-声音理解大模型统一理解语音环境声与音乐开源">MiDashengLM-7B 声音理解大模型，统一理解语音、环境声与音乐（开源）</h3>
<p>MiDashengLM-7B 是小米发布并全量开源的一款声音理解大模型，实现了对语音、环境声音和音乐的统一理解。</p>
<p>作为小米「人车家全生态」战略的关键技术，该模型依托跨领域的声音理解能力，显著提升了用户在智能座舱、智能家居等场景中的理解泛化性，推动多模态交互体验的全面升级。</p>
<p>该模型训练数据 100% 来自公开数据集，涵盖 110 万小时资源。小米完整公开了 77 个数据源的详细配比与训练流程。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/mispeech/midashenglm-7b）；前往 Github 获取代码（github.com/xiaomi-research/dasheng-lm）。前往 Demo 页面体验（xiaomi-research.github.io/dasheng-lm）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzUxMDQxMDMyNg==&amp;mid=2247517696&amp;idx=1&amp;sn=ca66a019a821ffc7949f376d9c2b87c9&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7130320251015223549UyXY1RpT.png" />   
    </p>
<h4 id="-小米这个模型和传统的-stt-模型风格完全不同可以说是为明确场景定制的">&gt; “小米这个模型，和传统的 STT 模型风格完全不同，可以说是为明确场景「定制的」🎯”</h4>
<h2 id="金山办公">金山办公</h2>
<h3 id="wps-灵犀原生-office-办公智能体用对话重塑生产力">WPS 灵犀，原生 Office 办公智能体，用对话重塑生产力</h3>
<p>WPS 灵犀作为 WPS AI 的 3.0 版本，将 AI 与办公软件进行了深度融合，让用户通过自然语言对话就可以完成 Word 和 PPT 的各类任务，实现了办公生产力的跨越式提升。</p>
<p>它采用「文档创作」与「AI 助理」同屏协作的形态，用户可以像聊天一样通过多轮对话来调整和生成内容。其中，AI PPT 功能支持通过对话生成并调整大纲，而灵犀语音助手允许用户通过语音通话快速提取文档中的键信息。</p>
<p>使用入口：前往 WPS AI 官网体验（ai.wps.cn）；或者下载 WPS 客户端。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzIwNTU0NDE1Ng==&amp;mid=2247508799&amp;idx=1&amp;sn=5c746bd4d8f8e3285a41b17cd621bb4b&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6690220251015223549Jso2rWpR.png" />   
    </p>
<h4 id="-支持-word-和-ppt期待尽快支持-excel-">&gt; “支持 Word 和 PPT，期待尽快支持 Excel 📝”</h4>
<h2 id="阿里巴巴">阿里巴巴</h2>
<h3 id="高德地图-2025全球首个基于地图的-ai-native-应用">高德地图 2025，全球首个基于地图的 AI Native 应用</h3>
<p>高德地图 2025 实现全面 AI 化升级，依托空间智能架构，推出具了备自主推理能力的出行生活智能体「小高老师」。用户通过自然语言与「小高老师」交互，表达个性化需求，智能体将迅速理解并生成相应方案。</p>
<p>新版本基于与通义共建的多元大模型簇，协同出行、生活、空间三大子智能体，实现了从「对话工具」到「行动伙伴」的跨越，为全球超过 10 亿用户提供覆盖行前、行中、行后的全旅程 AI 服务。</p>
<p>使用入口：前往 高德App 最新版，搜索 空间智能 体验。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTA3Nzc4MA==&amp;mid=2650724822&amp;idx=1&amp;sn=7c21388268e20ebcc9d90b37da0f9e03&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2843020251015223549PP1t2ngb.png" />   
    </p>
<h4 id="-体验下来对话助手并不是地图应用-ai-的最佳实践并没有比目的地搜索框体验好-">&gt; “体验下来，对话助手并不是地图应用 AI 的最佳实践，并没有比目的地搜索框体验好 🚫”</h4>
<h2 id="characterai">Character.AI</h2>
<h3 id="feed全球首个-ai-native-社交信息流丰富-ai-娱乐的互动性和创造性">Feed，全球首个 AI Native 社交信息流，丰富 AI 娱乐的互动性和创造性</h3>
<p>Feed 是一个动态滚动的 AI 内容平台，汇集了 Character.AI 整个应用里的最新角色、场景、直播（角色辩论或直播）与视频内容，并集成了多种多模态创作工具。用户不仅可以浏览信息流，还能随时参与互动，例如重写故事情节、将自己代入为主角或者与感兴趣的角色开启新的对话。</p>
<p>通过此次发布，Character.AI 从原本的聊天应用升级为内容驱动的 AI 社交平台，彻底改变了传统社交网络中「用户被动消费内容」的模式，将每一条内容转化为可互动、可再创作的创意游乐场。</p>
<p>使用入口：前往下载 Character.AI 移动端应用。</p>
<p>权威信源：https://blog.character.ai/character-ai-launches-worlds-first-ai-native-social-feed</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9621820251015223549fFpQC3de.png" />   
    </p>
<h4 id="-把-ai-陪伴的形式从对话扩展到了信息流会更有沉浸感-">&gt; “把 AI 陪伴的形式，从对话扩展到了信息流，会更有沉浸感 🔮”</h4>
<h2 id="perplexityxopentable">Perplexity X OpenTable</h2>
<h3 id="餐厅智能搜索与一键预订使用自然语言塑造流畅体验">餐厅智能搜索与一键预订，使用自然语言塑造流畅体验</h3>
<p>Perplexity 与全球知名餐厅预订平台 OpenTable 达成合作，共同推出全新智能餐厅预订功能。用户从搜索到预订一气呵成，无需在多个应用之间反复切换，也无需手动筛选海量评价，显著提升了查找和预订餐厅的效率。</p>
<p>用户可以使用自然语言提出复杂的就餐需求，Perplexity 能够精准理解并直接提供符合条件的 OpenTable 餐厅选项；当用户看到心仪的餐厅时，直接点击「预订」按钮，就可以通过 OpenTable 完成预订并收到确认信息，全程非常流畅。</p>
<p>使用入口：前往 Perplexity 官网体验（perplexity.ai）。</p>
<p>权威信源：https://www.perplexity.ai/hub/blog/book-a-table-with-perplexity-and-opentable</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1925320251015223549W8FrjCn7.png" />   
    </p>
<h4 id="-有意思的是海外是-ai-公司和传统应用公司合作国内是传统应用公司直接在内部加-ai-能力-">&gt; “有意思的是，海外是 AI 公司和传统应用公司合作，国内是传统应用公司直接在内部加 AI 能力 🧐”</h4>
<h1 id="8-月-5-日-1">8 月 5 日</h1>
<h2 id="阿里巴巴-1">阿里巴巴</h2>
<h3 id="qwen-image-图像生成模型--qwen-image-edit-图像编辑模型文本渲染与编辑能力卓越开源">Qwen-Image 图像生成模型 &amp;&amp; Qwen-Image-Edit 图像编辑模型，文本渲染与编辑能力卓越（开源）</h3>
<p>Qwen-Image 是一个参数量 20B 的 MMDiT 模型，在复杂文本渲染（尤其是中文）和一致性图像编辑方面表现卓越，在多个基准测试中达到 SOTA 水平。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Qwen/Qwen-Image）；前往 Github 获取代码（github.com/QwenLM/Qwen-Image）。前往 QwenChat 官网体验（chat.qwen.ai）。</p>
<p>Qwen-Image-Edit 基于 Qwen-Image 进一步训练而来，将精准的文本渲染能力拓展至编辑领域，不仅能完成元素的添加、删除等低阶编辑，也能胜任风格迁移、IP 创作等高阶语义编辑任务。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Qwen/Qwen-Image-Edit）；前往 Github 获取代码（github.com/QwenLM/Qwen-Image）。前往 QwenChat 官网体验（chat.qwen.ai）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk0ODg4NDI5NA==&amp;mid=2247485453&amp;idx=1&amp;sn=a9c70216c69bdad16dcb23314f608df0&amp;scene=21#wechat_redirect">官方介绍 Qwen-Image</a> | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0ODg4NDI5NA==&amp;mid=2247485690&amp;idx=1&amp;sn=247bdb87c9bfbac90bf3e87b42f6f0c3&amp;scene=21#wechat_redirect">Qwen-Image-Edit</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3591720251015223549bmnc9Pdz.png" />   
    </p>
<h4 id="-真正的-gpt-image-1-国产替代品甚至在中文渲染能力上大大超越-">&gt; “真正的 gpt-image-1 国产替代品，甚至在中文渲染能力上大大超越 🍻”</h4>
<h2 id="leonardo">Leonardo</h2>
<h3 id="lucid-origin-图像生成模型具备高清画质与鲜活色彩">Lucid Origin 图像生成模型，具备高清画质与鲜活色彩</h3>
<p>Lucid Origin 是一款图像生成模型，具有更强的色彩活力、更广泛的创意多样性、原生全高清画质输出以及精准的提示词响应能力。</p>
<p>模型在训练过程中，引入了具有艺术和摄影背景的研究人员共同参与，从而在美学、多样性和灵活性等多个维度上取得了平衡。</p>
<p>使用入口：前往 Leonardo 官网体验（app.leonardo.ai/image-generation）；或者前往下载 iOS / Android 移动端。</p>
<p>权威信源：https://leonardo.ai/news/lucid-origin-ai-image-model</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1602820251015223550eVyNhHcI.png" />   
    </p>
<h4 id="-生成的图片摄影感很强在众多生图模型里显得挺特别的-">&gt; “生成的图片摄影感很强，在众多生图模型里显得挺特别的 🎈”</h4>
<h2 id="eleven-labs">Eleven Labs</h2>
<h3 id="eleven-music-音乐生成模型支持多语言人声与精细化编辑">Eleven Music 音乐生成模型，支持多语言人声与精细化编辑</h3>
<p>Eleven Music 是 Eleven Labs 推出的一款 AI 音乐生成模型，能够通过自然语言描述生成录音室级别音乐。API 接口已经上线。</p>
<p>该模型支持实时生成 44.1kHz 的高品质音频，并能精准遵循用户指定的歌词、调性和 BPM。模型还支持多语言人声，并允许用户编辑单个部分或整首歌曲的声音/歌词，实现精细化控制。</p>
<p>使用入口：前往 Eleven Labs 官网体验（elevenlabs.io/music）；或者调用 API（elevenlabs.io/docs/cookbooks/music/quickstart）。</p>
<p>权威信源：https://elevenlabs.io/blog/eleven-music-is-here</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9214120251015223550dgxiT8jb.png" />   
    </p>
<h4 id="-suno-的有力竞争者来了ai-音乐生成的-api-不再那么难获得了-">&gt; “Suno 的有力竞争者来了，AI 音乐生成的 API 不再那么难获得了 👏”</h4>
<h2 id="google">Google</h2>
<h3 id="genie-3-通用世界模型实时生成高一致性的动态交互环境">Genie 3 通用世界模型，实时生成高一致性的动态交互环境</h3>
<p>Genie 3 是一款通用世界模型，可以基于文本提示词生成多样化的可交互环境。它能够模拟物理属性、自然生态以及虚构世界，并允许用户通过文本指令改变天气或引入新物体。</p>
<p>该模型能够以每秒 24 帧的速度和 720p 的分辨率实时生成与导航动态世界，并能在数分钟内保持场景的一致性，这标志着世界模型在实时交互能力上的重大突破。</p>
<p>但目前 Genie 3 仍存在一定局限，包括智能体动作空间有限、多智能体复杂交互模拟精度不足、无法高度还原真实世界地点，以及单次交互时长仅能维持数分钟等问题，仍待进一步优化。</p>
<p>权威信源：https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/45512202510152235506m5XTml4.png" />   
    </p>
<h4 id="-撕开了一道可以窥见未来虚拟世界的缝隙令人印象深刻-">&gt; “撕开了一道可以窥见未来虚拟世界的缝隙，令人印象深刻 💥”</h4>
<h2 id="智谱">智谱</h2>
<h3 id="zread-一站式代码理解与技术文档生成工具基于-glm-45-模型构建">Zread 一站式代码理解与技术文档生成工具，基于 GLM-4.5 模型构建</h3>
<p>Zread 是一款基于大模型的开发效率工具，能帮助开发者快速理解和接手复杂的代码项目。用户只需要输入 GitHub 仓库链接，Zread 就能生成清晰的技术导读文档，包含项目结构梳理、模块依赖分析与设计模式解读，还支持多仓库对比和分层解读。</p>
<p>此外，Zread 还能够构建团队知识协作系统，提供贡献者图谱、聚合社区评论，并具备交互式问答功能，全面提升代码理解与团队协作效率。</p>
<p>使用入口：前往 Zread 官网体验（Zread.ai）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI3NzQ0Mg==&amp;mid=2247491615&amp;idx=1&amp;sn=250061b00451f13be77e7af75eaa0d1f&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkyNzE3MTkyMw==&amp;mid=2247491223&amp;idx=1&amp;sn=05d53fda830e7c1f267c50aea592ba75&amp;scene=21#wechat_redirect">Zread 和 DeepWiki 怎么选？</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6661420251015223550Cc2lcyqr.gif" />   
    </p>
<h4 id="-智谱版的-deepwiki近期有种感觉智谱越来越重视应用开发了-">&gt; “智谱版的 deepwiki。近期有种感觉，智谱越来越重视应用开发了 👀”</h4>
<h2 id="googlexkaggle">Google X Kaggle</h2>
<h3 id="game-arena-大模型策略竞技场用游戏对决评测智能体推理与适应能力">Game Arena 大模型策略竞技场，用游戏对决评测智能体推理与适应能力</h3>
<p>Kaggle Game Arena（游戏竞技场）是 Google 与 Kaggle 联合推出的一个新型基准测试平台，让不同的大模型在多种策略游戏中展开 1V1 对抗，以此系统化地评估他们在复杂推理与动态适应方面的能力。</p>
<p>整个系统由游戏环境、输入输出适配器与可视化工具组成，比赛结果将基于 Elo 等性能指标进行排名，并在 Kaggle 平台上形成独立的公开排行榜。</p>
<p>由于游戏自身具备规则明确、结构清晰及胜负可量化等特点，它们已成为衡量大模型通用问题解决能力的理想实验场景，也为研究社区提供了透明且一致的评估基准。</p>
<p>使用入口：前往 Kaggle Game Arena 官网体验（kaggle.com/game-arena）。</p>
<p>权威信源：https://www.kaggle.com/blog/introducing-game-arena</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/63504202510152235510c52p3qo.png" />   
    </p>
<h4 id="-挺新颖的测评方式确实会比大众问答盲测更能看出模型的推理能力-">&gt; “挺新颖的测评方式，确实会比大众问答盲测更能看出模型的推理能力 🏆”</h4>
<h2 id="腾讯-1">腾讯</h2>
<h3 id="ai-播客一键生成流畅自然的双人对话播客">AI 播客，一键生成流畅自然的双人对话播客</h3>
<p>腾讯混元推出了 AI 播客功能，支持将文本、网页链接和文档一键转换为流畅自然的双人对话式音频。它把原本晦涩复杂的专业内容，转化为一场逻辑清晰、节奏舒适的对谈，让用户通过「听」的方式更高效地理解和吸收信息。</p>
<p>目前，该功能已经应用于 ima 知识库 和 腾讯新闻 AI 播客两个场景，分别支持将知识文档和单篇新闻图文快速生成播客音频，显著提升用户的信息获取体验。</p>
<p>使用入口：前往 腾讯混元 官网体验（hunyuan.tencent.com）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkwODU2OTQyNQ==&amp;mid=2247495334&amp;idx=1&amp;sn=72c3edeccde01a559bb07d9bf0beccf5&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7142920251015223551b91eMFjE.png" />   
    </p>
<h4 id="-个人jomy认为文本生成播客只一个令人新奇的好-demo但是并无法改变我们原来的阅读习惯-">&gt; “个人（Jomy）认为，文本生成播客，只一个令人新奇的好 Demo，但是并无法改变我们原来的阅读习惯 ❌”</h4>
<h2 id="华为">华为</h2>
<h3 id="全面开源-cann挑战英伟达-cuda-主导地位">全面开源 CANN，挑战英伟达 CUDA 主导地位</h3>
<p>华为在昇腾计算产业发展峰会上宣布，其 AI 计算架构 CANN（Compute Architecture for Neural Networks）全面开源。</p>
<p>CANN 定位与 CUDA 相当，是昇腾 AI 处理器的核心编程环境。此举旨在构建和繁荣昇腾硬件生态，直接挑战英伟达 CUDA 在 AI 计算领域的长期主导地位。</p>
<p>权威信源：https://www.hiascend.com/cann | <a href="https://mp.weixin.qq.com/s?__biz=MjM5ODI2NDk2Mw==&amp;mid=2658941984&amp;idx=1&amp;sn=6fd9cb6d06a6f9c457cfca0a132f196b&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzE5MTMxMDk1NA==&amp;mid=2247483841&amp;idx=1&amp;sn=97136f233dc459645789c6f988fb0893&amp;scene=21#wechat_redirect">解读</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/37910202510152235510RF0x9gU.png" />   
    </p>
<h4 id="-希望可以尽快看到越来越多的国产模型使用我们自己的显卡来进行训练和推理-">&gt; “希望可以尽快看到，越来越多的国产模型使用我们自己的显卡来进行训练和推理 💪”</h4>
<h2 id="eu-ai-act-正式生效">EU AI Act 正式生效</h2>
<h3 id="成全球首部全面性-ai-法律">成全球首部全面性 AI 法律</h3>
<p>EU AI Act（人工智能法案）正式生效，被欧盟委员会誉为「世界上第一部全面的人工智能法律」。</p>
<p>该法案为 AI 技术的开发和应用提供明确的法律框架，规范其在欧盟 27 个成员国中的使用，并同样适用于向欧盟市场提供 AI 系统或服务的外国公司，即无论是 AI 系统的开发者还是使用者，都必须遵守法案设定的规范。</p>
<p>权威信源：https://www.euaiact.com | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0MDQyNTY4Mw==&amp;mid=2247495092&amp;idx=1&amp;sn=5e5c200f1387977362a360e4abc897b3&amp;scene=21#wechat_redirect">解读</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/99405202510152235513Yvezge6.png" />   
    </p>
<h4 id="-全世界开始对-ai-立法这会对-ai-企业有更高的标准-">&gt; “全世界开始对 AI 立法，这会对 AI 企业有更高的标准 📐”</h4>
<h1 id="8-月-6-日-1">8 月 6 日</h1>
<h2 id="anthropic">Anthropic</h2>
<h3 id="claude-opus-41-基础模型增强推理与编程能力">Claude Opus 4.1 基础模型，增强推理与编程能力</h3>
<p>Claude Opus 4.1 是 Claude Opus 4 的一次升级，重点提升了模型在智能体任务、真实世界编程和复杂推理方面的表现。</p>
<p>新版本在 SWE-bench Verified 编程基准测试上的性能提升至 74.5%，达到业界领先水平。GitHub 反馈 Claude Opus 4.1 在多文件代码重构方面提升尤为显著。Windsurf 的测试结果表明，此次性能提升幅度显著，大致相当于从 Sonnet 3.7 到 Sonnet 4 的跨越。</p>
<p>使用入口：前往 Claude 官网（claude.ai）或者 Claude Code（claude.com/product/claude-code）体验；或者调用 API（console.anthropic.com）。</p>
<p>权威信源：https://www.anthropic.com/news/claude-opus-4-1 | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247503451&amp;idx=1&amp;sn=aff88889617e55d3b7eb0ff9bcb3295f&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1466920251015223551v5dbjrok.png" />   
    </p>
<h4 id="-claude-为了狙击-gpt-5放出了-opus-41其实功能没有什么更新主要是一些小的进步-">&gt; “Claude 为了狙击 GPT-5，放出了 Opus 4.1，其实功能没有什么更新，主要是一些小的进步 🚀”</h4>
<h2 id="openai">OpenAI</h2>
<h3 id="gpt-oss-120b-gpt-oss-20bopenai-重返开源模型生态开源">gpt-oss-120b &amp;&amp; gpt-oss-20b，OpenAI 重返开源模型生态（开源）</h3>
<p>OpenAI 开源了 gpt-oss-120b 和 gpt-oss-20b 两款语言模型，称其训练过程受到了 OpenAI 内部前沿模型的启发。其中，gpt-oss-120b（117B 参数）适用于生产环境的通用推理任务，可在单个 80GB GPU 上部署；gpt-oss-20b（21B 参数）则面向低延迟、本地或专业用例。</p>
<p>两款模型均采用 MXFP4 量化技术，优化了内存使用效率，并支持可配置的推理强度、完整的思维链访问及参数微调功能。此外，模型原生集成了函数调用、网页浏览与 Python 代码执行等 Agent 能力，能为各类智能体任务提供强大支持。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/openai/gpt-oss-120b）（huggingface.co/openai/gpt-oss-20b）；前往 Github 获取代码（github.com/openai/gpt-oss）。前往 PlayGround 官网体验（gpt-oss.com）。</p>
<p>权威信源：https://openai.com/index/introducing-gpt-oss | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247503467&amp;idx=1&amp;sn=f139474fb9bbca5156150b1e512624ae&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7556520251015223551DOvoBzmT.png" />   
    </p>
<h4 id="-受到-deepseek-的影响openai-终于-open-了一次有意思的是他们只提供了-mxfp4-量化版本-">&gt; “受到 DeepSeek 的影响，OpenAI 终于 Open 了一次。有意思的是，他们只提供了 MXFP4 量化版本 👀”</h4>
<h2 id="面壁智能">面壁智能</h2>
<h3 id="minicpm-v-40-端侧多模态模型在手机上稳定流畅运行开源">MiniCPM-V 4.0 端侧多模态模型，在手机上稳定流畅运行（开源）</h3>
<p>MiniCPM-V 4.0 是面壁智能开源的新一代端侧多模态模型，参数量4B，能够在手机、平板等端侧设备上实现稳定、流畅的运行，长时间使用也无发热卡顿。相较于上一代 8B 模型，它在参数减半的同时显著提升了多模态能力，在多个榜单上取得了同规模 SOTA 的成绩。</p>
<p>为方便开发者部署，面壁智能同步开源了推理工具 MiniCPM-V CookBook，支持 llama.cpp、vLLM、SGLang 等多种框架，内置了多种量化流水线及完整的 iOS 示例，真正实现了开箱即用的轻量化部署。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/openbmb/MiniCPM-V-4）；前往 Github 获取代码（github.com/OpenBMB/MiniCPM-o）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzM3OTc2Nw==&amp;mid=2247494545&amp;idx=1&amp;sn=908ef77911fb5cdda179073885d89249&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/5713420251015223551eu9aKNgc.png" />   
    </p>
<h4 id="-个人认为模型的命名有点问题因为面壁在月底又更新了-45-版本但是参数更大并不算-40-版本的升级-">&gt; “个人认为模型的命名有点问题，因为面壁在月底又更新了 4.5 版本，但是参数更大，并不算 4.0 版本的升级 🤔”</h4>
<h2 id="cohere">Cohere</h2>
<h3 id="north-企业级智能体平台私有化部署多源集成流程自动化">North 企业级智能体平台，私有化部署 + 多源集成 + 流程自动化</h3>
<p>North 是 Cohere 推出的企业级智能体平台，支持私有化部署，能够无缝集成企业内部各类分散数据源。员工通过自然语言聊天和搜索可以快速获取可靠信息，高效完成总结会议、文档生成等任务，并自动化处理从 CRM 更新到复杂业务流程的多种操作。</p>
<p>North 融合了 Cohere 先进的生成式模型和搜索模型，支持定制智能体以及内置的自动化工作流，能有效减轻员工日常工作中的重复性负担，显著提升整体生产力。其架构经轻量化优化，最低仅需 2 块 GPU 即可运行，兼具成本效益与扩展性。</p>
<p>使用入口：前往 Cohere North 官网了解详情（cohere.com/north）。</p>
<p>权威信源：https://cohere.com/blog/north-ga</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6965420251015223552EDXKNEiJ.png" />   
    </p>
<h4 id="-越来越多的非头部模型企业不再是只提供模型而是开始关注更落地的事情了-">&gt; “越来越多的非头部模型企业，不再是只提供模型，而是开始关注更落地的事情了 🛠”</h4>
<h2 id="langchain">LangChain</h2>
<h3 id="open-swe-异步云端编程智能体适合复杂长程的开发任务开源">Open SWE 异步云端编程智能体，适合复杂长程的开发任务（开源）</h3>
<p>Open SWE 是 LangChain 推出的首个开源、异步、云托管的编程智能体，能直接连接用户的 GitHub 仓库，并通过 issue 或自定义界面接收开发任务。通过与 GitHub 深度集成，所有任务的创建、跟踪与交付都在开发者熟悉的环境中进行，显著提升了处理复杂长耗时任务的效率。</p>
<p>它的工作模式像一名真正的工程师：可以深入分析代码库、制定执行计划、编写代码、运行测试、审查修改内容，并最终发起拉取请求。与传统编程工具相比，Open SWE 更注重整体流程与用户体验，允许用户在智能体运行过程中随时中断并引导操作，从而实现对开发过程更灵活的控制。</p>
<p>使用入口：前往 Open SWE 官网体验（swe.langchain.com）。</p>
<p>权威信源：https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6109520251015223552MTXSeinj.png" />   
    </p>
<h4 id="-异步云托管的-agent可能会是-agent-的新趋势-">&gt; “异步、云托管的 Agent，可能会是 Agent 的新趋势 📈”</h4>
<h2 id="google-1">Google</h2>
<h3 id="gemini-storybook-故事书一键生成个性化有声童话自定义插画与风格">Gemini Storybook 故事书，一键生成个性化有声童话，自定义插画与风格</h3>
<p>Gemini 正式推出 Storybook 创新功能，用户只需输入简单的文字描述，就可以创作一本长达 10 页的图文并茂的有声故事书，且每页都配有定制插画和流畅的朗读旁白。</p>
<p>此外，该功能支持上传照片、截图或文档作为参考，支持指定艺术风格（例如定格动画、漫画、像素艺术），还可通过多轮调整不断完善情节和表达，真正实现故事的个性化创作。目前，Gemini Storybook 已支持超过 45 种语言。</p>
<p>使用入口：前往 Google Gemini 官网体验（gemini.google.com/storybook）。</p>
<p>权威信源：https://gemini.google/overview/storybook</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/166152025101522355297rA4FmZ.png" />   
    </p>
<h4 id="-google-对于-ai-应用的开发能力和产品敏锐度确实是世界一流的-">&gt; “Google 对于 AI 应用的开发能力和产品敏锐度，确实是世界一流的 👏”</h4>
<h2 id="nvidia">NVIDIA</h2>
<h3 id="回应称芯片不存在后门终止开关和监控软件">回应称，芯片不存在后门、终止开关和监控软件</h3>
<p>7月31日，中国国家网信办、工信部及国安部联合约谈英伟达中国，要求其 72 小时内提交 H20 芯片的完整技术说明，质疑其可能存在后门、远程终止开关或监控软件。</p>
<p>8月6日，英伟达发布中英文声明，称经三家独立实验室检测，H20 芯片不存在上述安全隐患。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzA4NDI3NjcyNA==&amp;mid=2650152776&amp;idx=1&amp;sn=dbe72e3d1683449e8285636bfab21c39&amp;scene=21#wechat_redirect">链接</a> | <a href="https://mp.weixin.qq.com/s?__biz=MjM5MDk4MzA3OA==&amp;mid=2247539504&amp;idx=1&amp;sn=317539615da92d4dcecac382948125dc&amp;scene=21#wechat_redirect">链接</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7594520251015223552U4EhgGew.png" />   
    </p>
<h4 id="-有消息称英伟达已指示其供应商停止生产面向中国市场的-h20-ai-芯片-">&gt; “有消息称，英伟达已指示其供应商停止生产面向中国市场的 H20 AI 芯片 👀”</h4>
<h1 id="8-月-7-日-1">8 月 7 日</h1>
<h2 id="minimax">MiniMax</h2>
<h3 id="speech-25-语音生成模型增强多语种表现力与音色复刻能力">Speech 2.5 语音生成模型，增强多语种表现力与音色复刻能力</h3>
<p>Speech 2.5 是 MiniMax 发布的新一代语音生成模型，在继承前代 Speech 02 高性价比优势的基础上，进一步提升了多语种表现力、音色复刻能力和语种覆盖范围。</p>
<p>该模型中文效果已达全球领先水平，其行业顶尖的音色复刻能力可精准还原跨语种口音与特定年龄段的声音细节。同时，模型支持语种数量扩展至 40 个。</p>
<p>使用入口：前往 MiniMax 官网体验（minimaxi.com/audio）；或者调用 API（minimaxi.com/platform_overview）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzE5MTA3NzcxMQ==&amp;mid=2247486790&amp;idx=1&amp;sn=08ccca6bcb9644391af510f84f2189d3&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6969120251015223552E8XR8Oc4.png" />   
    </p>
<h4 id="-minimax-的多模态生成模型相较于其语言模型更有竞争力-">&gt; “Minimax 的多模态生成模型，相较于其语言模型，更有竞争力 🔥”</h4>
<h2 id="anysphere">Anysphere</h2>
<h3 id="cursor-cli-编程智能体命令行工具满足不同-ide-用户需求">Cursor CLI 编程智能体命令行工具，满足不同 IDE 用户需求</h3>
<p>Cursor 正式推出智能体命令行界面（CLI），使开发者能够在任意开发环境中使用 Cursor Agent 编程辅助功能。用户通过简单的 curl 命令完成安装后，使用 cursor-agent chat 命令即可启动智能体处理各类编程任务。</p>
<p>Cursor CLI 可以与任何模型配合使用，既可在本地终端运行，也支持远程并行调用多个智能体。这一升级标志着 Cursor 从单一的编辑器内置助手，演进为一个适用于不同 IDE 环境的通用型编程智能体。</p>
<p>使用入口：前往 Cursor CLI 官网体验（cursor.com/cli）。</p>
<p>权威信源：https://cursor.com/blog/cli</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/49479202510152235528NTeMFgj.png" />   
    </p>
<h4 id="-cursor-cli-相比-claude-code可以使用非-claude-的模型也算是一种差异化竞争-">&gt; “Cursor CLI 相比 Claude Code，可以使用非 Claude 的模型，也算是一种差异化竞争 🚩”</h4>
<h2 id="google-2">Google</h2>
<h3 id="gemini-系列学习功能提供视觉化与互动式的-ai-学习体验">Gemini 系列学习功能，提供视觉化与互动式的 AI 学习体验</h3>
<p>Gemini 推出了一系列强大的学习辅助功能，能够帮助学生更深入地掌握和复习知识。</p>
<ul>
<li>Guided Learning（引导式学习）：通过分步解析与适应性解释，不仅告诉学生如何解题，更帮助他们理解背后的原理与逻辑，避免单纯提供答案。</li>
<li>Visual Learning（视觉学习）：系统能够自动整合高质量的图片、示意图和 YouTube 视频等资源，让复杂概念变得直观易懂。</li>
<li>Quiz generation &amp;&amp; Flashcards（测验&amp;&amp;闪卡）：根据课堂内容或测验结果，即时生成互动测验和带音频的闪卡，为学生提供全新、高效的知识巩固与备考方式。</li>
</ul>
<p>使用入口：前往 Gemini 官网体验（gemini.google.com）。</p>
<p>权威信源：https://blog.google/products/gemini/new-gemini-tools-students-august-2025</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/8223220251015223552jdKhn1mm.png" />   
    </p>
<h4 id="-google-不愧是传统大厂在-ai-产品交互体验上一直是引领潮流-">&gt; “Google 不愧是传统大厂，在 AI 产品交互体验上一直是引领潮流 🌊”</h4>
<h2 id="上海人工智能实验室">上海人工智能实验室</h2>
<h3 id="mineru2-高精度文档解析引擎开源-mineruchem-化学信息提取工具">MinerU2 高精度文档解析引擎（开源）&amp;&amp; MinerU.Chem 化学信息提取工具</h3>
<p>MinerU 是上海人工智能实验室开源的智能文档解析引擎，其升级版本 MinerU2 解析准确率提升了 22%，解析速度提升了 6 倍。</p>
<p>该引擎不仅能够精准识别文本、布局与表格，还扩展了对数学公式、物理符号和化学分子式的高效提取，将适用范围延伸至科学数据领域，为科研工作提供高质量的语料基础。</p>
<p>使用入口：开源；前往 Github 获取（github.com/opendatalab/MinerU）。前往 Miner官网体验（mineru.net）；或者申请调用 API（mineru.net/apiManage/token）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkxMDc0MDU5Mg==&amp;mid=2247550992&amp;idx=1&amp;sn=5f53580545f1f6070e5242ab35cae86d&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4841620251015223552EqdcfFmz.png" />   
    </p>
<h4 id="-文档解析是-rag-的刚需而-mineru-作为开源方案真真切切帮助了不少企业-">&gt; “文档解析是 RAG 的刚需，而 MinerU 作为开源方案，真真切切帮助了不少企业 👊”</h4>
<p>基于 MinerU2 的先进解析能力，MinerU.Chem 专门面向化学科研领域，能够深度解析化学文献，精确提取化合物结构与化学反应等关键信息，并具备业界领先的分子结构图像识别功能。</p>
<p>官网可以体验化学解析与可视化预览服务，包括交互式查看分子结构、一键生成分子与反应式汇总表，同时支持将输出结果以多种格式（如结构文件、SMILES 或图片）进行复制或下载，显著提升化学文献处理的效率与便捷性。</p>
<p>使用入口：前往 MinerU.Chem 官网体验（mineru.net/chem）；或者下载 MinerU 桌面客户端。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkxMDc0MDU5Mg==&amp;mid=2247550993&amp;idx=1&amp;sn=7dcaaebd9cec296ccf2548d6257bf411&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/61311202510152235531BvZKkjc.png" />   
    </p>
<h1 id="8-月-8-日-1">8 月 8 日</h1>
<h2 id="openai-1">OpenAI</h2>
<h3 id="gpt-5-新一代统一模型实现智能跃升与效率突破">GPT-5 新一代统一模型，实现智能跃升与效率突破</h3>
<p>OpenAI 正式推出新一代统一模型 GPT‑5，首次融合了 o 系列的深度推理能力与 GPT 系列的高速响应特性，并采用实时路由机制，自动在深度推理与快速响应两种模式之间切换。</p>
<p>在技术层面，新模型提供包括主版本、Mini、Nano 和 Pro 在内的多种规格，支持文本、图像、视频等多模态输入输出，并首次实现了初步的视频理解能力。其上下文窗口最长 272K Token，显著扩展了复杂信息的连续处理能力。</p>
<p>相比前代模型，GPT‑5 在数学、法律和系统设计等复杂任务中的准确率提升约 12% 至 18%，幻觉现象发生率较 GPT‑4o 降低约 26%，显著提高了模型输出的可靠性及安全性。</p>
<p>使用入口：前往 ChatGPT 官网体验（chatgpt.com）；或者使用 Codex CLI 完成编程任务（github.com/openai/codex）。</p>
<p>权威信源：https://openai.com/index/introducing-gpt-5 | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247503712&amp;idx=1&amp;sn=6af188a9a3278bd29052ed08104ff80a&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/902092025101522355349cZjEjU.png" />   
    </p>
<h4 id="-预告了很久的-gpt-5-终于来了但似乎不像一个大的升级而更像多个模型的集成-">&gt; “预告了很久的 GPT-5 终于来了，但似乎不像一个大的升级，而更像多个模型的集成 🔔”</h4>
<h2 id="google-3">Google</h2>
<h3 id="magenta-realtime-实时音乐生成模型支持音频注入与风格控制开源">Magenta RealTime 实时音乐生成模型，支持音频注入与风格控制（开源）</h3>
<p>Magenta RealTime 是 Google Magenta 团队推出并开源的一款实时音乐生成模型，能够根据文本或音频风格提示流式生成音乐，并实现了实时系数达 1x 的音频输出，可以视为 MusicFX DJ 模式的开源版本。</p>
<p>该模型现已支持「音频注入」功能，用户可以通过现场演奏或预录制音频，进行实时风格转换与层次叠加，显著提升即兴创作与音乐制作的灵活性。模型参数量仅为 0.8B，可在免费 Colab TPU 环境中流畅运行。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/google/magenta-realtime）；前往 Github 获取代码（github.com/magenta/magenta-realtime）。前往 Colab 体验（colab.research.google.com/github/magenta/magenta-realtime/blob/main/notebooks/Magenta_RT_Demo.ipynb）。</p>
<p>权威信源：https://magenta.withgoogle.com/magenta-realtime</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1572720251015223553MfyqMzno.png" />   
    </p>
<h4 id="-音乐生成居然已经被-google-卷到了实时生成-">&gt; “音乐生成居然已经被 Google 卷到了实时生成 🎵”</h4>
<h2 id="nvidia-1">NVIDIA</h2>
<h3 id="nvidia-cosmos-世界基础模型开发平台适用于物理-ai开源">NVIDIA Cosmos 世界基础模型开发平台，适用于物理 AI（开源）</h3>
<p>物理 AI（如机器人和自动驾驶汽车）的快速发展，导致对高质量标注数据的需求呈指数级增长，仅依靠现实采集已难以满足需要。而世界基础模型通过基于真实环境动力学进行训练，能够模拟、预测并推理未来世界状态，正在成为突破数据瓶颈的关键技术。</p>
<p>NVIDIA Cosmos 就是一个面向物理 AI 的世界基础模型开发平台，提供三种可供后续训练的模型类型。</p>
<ul>
<li>Cosmos Predict：根据提示词生成符合物理规律的未来世界状态视频，用于加速合成数据生成。</li>
<li>Cosmos Transfer：根据分割图、深度图等多种输入生成高真实感的世界模拟效果，实现照片级的风格迁移。</li>
<li>Cosmos Reason：一个具备物理常识理解与具身推理能力的视觉语言模型，既可用于筛选高质量训练数据，也可进一步训练为视觉-语言-动作模型，协助物理 AI 完成空间感知、运动规划与复杂任务执行。</li>
</ul>
<p>使用入口：开源；前往获取 Cosmos Predict（github.com/nvidia-cosmos/cosmos-predict2）；前往获取 Cosmos Transfer（github.com/nvidia-cosmos/cosmos-transfer1）；前往获取 Cosmos Reason（research.nvidia.com/labs/dir/cosmos-reason1）。</p>
<p>权威信源：https://developer.nvidia.com/blog/r2d2-boost-robot-training-with-world-foundation-models-and-workflows-from-nvidia-research</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4838820251015223553AELklafj.png" />   
    </p>
<h4 id="-这就是自动驾驶行业最近很火热的-vla-模型-">&gt; “这就是自动驾驶行业最近很火热的 VLA 模型 🚗”</h4>
<h2 id="2025-世界机器人大会2025wrc">2025 世界机器人大会（2025WRC）</h2>
<h3 id="在北京亦庄举行">在北京亦庄举行</h3>
<p>8月8日至8月12日，2025 世界机器人大会（WRC）在北京亦庄举行，主题是「让机器人更智慧，让具身体更智能」。</p>
<p>博览会吸引了 200 余家企业参与，共展出 1500 余件展品，其中超过 100 款为首发新品。尤其是人形机器人领域，参展整机企业数量达到 50 家，创历届展会之最。</p>
<p>同期举办的世界机器人大赛吸引了全球上万名选手参与。此外，大会还推出了全球首个「机器人消费节」和「机器人大世界 2.0」启幕活动，致力于打造集展示、交易、体验于一体的产业生态新地标。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzAwMDUyOTg5MQ==&amp;mid=2647901810&amp;idx=1&amp;sn=3c10183622be734c1be19b61871e737a&amp;scene=21#wechat_redirect">官方介绍-开幕</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzAwMDUyOTg5MQ==&amp;mid=2647902172&amp;idx=1&amp;sn=8a293379941a5fa46ecb1f67548dbc3a&amp;scene=21#wechat_redirect">闭幕</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9566820251015223553ZpqmgWkY.png" />   
    </p>
<h2 id="meta">Meta</h2>
<h3 id="收购-ai-音频初创公司-waveforms">收购 AI 音频初创公司 WaveForms</h3>
<p>Meta 宣布收购 AI 语音技术初创公司 WaveForms，具体交易金额未披露。此次收购是为了强化 Meta 新成立的 Superintelligence Labs 的技术实力。WaveForms 的两位联合创始人已确认加入 Meta。这是 Meta 短期内进行的第二起 AI 音频领域收购（7月收购了 PlayAI）。</p>
<p>WaveForms（waveforms.ai）成立仅八个月，专注于突破「语音图灵测试」，即让 AI 生成的语音与人类语音无法区分。其技术方向与 Meta 在 AI 助手、可穿戴设备和音频内容创作等领域的战略高度契合。</p>
<p>权威信源：https://techcrunch.com/2025/08/08/meta-acquires-ai-audio-startup-waveforms</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2681720251015223553xIrKZMgS.png" />   
    </p>
<h4 id="-meta-又采购了这次还是音频领域下一次是不是视频了-">&gt; “Meta 又采购了，这次还是音频领域，下一次是不是视频了 📺”</h4>
<h1 id="8-月-11-日-1">8 月 11 日</h1>
<h2 id="智谱-1">智谱</h2>
<h3 id="glm-45v-106b-视觉推理模型全场景视觉能力卓越开源">GLM-4.5V-106B 视觉推理模型，全场景视觉能力卓越（开源）</h3>
<p>GLM-4.5V 是智谱最新开源的一款视觉推理模型，基于新一代旗舰文本基座 GLM-4.5-Air 构建，实现了全场景视觉推理能力，覆盖图像推理、视频理解、GUI 任务、复杂图表与长文档解析以及 Grounding（视觉元素定位）等多种任务。</p>
<p>模型总参数量 106B，激活参数 12B，在 41 个公开视觉多模态榜单中综合效果达到同规模开源模型 SOTA 性能，号称是全球 100B 规模效果最佳的视觉推理模型。此外，模型新增了思考模式开关，允许用户根据需求在快速响应和深度推理之间灵活选择，以平衡效率与效果。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/collections/zai-org/glm-45v-68999032ddf8ecf7dcdbc102）；前往 Github 获取代码（github.com/zai-org/GLM-V）。前往 Z.ai 官网体验（z.ai）；或者调用 API（docs.bigmodel.cn/api-reference）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI3NzQ0Mg==&amp;mid=2247491823&amp;idx=1&amp;sn=186403c3a030f6d64dbe7e45e124116f&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247503868&amp;idx=1&amp;sn=ba20c193c88840a442677134c3edc04f&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1470520251015223553pLKHmgmr.png" />   
    </p>
<h4 id="-多模态能力属于全球第一梯队期待-glm-5-可以是一个真正的全模态模型-">&gt; “多模态能力属于全球第一梯队，期待 GLM-5 可以是一个真正的全模态模型 😎”</h4>
<h2 id="百川">百川</h2>
<h3 id="baichuan-m2-医疗增强大模型单卡即可私有化部署开源">Baichuan-M2 医疗增强大模型，单卡即可私有化部署（开源）</h3>
<p>Baichuan-M2 是百川发布并开源的一款医疗增强大模型，针对医疗领域对数据隐私与私有化部署的需求，实现了极致的轻量化设计。经量化后，该模型可部署于单张 RTX 4090 显卡，大幅降低了使用门槛。</p>
<p>该模型在 OpenAI 发布的权威医疗健康评测集 HealthBench 上取得了 60.1 的高分，以 32B 的参数量超越了 gpt-oss-120b、Qwen3-235B 等所有现有的开源大模型。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/baichuan-inc/Baichuan-M2-32B）。</p>
<p>权威信源：https://www.baichuan-ai.com/blog/baichuan-M2 | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNzU0OTg0Mw==&amp;mid=2247484617&amp;idx=1&amp;sn=48d3288db3bdf3cd44b6f4b44424ca6e&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247503898&amp;idx=1&amp;sn=17d48e47cb0aaafde1778689cff918f0&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1449920251015223554BaakUEev.png" />   
    </p>
<h4 id="-小参数的模型在垂直领域打败大模型的案例会越来越多-">&gt; “小参数的模型在垂直领域打败大模型的案例会越来越多 🎊”</h4>
<h2 id="昆仑万维">昆仑万维</h2>
<h3 id="skyreels-a3-音频驱动数字人生成模型让数字人说话-60s开源">SkyReels-A3 音频驱动数字人生成模型，让数字人说话 60s（开源）</h3>
<p>SkyReels-A3 是昆仑万维发布并开源的一款音频驱动的人像视频生成模型，能够通过输入语音，让静态照片或现有视频中的人物开口说话或进行表演。该模型在动作自然度、镜头运用和生成时长等方面均有显著提升，支持单分镜生成最高 60 秒的连贯视频。</p>
<p>借助多模态输入兼容性，用户可依据照片、音频与文本提示词共同生成一段全新的数字人表演；也可仅为原有视频替换音频，模型将自动调整人物口型与表情，实现音画同步。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Skywork）。前往 SkyReels 官网体验（skyreels.ai）。</p>
<p>权威信源：https://skyworkai.github.io/skyreels-a3.github.io | <a href="https://mp.weixin.qq.com/s?__biz=MzI1MzE1NDc3Mg==&amp;mid=2247505885&amp;idx=1&amp;sn=162232598861a033535cc8dfb3280730&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3443320251015223554YHCcqeiD.png" />   
    </p>
<h4 id="-越来越多的公司推出数字人模型了数字人领域也不再有门槛-">&gt; “越来越多的公司推出数字人模型了，数字人领域也不再有门槛 🧱”</h4>
<h2 id="harveyximanage">Harvey X iManage</h2>
<h3 id="深度融合-imanage-知识库实现安全高效的-ai-法律内容交互">深度融合 iManage 知识库，实现安全高效的 AI 法律内容交互</h3>
<p>Harvey 是一款面向律师事务所和企业法务部门造的生成式 AI 平台，能够通过自然语言对话执行法律研究、合同起草与审查、尽职调查及合规检查等任务。iManage 则是服务于法律、金融与咨询等行业的知识工作平台，专注于集中管理文档与邮件，并把信息转化为可复用的组织知识库。</p>
<p>此次双方集成后，用户可以在 Harvey 的 Assistant、Workflows 和 Vault 功能中，通过嵌入式界面直接从 iManage 导入文档，全程无需第三方中间件，有效保障数据安全与合规性。</p>
<p>此外，用户还可在 Harvey 中起草文档并实时导回 iManage 的特定事务中，系统将完整保留版本记录与审计追踪。</p>
<p>使用入口：前往 Harvey 官网体验（harvey.ai）。</p>
<p>权威信源：https://www.harvey.ai/blog/harveys-imanage-integration</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9261220251015223554JRJGdzmH.png" />   
    </p>
<h4 id="-海外应用对于互相集成的态度还是比较开放的-">&gt; “海外应用对于互相集成的态度还是比较开放的 🤝”</h4>
<h1 id="8-月-12-日-1">8 月 12 日</h1>
<h2 id="腾讯-2">腾讯</h2>
<h3 id="混元-large-vision-多模态理解模型多语言能力出众">混元 Large-Vision 多模态理解模型，多语言能力出众</h3>
<p>混元 Large-Vision 是一款多模态理解模型，激活参数 52B，支持任意分辨率的图像、视频和 3D 空间输入，并重点提升了多语言场景的理解能力。</p>
<p>该模型已经在腾讯内部的拍照解题、视频通话、视频理解及文案创作等核心业务场景中展现出强大的应用价值。</p>
<p>使用入口：前往 腾讯混元 官网体验（hunyuan.tencent.com）。</p>
<p>权威信源：https://vision.hunyuan.tencent.com | <a href="https://mp.weixin.qq.com/s?__biz=MzkwODU2OTQyNQ==&amp;mid=2247495409&amp;idx=1&amp;sn=eba3b1f8058b7730b57a46c04c210b92&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6388420251015223554TBok6urd.png" />   
    </p>
<h2 id="昆仑万维-1">昆仑万维</h2>
<h3 id="matrix-3d-世界模型生成自由探索全景覆盖的-3d-场景开源">Matrix-3D 世界模型，生成自由探索、全景覆盖的 3D 场景（开源）</h3>
<p>Matrix-3D 是昆仑万维发布并开源的一个框架，能够生成具备全局一致性与高度可控性的可探索 3D 世界。它从单张图像出发，首先生成画面连贯、轨迹一致的全景视频，然后通过优化路径或前馈网络路径将视频转换为可漫游的三维场景。</p>
<p>此外，为支持模型训练，团队还构建了包含 116K 条序列的大规模高质量合成数据集 Matrix-Pano。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Skywork/Matrix-3D）；前往 Github 获取代码（github.com/SkyworkAI/Matrix-3D）。</p>
<p>权威信源：https://matrix-3d.github.io | <a href="https://mp.weixin.qq.com/s?__biz=MzI1MzE1NDc3Mg==&amp;mid=2247505931&amp;idx=2&amp;sn=ebcffe26210a0cf618b893f500bc8f87&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2488420251015223554VuVsyqmP.png" />   
    </p>
<h4 id="-3d-世界模型开始越来越多本质还是基于-ai-3d-生成模型-">&gt; “3D 世界模型开始越来越多，本质还是基于 AI 3D 生成模型 🦾”</h4>
<h2 id="昆仑万维-2">昆仑万维</h2>
<h3 id="matrix-game-20-交互式世界模型实时生成长序列视频开源">Matrix-Game 2.0 交互式世界模型，实时生成长序列视频（开源）</h3>
<p>Matrix-Game 2.0 是昆仑万维推出并开源的一款交互式世界模型，作为业内首个面向通用场景实现实时长序列交互生成的开源方案，其性能对标尚未公开的 Google Genie 3。</p>
<p>相较于上一版本，Matrix-Game 2.0 侧重于低延迟、高帧率的长序列交互性能。它能够以 25 FPS 的速度稳定生成连续视频内容，生成时长可扩展至分钟级别，大幅提升了连贯性。</p>
<p>用户通过简单指令即可在城市、野外等多种风格场景中进行自由操控与探索，系统将实时生成符合物理逻辑的动态画面。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Skywork/Matrix-Game-2.0）；前往 Github 获取代码（github.com/SkyworkAI/Matrix-Game）。</p>
<p>权威信源：https://matrix-game-v2.github.io | <a href="https://mp.weixin.qq.com/s?__biz=MzI1MzE1NDc3Mg==&amp;mid=2247505931&amp;idx=1&amp;sn=3e622bb56e4dd038d1cf84febe657d72&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/5352120251015223556bp0IhokH.png" />   
    </p>
<h4 id="-相比-google-genie-3缺乏最重要的一个特性对场景的记忆-">&gt; “相比 Google Genie 3，缺乏最重要的一个特性：对场景的记忆 🧠”</h4>
<h2 id="genspark-1">Genspark</h2>
<h3 id="ai-meeting-notes全球首款支持-apple-watch-的一键-ai-会议纪要应用">AI Meeting Notes，全球首款支持 Apple Watch 的一键 AI 会议纪要应用</h3>
<p>AI Meeting Notes 是 Genspark 推出的智能会议纪要功能，用户只需在 Apple Watch 上双击或者在手机 App 里单击，就可以开始录制会议内容，AI 将自动把录音转为全面且专业的会议纪要。</p>
<p>该工具作为可无缝连接 Google 或 Outlook 日历，一键录制会议。会议结束后，系统通过先进 AI 技术分析对话内容、提取关键信息，并在几分钟内自动生成结构化纪要并发送给所有参会人。</p>
<p>使用入口：前往 Apple Watch 体验；或者下载 Genspark iOS / Android 移动端 App。</p>
<p>权威信源：https://mainfunc.ai/blog/genspark_ai_meeting_notes</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9864920251015223556FpqzNXj2.png" />   
    </p>
<h4 id="-genspark-的开发能力令人佩服已经发展为了一个大而全的-agent-产品-">&gt; “Genspark 的开发能力令人佩服，已经发展为了一个大而全的 Agent 产品 ⛓”</h4>
<h2 id="anthropic-1">Anthropic</h2>
<h3 id="claude-上线记忆功能打造更智能的个性化-ai-助手">Claude 上线记忆功能，打造更智能的个性化 AI 助手</h3>
<p>Claude 最新上线的记忆功能，能够自动引用历史聊天记录，省去了用户手动翻阅和搜索历史记录的繁琐操作，使交互更加高效便捷，也显著提升了对话的连续性与个性化体验。</p>
<p>例如，当用户开启新对话时，无需重复提供信息即可从上一次中断处继续交流；同时，系统能够自动保留并运用上下文，使回复更加贴合用户的个性化需求和偏好。</p>
<p>使用入口：前往 Claude 官网体验（claude.ai）。</p>
<p>权威信源：https://x.com/claudeai/status/1954982275453686216</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/91735202510152235561Q8AL4fD.png" />   
    </p>
<h4 id="-claude-终于也有了自己的记忆功能期待看到他们关于记忆的技术分享-">&gt; “Claude 终于也有了自己的记忆功能，期待看到他们关于记忆的技术分享 ⏳”</h4>
<h1 id="8-月-13-日-1">8 月 13 日</h1>
<h2 id="anthropic-2">Anthropic</h2>
<h3 id="claude-sonnet-4-api-支持-1m-token-超长上下文">Claude Sonnet 4 API 支持 1M Token 超长上下文</h3>
<p>Claude Sonnet 4 模型 API 更新后，支持高达 1M Token 超长上下文窗口，较之前增长了 5 倍之多。这一突破使得模型在单次请求中能够处理和理解海量信息，极大地扩展了应用边界。</p>
<p>在代码分析任务中，模型可以加载整个代码库，深入理解项目结构并提出系统性优化建议；在文档综合方面，它可以同时处理数百份法律合同或技术规范，并精准挖掘其内在关联；在构建复杂智能体时，模型能够支持包含数百次工具调用与多步骤的冗长工作流，并始终保持上下文的连贯性与一致性。</p>
<p>使用入口：前往调用 API（console.anthropic.com）。</p>
<p>权威信源：https://www.anthropic.com/news/1m-context</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1384120251015223556twWrpNqy.png" />   
    </p>
<h4 id="-openaiclaude-和-gemini-主流模型上下文都来到了-1m国产厂商们抓紧跟进了-">&gt; “OpenAI、Claude 和 Gemini 主流模型上下文都来到了 1M，国产厂商们抓紧跟进了 💪”</h4>
<h2 id="higgsfield-ai">Higgsfield AI</h2>
<h3 id="draw-to-video-视频生成功能无需文本提示">Draw-to-Video 视频生成功能，无需文本提示</h3>
<p>Higgsfield AI 推出了升级版 Draw-to-Video 功能，用户无需编写提示词，仅通过绘制画面和添加图片，就可以指导 AI 生成视频。</p>
<p>用户只需上传一张初始图片，然后在编辑器通过箭头标注运动轨迹、使用简短文字补充动作说明，或直接插入其他图片（如产品图），AI 会根据这些视觉指令生成连贯的动态视频，实现多种创意效果。</p>
<p>使用入口：前往 Higgsfield 官网体验（higgsfield.ai/create/draw-to-video）。</p>
<p>权威信源：https://higgsfield.ai/posts/2FwbR7GpsE0tbLhlf7VkZw</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9049720251015223556d5GqtarH.png" />   
    </p>
<h4 id="-大胆猜测一下原理应该是使用多模态模型分析画面来生成对应的-i2v-视频提示词而非直接对视频进行编辑-">&gt; “大胆猜测一下，原理应该是使用多模态模型分析画面，来生成对应的 I2V 视频提示词，而非直接对视频进行编辑 🧐”</h4>
<h1 id="8-月-14-日-1">8 月 14 日</h1>
<h2 id="腾讯-3">腾讯</h2>
<h3 id="hunyuan-gamecraft-游戏视频生成工具实时打造动态游戏场景">Hunyuan-GameCraft 游戏视频生成工具，实时打造动态游戏场景</h3>
<p>Hunyuan-GameCraft 是一个高动态、交互式游戏视频生成框架。用户仅需输入一张图片、一段文字描述，并配合键盘方向键进行动作指令，就可以实时生成高清动态的游戏视频。</p>
<p>无论是第一人称跑酷还是第三人称探险，该工具都能带来连贯而沉浸的穿梭体验，有效解决传统游戏内容生产中动作僵硬、场景静态和长期一致性差等难题。</p>
<p>它还支持「边跑边转视角」等复杂操作，能生成动态内容（如 NPC 运动、天气变化），并通过混合历史条件增强记忆，确保长视频中角色与环境的稳定。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/tencent/Hunyuan-GameCraft-1.0）；前往 Github 获取代码（github.com/Tencent-Hunyuan/Hunyuan-GameCraft-1.0）。</p>
<p>权威信源：https://hunyuan-gamecraft.github.io | <a href="https://mp.weixin.qq.com/s?__biz=MzkwODU2OTQyNQ==&amp;mid=2247495473&amp;idx=1&amp;sn=1efac707e1cab62a26d52ec0a5b10f11&amp;scene=21#wechat_redirect">官方介绍</a></p>
<h4 id="-所以对于玩家来说未来的游戏不再是预设好的场景而是不同的平行宇宙-">&gt; “所以对于玩家来说，未来的游戏不再是预设好的场景，而是不同的平行宇宙 🌌”</h4>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6611720251015223556gbvPjGl2.png" />   
    </p>
<h2 id="腾讯-4">腾讯</h2>
<h3 id="元宝全面接入腾讯生态应用实现能力调用数据互通与内容融合">元宝全面接入腾讯生态应用，实现能力调用、数据互通与内容融合</h3>
<p>从今年 3 月份开始，腾讯元宝逐步接入了腾讯文档、腾讯新闻、微信读书、腾讯地图、视频号、QQ 音乐、京东、腾讯视频及腾讯会议等多款腾讯系应用。</p>
<p>此次整合主要体现在三个方面：一是在各应用中直接集成元宝的 AI 能力，提升使用效率；二是实现跨应用数据互联互通，增强用户体验的一致性；三是在元宝的问答结果中直接呈现书籍、地图、视频、音乐等相关内容，使信息获取更加直观便捷。</p>
<ul>
<li>元宝 X 腾讯文档 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247484514&amp;idx=1&amp;sn=a1610aef8681bdbb74287b14928f375a&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 腾讯新闻 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247485753&amp;idx=1&amp;sn=4d88dbb6f98e666136958172ba36c860&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 微信读书/起点读书 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247486193&amp;idx=1&amp;sn=f20bfb3925e723155e50e6696639ff8c&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 腾讯地图 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247486318&amp;idx=1&amp;sn=4ff59effe03bb64969fe3efb0ca79463&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 视频号 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247487105&amp;idx=1&amp;sn=67a9ccd46bddbec8af89672e8beba24c&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X QQ音乐 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247487500&amp;idx=1&amp;sn=86585a814a67590cae7f21a2aeba5b2c&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 京东 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247488442&amp;idx=1&amp;sn=9762eed3cc97ee45352f5d82d01b66b0&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 腾讯视频 | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247488533&amp;idx=1&amp;sn=8790a2e0403832408f04768ff0ae4d0d&amp;scene=21#wechat_redirect">官方介绍</a></li>
<li>元宝 X 腾讯会议！ | <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzY4MjM5MA==&amp;mid=2247488734&amp;idx=1&amp;sn=cbacb1fb8c7b95f43bfdbc47d27a4dd9&amp;scene=21#wechat_redirect">官方介绍</a></li>
</ul>
<p>使用入口：前往 腾讯元宝 官网体验（yuanbao.tencent.com）；或者下载 元宝 桌面客户端或者移动端。</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9413420251015223556kecZBmci.png" />   
    </p>
<h4 id="-元宝在整合腾讯生态的数据和产品-">&gt; “元宝在整合腾讯生态的数据和产品 🧩”</h4>
<h2 id="google-4">Google</h2>
<h3 id="gemini-更新个性化上下文与临时聊天功能增强个性化聊天体验">Gemini 更新「个性化上下文」与「临时聊天」功能，增强个性化聊天体验</h3>
<p>Gemini 更新了 Personal Context（个性化上下文）与 Temporary Chats（临时聊天）功能，目前已默认向 2.5 Pro 用户开启。用户可随时在设置中自主启用或关闭相关功能。</p>
<p>其中，个性化上下文功能允许 Gemini 从先前的对话中学习关键信息和用户偏好，从而提供更贴合个人需求的自然回；临时聊天功能则提供隐私保护模式，该模式下的对话既不会被保存至历史记录，也不会用于模型训练或个性化改进，保障用户隐私。</p>
<p>使用入口：前往 Gemini 官网体验（google.gemini.com）。</p>
<p>权威信源：https://blog.google/products/gemini/temporary-chats-privacy-controls</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1418720251015223557bPlTYqmI.png" />   
    </p>
<h4 id="-个性化上下文本质就是记忆跨会话的记忆已经成为了-chatbot-的标配-">&gt; “个性化上下文本质就是记忆，跨会话的记忆已经成为了 Chatbot 的标配 🔑”</h4>
<h2 id="2025世界人形机器人运动会">2025世界人形机器人运动会</h2>
<h3 id="在北京国家速滑馆举行">在北京国家速滑馆举行</h3>
<p>2025年世界人形机器人运动会于 8 月 14 日至 17 日在北京国家速滑馆举行。本届运动会吸引了来自 16 个国家/地区的 280 支队伍、共计 500 余台人形机器人同场竞技。</p>
<p>赛事涵盖竞技赛、表演赛和场景赛三大类别，既包括田径、足球、自由体操等传统体育项目，也涉及工业、医药、酒店等实际应用场景。</p>
<p>在全部 19 个赛项共 26 枚金牌的争夺中，中国团队表现突出。其中，北京天工队的「具身天工 Ultra」以 21.50 秒的成绩获得 100 米短跑冠军；清华大学天工队在 5 对 5 足球项目中战胜德国队，夺得金牌。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk5MDE4MDg1MQ==&amp;mid=2247485634&amp;idx=1&amp;sn=d8c5c14196edfaa67a599d58f154e2a8&amp;scene=21#wechat_redirect">奖牌榜</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4511320251015223557xhDjpLgl.png" />   
    </p>
<h2 id="美国政府收购英特尔-10-股份">美国政府收购英特尔 10% 股份</h2>
<h3 id="强化本土芯片制造控制权">强化本土芯片制造控制权</h3>
<p>美国政府与英特尔达成一项新协议，将收购英特尔10%的股权，以加强对该公司芯片代工业务的管控，防止这一关键业务在未来被剥离或出售。</p>
<p>根据协议条款，若英特尔在代工业务中的持股比例低于 51%，美国政府有权以每股 20 美元的价格额外收购 5% 的股份。作为协议的一部分，英特尔已收到此前根据美国《芯片与科学法案》授予的 57 亿美元现金拨款。</p>
<p>权威信源：https://techcrunch.com/2025/08/28/trump-administrations-deal-is-structured-to-prevent-intel-from-selling-foundry-unit</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/92532202510152235575XfiCSoK.png" />   
    </p>
<h4 id="-按照政治书上的定义这算是社会主义特色的资本主义-">&gt; “按照政治书上的定义，这算是社会主义特色的资本主义 🤔”</h4>
<h2 id="cohere-1">Cohere</h2>
<h3 id="完成-5-亿美元融资">完成 5 亿美元融资</h3>
<p>Cohere 宣布完成 5 亿美元融资，估值达到 68 亿美元。本轮融资由 Radical Ventures 和 Inovia Capital 领投，AMD、NVIDIA、Salesforce 等现有投资者及新投资者共同参与。</p>
<p>新资金将主要用于加速其智能体平台 North 的发展，该平台整合了 Command 系列生成模型与 Embed 系列检索模型，能帮助企业显著提升任务执行效率。</p>
<p>Cohere 专注于为企业和政府提供以安全为核心的 AI 解决方案，高度重视本地数据控制、合规性及数字主权。</p>
<p>权威信源：https://cohere.com/blog/august-2025-funding-round</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4305020251015223557dChUDgp6.png" />   
    </p>
<h4 id="-cohere-很明显不再只讲大模型的故事了而他们的新故事也受到了资本市场的认可-">&gt; “Cohere 很明显不再只讲大模型的故事了，而他们的新故事也受到了资本市场的认可 💰”</h4>
<h1 id="8-月-15-日-1">8 月 15 日</h1>
<h2 id="阿里巴巴-2">阿里巴巴</h2>
<h3 id="webwatcher-多模态-deep-research-agent开源">WebWatcher 多模态 Deep Research Agent（开源）</h3>
<p>WebWatcher 是阿里巴巴开源的多模态深度研究 Agent，致力于突破传统 Agent 在处理图文混合内容时的能力瓶颈。它强调感知与推理的多模态协同，显著提升了复杂问题下的响应质量与可信度。</p>
<p>通过整合网页浏览、图像搜索、代码解释器与内置 OCR 等多种工具，它能够在面对多步骤、跨模态的复杂研究任务时，自主规划工具调用路径，逐步搜集线索、整合多源信息，并最终生成可靠结论。</p>
<p>使用入口：开源；前往 Github 获取（github.com/Alibaba-NLP/WebAgent）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkxMTYyMTAzNA==&amp;mid=2247497459&amp;idx=1&amp;sn=8ea44bb33730d67101dbca124158ab09&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/8905120251015223557aT3LLver.png" />   
    </p>
<h2 id="anthropic-3">Anthropic</h2>
<h3 id="claude-code-和-claude-双双更新学习模式促进深度理解与技能培养">Claude Code 和 Claude 双双更新学习模式，促进深度理解与技能培养</h3>
<p>Anthropic 为其智能编程助手 Claude Code 推出两项全新功能，用户可以通过输入 /output-style 命令自由切换不同的代码交互风格：</p>
<ul>
<li>Explanatory（解释）：Claude 在编程时会逐步解释推理过程与实现逻辑，帮助用户清晰理解每一步的编写思路；</li>
<li>Learning（学习）：Claude 会鼓励用户亲自完成关键代码片段的编写，以类似结对编程的方式在实践中提升技能。</li>
</ul>
<p>此外，Claude 现已向所有用户开放此前仅教育版可用的 Learning 模式。在该模式下，Claude 将不再这届给出答案，而是通过引导和提示，协助用户自主理解复杂概念、掌握核心知识。</p>
<p>使用入口：前往 Claude Code 官网了解详情（claude.com/product/claude-code）或者前往 Claude 官网体验（claude.ai）。</p>
<p>权威信源：https://docs.anthropic.com/en/docs/claude-code/output-styles</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2604420251015223558Lcvz0dqx.png" />   
    </p>
<h4 id="-vibe-coding-确实需要更好的人机协作的模式-">&gt; “Vibe Coding 确实需要更好的人机协作的模式 👨💻”</h4>
<h2 id="whispers-from-the-sta">Whispers from the Sta</h2>
<h3 id="首款国产-ai-驱动的对话式生存游戏正式上线-steam">首款国产 AI 驱动的对话式生存游戏，正式上线 Steam</h3>
<p>Whispers from the Star（群星低语）是一款对话式生存游戏，已在 Steam 平台正式发售。</p>
<p>游戏中，玩家将扮演一名通讯支援者，与因事故被困于盖亚星球的天体物理学学生 Stella 建立联系。每一次对话选择都将直接影响剧情发展，推动故事走向多重结局。玩家需通过沟通引导 Stella 探索环境、应对危机，共同寻找生存与归家之路。</p>
<p>使用入口：前往 Steam 官网体验（store.steampowered.com/app/3730100）。</p>
<p>权威信源：https://store.steampowered.com/app/3730100/Whispers_from_the_Star</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6126320251015223558rgcM89eI.png" />   
    </p>
<h4 id="-第一款将-llm-应用到游戏里的案例玩过的朋友可以分享下体验么-">&gt; “第一款将 LLM 应用到游戏里的案例，玩过的朋友可以分享下体验么 🎮”</h4>
<h1 id="8-月-18-日-1">8 月 18 日</h1>
<h2 id="nvidia-2">NVIDIA</h2>
<h3 id="nemotron-nano-2-端侧模型兼具高精度与高效率开源">Nemotron Nano 2 端侧模型，兼具高精度与高效率（开源）</h3>
<p>Nemotron Nano 2 是 NVIDIA 推出并开源的一款 9B 参数的小模型，在保持高精度的同时，实现了比同尺寸开源模型高出 6 倍的吞吐量，非常适合 PC 及端侧设备等低延迟应用场景。</p>
<p>此外，模型引入了可配置的思考预算功能，允许开发者根据实际需求调整模型的内部推理量，从而在准确性、吞吐量和成本之间取得平衡，最多可节省 60% 的推理成本。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2）。前往 NVIDIA 官网体验（build.nvidia.com/nvidia/nvidia-nemotron-nano-9b-v2）。</p>
<p>权威信源：https://huggingface.co/blog/nvidia/supercharge-ai-reasoning-with-nemotron-nano-2?nvid=nv-int-tblg-513492%20</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6134420251015223558TrI76skb.png" />   
    </p>
<h4 id="-明显感觉到近期各个公司小模型的发布频率比大模型高多了-">&gt; “明显感觉到，近期各个公司小模型的发布频率，比大模型高多了 🚀”</h4>
<h2 id="meshy-ai">Meshy AI</h2>
<h3 id="meshy-5-新一代模型全方位增强-3d-内容生成与编辑能力">Meshy 5 新一代模型，全方位增强 3D 内容生成与编辑能力</h3>
<p>Meshy 正式推出了新一代 3D 生成模型 Meshy 5，该版本在多个核心方面实现了重要升级，显著提高了生成模型的稳定性、智能化水平与成品质量。</p>
<ul>
<li>材质与贴图：全新 PBR 贴图管线可自动生成金属度、粗糙度和法线贴图，极大增强了模型质感表现。</li>
<li>生成稳定性：模型完整度显著优化，减少了破面、扭曲和悬浮部件等常见问题。</li>
<li>智能工具三件套：A/T Pose 快速生成功能可加速角色绑定；实时贴图编辑支持直接在模型表面修改瑕疵；提示词优化助手帮助新手快速产出高质量模型。</li>
<li>动画库：新增 500+ 角色动画预设，覆盖跑、跳、战斗、休闲等多种动作场景。</li>
<li>对齐优化：支持多视角输入，提升贴图与模型的匹配度，实现更精准完整的 3D 建模。</li>
</ul>
<p>使用入口：前往 Meshy 官网体验（meshy.ai）。</p>
<p>权威信源：https://www.bilibili.com/video/BV1edY4zvEFB</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2850420251015223558zul1K4g5.png" />   
    </p>
<h4 id="-这个月-3d-生成模型不约而同的迎来了小升级-">&gt; “这个月 3D 生成模型不约而同的迎来了小升级 🌋”</h4>
<h2 id="百度文库x百度网盘">百度文库 X 百度网盘</h2>
<h3 id="genflow-20-全球首个全端通用智能体百个专家-agent-协同生成多模态内容">GenFlow 2.0 全球首个全端通用智能体，百个专家 Agent 协同生成多模态内容</h3>
<p>百度文库联合百度网盘推出 GenFlow 2.0，基于自研的 Multi-Agent 基础架构，能够自主理解用户意图并进行任务规划与执行，支持超过 100 个专家智能体并行协作，最终生成包括 PPT、研报、视频与代码在内的多种模态内容。</p>
<p>特别的，用户可以在任务执行过程中随时介入，修改思考内容或上传参考文。而且，它还全面接入了百度生态资源，可以灵活调用网盘资料、地图工具和学术文献，并通过分析用户历史记录，提供更贴合个性化需求的内容生成服务。</p>
<p>使用入口：前往 百度文库 官网体验（wenku.baidu.com/pcactivity/genflowPromotion）；或者前往 百度文库 移动端。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODMwNzE2MA==&amp;mid=2654703804&amp;idx=1&amp;sn=11b5dabd9656739f04bfe3f395cd4f3e&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9165220251015223558X8FVxlgO.png" />   
    </p>
<h2 id="microsoft">Microsoft</h2>
<h3 id="excel-新增-copilot-函数将大模型能力引入电子表格">Excel 新增 COPILOT 函数，将大模型能力引入电子表格</h3>
<p>Excel 新增 =COPILOT() 函数，语法为 =COPILOT(prompt_part1, [context1], &hellip;)  ，用户不仅可以在单元格中输入提示词（prompt），还可以引用其他单元格作为上下文（context），轻松完成文本分析、内容生成、数据分类和创意构想等多种任务。</p>
<p>由于该函数已内置至 Excel 计算引擎，当所引用的数据发生变化时，AI 生成的内容将自动更新，无需手动刷新，大大提高了数据处理的实时性和一致性。此外，=COPILOT() 函数还可以与 IF、LAMBDA 等现有函数无缝结合，进一步扩展了 Excel 在复杂分析和自动化工作流程中的应用能力。</p>
<p>权威信源：https://techcommunity.microsoft.com/blog/microsoft365insiderblog/bring-ai-to-your-formulas-with-the-copilot-function-in-excel/4443487</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4051520251015223558r64eK2pZ.png" />   
    </p>
<h4 id="-把-ai-作为一个函数公式放到-excel-里真是一个既优雅又实用的方案-">&gt; “把 AI 作为一个函数公式放到 Excel 里，真是一个既优雅又实用的方案 💎”</h4>
<h1 id="8-月-19-日-1">8 月 19 日</h1>
<h2 id="jetbrains">JetBrains</h2>
<h3 id="ai-assistant-引入-next-edit-suggestions提供全局性的智能修改建议">AI Assistant 引入 Next Edit Suggestions，提供全局性的智能修改建议</h3>
<p>JetBrains 为其 AI Assistant 引入了新功能 Next Edit Suggestions，超越了传统的单行代码补全能力，能够基于用户最近的编辑行为，智能分析其修改意图，并在同一文件的任意位置推荐代码添加、删除或调整建议。</p>
<p>例如，开发者可在编写某段逻辑后，获得插入辅助方法、更新关联变量名称或调整相关函数调用等全局性修改提示。</p>
<p>这一功能由 JetBrains 自研的 Mellum 模型驱动，目前已在 Java、Kotlin 及 Python 三种语言中以测试版形式率先推出。</p>
<p>使用入口：前往 JetBrains 官网了解详情（jetbrains.com/help/ai-assistant/next-edit-suggestions.html）。</p>
<p>权威信源：https://blog.jetbrains.com/ai/2025/08/introducing-next-edit-suggestions-in-jetbrains-ai-assistant</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/76758202510152235586V3DXhqq.png" />   
    </p>
<h4 id="-跨行的自动补全这种操作更贴近程序员真实的使用习惯-">&gt; “跨行的自动补全，这种操作更贴近程序员真实的使用习惯 👏”</h4>
<h2 id="字节跳动">字节跳动</h2>
<h3 id="飞书多维表格独立版上线支持跨平台集成">飞书多维表格独立版上线，支持跨平台集成</h3>
<p>飞书多维表格现已作为独立产品正式上线，用户无需下载或注册飞书即可直接使用，并支持与各类即时通讯（IM）系统实现跨平台打通。</p>
<p>独立版本延续了全部核心功能，包括仪表盘、工作流、高级权限管理与百万行数据处理能力，可灵活嵌入企业现有协作生态。其内置的 AI 字段捷径与 AI 分析等功能，能够帮助业务人员轻松将人工智能融入日常流程。</p>
<p>使用入口：前往 飞书多维表格 官网体验（base.feishu.cn）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzg4ODI0ODMyOQ==&amp;mid=2247537783&amp;idx=1&amp;sn=420e5a073042e8383d2812df7d804c4c&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504711&amp;idx=1&amp;sn=a55ec87b94ccf9a92aecf39f37ff3b02&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3123820251015223559wODbd9cu.png" />   
    </p>
<h4 id="-飞书表格本质其实不是表格而是个数据库可视化自动化工具-">&gt; “飞书表格本质其实不是表格，而是个数据库可视化+自动化工具 ⚙”</h4>
<h1 id="8-月-20-日-1">8 月 20 日</h1>
<h2 id="tripo">TRIPO</h2>
<h3 id="tripo-30-新一代模型几何精度与纹理质量全面升级">TRIPO 3.0 新一代模型，几何精度与纹理质量全面升级</h3>
<p>TRIPO 3.0 是 TRIPO 系列 3D 生成模型的重大升级版本，其核心在于重新设计了几何与纹理生成管线，提供更锐利的几何体、更清晰的拓扑结构和更丰富的纹理，生成的模型能直接用于专业的设计和动画工作流。</p>
<p>此外，TRIPO 3.0 引入了「标准模式」和「超高清模式」两种输出选项，并集成了 Flux 和 GPT-4o 的多模态能力，支持草图生成 3D 模型、T-Pose 和角色自动绑定与生成。魔法画笔 2.0、智能部件分割以及优化的工作室体验等一系列功能的加入，使模型真正达到可用于生产的水平。</p>
<p>使用入口：前往 TRIPO 官网体验（studio.tripo3d.ai）。</p>
<p>权威信源：https://www.tripo3d.ai/blog/introducing-tripo-new-algorithm3</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9071720251015223559bPcT23qM.png" />   
    </p>
<h4 id="-ai-3d-生成又向工业化落地迈进了一步-">&gt; “AI 3D 生成又向工业化落地迈进了一步 👣”</h4>
<h2 id="智谱-2">智谱</h2>
<h3 id="autoglm-20-手机智能体全球首个可在云端自主运行的通用-agent">AutoGLM 2.0 手机智能体，全球首个可在云端自主运行的通用 Agent</h3>
<p>AutoGLM 2.0 是智谱推出的新一代手机智能体，能够在云端自主操作美团、京东、小红书等数十个高频应用，覆盖生活与办公多种真实场景。</p>
<p>生活中，它可独立完成点外卖、订机票等任务；办公方面，它能实现跨平台信息检索、内容生成、视频制作及社交媒体发布等一系列自动化流程。</p>
<p>该智能体基于 GLM-4.5 与 GLM-4.5V 模型驱动，并创新采用「Agent + 云设备」的新技术范式，通过专属云端手机实现任务处理，完全不占用用户本地设备资源，在执行过程中用户可正常使用手机。</p>
<p>使用入口：前往 AutoGLM 官网下载（autoglm.zhipuai.cn/htdocs/download.html）；或者前往应用商店下载 AutoGLM 移动端。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI3NzQ0Mg==&amp;mid=2247491859&amp;idx=1&amp;sn=565f8a36b879e596c6d369229692647a&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504648&amp;idx=1&amp;sn=27371ced3021d10aa6ee1433904327cd&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7963120251015223559uKIAFXcH.png" />   
    </p>
<h4 id="-操作云电脑的-agent-听多了操作云手机的-agent-是第一次见-">&gt; “操作云电脑的 Agent 听多了，操作云手机的 Agent 是第一次见 🥳”</h4>
<h2 id="macaron">Macaron</h2>
<h3 id="全球首个生活伙伴型智能体贴心生成专属应用">全球首个生活伙伴型智能体，贴心生成专属应用</h3>
<p>Macaron 是一款以哆啦 A 梦为原型的智能陪伴应用，致力于成为用户身边既实用又温暖的生活伙伴。与专注于效率提升的生产力工具不同，Macaron 更关注用户的幸福感与情感需求。</p>
<p>它能够实时响应用户的情绪状态、兴趣偏好和个人愿望，生成高度个性化的工具与解决方案。比如，为学生创建学习计划器，为烹饪爱好者生成入门日记，或根据财务状况定制预算工具。</p>
<p>更特别的是，它会细心记住用户分享的生活细节，并在对话中自然提及，建立起真挚而持续的情感连接。</p>
<p>使用入口：前往 Macaron 官网体验（macaron.im）。</p>
<p>权威信源：https://macaron.im/the-dawn-of-a-life-first-agent-macaron-ai | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504060&amp;idx=1&amp;sn=40dac0453700d8959edf4638be62ee2d&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2271220251015223559Z6RI3bdq.png" />   
    </p>
<h4 id="-ai-陪伴--vibe-coding一种出乎意料的搭配-">&gt; “AI 陪伴 + Vibe Coding，一种出乎意料的搭配 ❗❗”</h4>
<h2 id="腾讯-5">腾讯</h2>
<h3 id="企业微信-50全面融入-ai-能力的办公平台">企业微信 5.0，全面融入 AI 能力的办公平台</h3>
<p>企业微信 5.0 版本以「AI」和「办公」为核心，把 AI 能力深入融入了多个企业办公场景，并推出了专供海外使用的 WeCom。</p>
<ul>
<li>智能搜索：用户通过模糊或口语化的方式提问，AI 能理解其意图并根据用户权限范围内的聊天记录、文档及会议内容，精准定位答案并汇总数据。</li>
<li>智能总结：整合项目相关信息，一键生成总结报告，并支持团队成员协同补充与完善。</li>
<li>智能机器人：企业可以创建智能机器人作为随时可咨询的 AI 同事，还支持团队成员上传更多资料（比如业务 SOP、规章制度、产品介绍、客户案例等），便于组织内部共享和查询。</li>
</ul>
<p>使用入口：前往 企业微信 体验。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzA3NDEyMDgzMw==&amp;mid=2652999642&amp;idx=1&amp;sn=6b93aa930fa624e977dc211150a8f7c9&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4864720251015223559CpgyDmic.png" />   
    </p>
<h4 id="-所有的企业级-im-都在增加-ai-功能可是要把效果做好才能真的让用户用起来-">&gt; “所有的企业级 IM 都在增加 AI 功能，可是要把效果做好，才能真的让用户用起来 ✔”</h4>
<h1 id="8-月-21-日-1">8 月 21 日</h1>
<h2 id="deepseek">DeepSeek</h2>
<h3 id="deepseek-v31-语言模型agent-能力与思考效率提升开源">DeepSeek-V3.1 语言模型，Agent 能力与思考效率提升（开源）</h3>
<p>DeepSeek-V3.1 正式发布，这是一次面向 Agent 时代的重大升级。新版本引入了混合推理架构，使单个模型能同时支持思考模式与非思考模式。</p>
<p>本次升级重点增强了模型的 Agent 能力，显著提升了模型在工具使用与智能体任务中的表现，尤其是在编程智能体（SWE-bench）和搜索智能体（browsecomp）评测中取得了明显进步，大幅领先于之前的版本。</p>
<p>此外，DeepSeek-V3.1 新增了对 Anthropic API 格式的支持，方便开发者将其能力接入 Claude Code 等框架。</p>
<p>使用入口：开源；前往 HugingFace 获取（huggingface.co/deepseek-ai/DeepSeek-V3.1）。前往 DeepSeek 官网体验（chat.deepseek.com）；或者调用 API（platform.deepseek.com）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk0OTYwNzc3NQ==&amp;mid=2247485630&amp;idx=1&amp;sn=2957eed7db6d3ecfc75b1dd18404225d&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504654&amp;idx=1&amp;sn=c9c29fd819504d7fe81f67a4dec360a0&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9569220251015223559xlQ8RUhF.png" />   
    </p>
<h4 id="-deepseek-在-v31-将思考模型和非思考融合了所以应该不会有-r2-了而是-v4-">&gt; “DeepSeek 在 V3.1 将思考模型和非思考融合了，所以应该不会有 R2 了，而是 V4 🧐”</h4>
<h2 id="字节跳动-1">字节跳动</h2>
<h3 id="seed-oss-36b-语言模型原生支持-512k-长上下文开源">Seed-OSS-36B 语言模型，原生支持 512K 长上下文（开源）</h3>
<p>Seed-OSS-36B 是字节跳动 Seed 团队发布的一款大语言模型，专注于长上下文处理、复杂推理及 Agent 任务支持。此次开源了 Base（含合成数据）、Base‑woSyn（不含合成数据）、Instruct（指令微调版）三个版本。</p>
<p>该模型原生支持高达 512K 长上下文，是当前开源模型中最长的上下文窗口；允许用户灵活控制「思考预算」，动态调整推理长度和效率；在推理任务上表现出色，并具备强大的工具使用和问题解决能力。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/ByteDance-Seed/Seed-OSS-36B-Base）；前往 Github 获取代码（github.com/ByteDance-Seed/seed-oss）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzA4NzgzMjA4MQ==&amp;mid=2453475622&amp;idx=1&amp;sn=3d85af96b84242d70cfb26c0487957e2&amp;scene=21&amp;click_id=21#wechat_redirect">媒体报道</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9475620251015223559Up3OXifD.png" />   
    </p>
<h4 id="-在这个小模型都玩-moe-的年代字节这个模型更像是一次技术展示-">&gt; “在这个小模型都玩 MoE 的年代，字节这个模型更像是一次技术展示 💪”</h4>
<h2 id="cursorxlinear">Cursor X Linear</h2>
<h3 id="智能编程助手与项目管理无缝协同实现自动任务处理">智能编程助手与项目管理无缝协同，实现自动任务处理</h3>
<p>Cursor 与项目管理工具 Linear 进行了深度集成，使开发团队能够直接在 Linear 内触发并管理 Cursor 智能体，显著降低处理中低优先级任务的门槛，全面提升开发效率。</p>
<p>用户只需将 Linear issue（如修复 bug 或开发新功能）指派给 @Cursor 或在评论中提及，即可启动后台智能体自动处理该任务。</p>
<p>借助该集成，Cursor 能够自动获取问题详情、评论及相关资料作为上下文，精准执行编程任务。任务完成后，智能体会自动创建 pull request 并更新进度，团队成员可在 Linear 中直接查看和审查代码，形成流畅的开发协作闭环。</p>
<p>使用入口：前往 Cursor 官网了解详情（cursor.com）。</p>
<p>权威信源：https://linear.app/now/how-cursor-integrated-with-linear-for-agents | https://cursor.com/blog/linear</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9962720251015223600xYe5Aph1.png" />   
    </p>
<h4 id="-又是一个集成的案例海外企业-">&gt; “又是一个集成的案例，海外企业 🤝”</h4>
<h2 id="runway">Runway</h2>
<h3 id="game-worlds-交互式叙事体验平台实时生成个性化剧情">Game Worlds 交互式叙事体验平台，实时生成个性化剧情</h3>
<p>Game Worlds 是 Runway 推出的新一代交互式叙事体验平台，标志着游戏行业迈向动态生成式叙事。也就是说，平台里所有游戏的世界构建、角色设定与情节发展均无需预先编写，而是在用户参与过程中即时生成。</p>
<p>目前，用户既可进入多个预设世界进行体验，例如抢劫题材的《最后的得分》与悬疑主题的《雅典娜之泉》，也能自行创建独特的游戏世界。游玩过程中，系统会实时生成图像以增强叙事沉浸感，也支持用户选择传统聊天界面或视觉优先的漫画模式。未来，该平台将整合更丰富的视觉体验和实时视频生成能力。</p>
<p>使用入口：前往 Runway 网站体验（play.runwayml.com）。</p>
<p>权威信源：https://runwayml.com/research/runway-game-worlds</p>
<h4 id="-十年后是不是就不存在电视剧了每个人都是导演-">&gt; “十年后是不是就不存在电视剧了，每个人都是导演 🎥”</h4>
<h2 id="made-by-google-2025">Made  by  Google 2025</h2>
<h3 id="pixel-10-系列-ai-旗舰手机--pixel-watch-4-智能手表--gemini-for-home-智能家居助手">Pixel 10 系列 AI 旗舰手机 &amp;&amp; Pixel Watch 4 智能手表 &amp;&amp; Gemini for Home 智能家居助手</h3>
<p>在 8 月 20 日举办的 Made  by  Google 2025 发布会上，Google 推出了多款深度融合 GenAI 的硬件产品，包括全新旗舰 Pixel 10 系列手机、Pixel Watch 4 智能手表以及面向智能家居的 Gemini for Home 助手等。</p>
<p>Pixel 10 系列搭载 Tensor G5 处理器与 Gemini Nano 端侧模型，集成多项前沿 AI 功能。</p>
<ul>
<li>Gemini Live：升级了音频模型，可识别用户语气并调整回应方式。</li>
<li>Magic Cue：可在 Gmail 和日历等应用中实时提供上下文建议；。</li>
<li>Camera Coach：可辅助构图，帮助用户提升拍摄效果。</li>
<li>Voice Translate：支持通话过程中的实时翻译。</li>
</ul>
<p>权威信源：https://techcrunch.com/2025/08/20/google-doubles-down-on-ai-phones-with-its-pixel-10-series</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9150420251015223600nF6j9Blk.png" />   
    </p>
<h4 id="-gemini-is-watching-you-">&gt; “Gemini is watching you 👓”</h4>
<p>Pixel Watch 4 将 Gemini 助手集成于手表端，用户抬腕即可语音交互。其新增的个人健康教练功能，可基于用户的健康数据主动提供个性化健身与睡眠建议，实现 24/7 全天候腕上健康管理。</p>
<p>权威信源：https://blog.google/products/pixel/pixel-watch-4</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1885720251015223600CQb8V4kE.png" />   
    </p>
<p>Gemini for Home 是一款基于 Gemini 模型的新一代家庭语音助手，具备更强的推理与搜索能力，可智能操控媒体播放、同时执行多项家居指令，并协助管理家庭日历与购物清单。</p>
<p>权威信源：https://blog.google/products/google-nest/gemini-for-home</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7911820251015223600BjgpOCgI.png" />   
    </p>
<h2 id="国务院">国务院</h2>
<h3 id="深入实施人工智能行动的意见">深入实施“人工智能+”行动的意见</h3>
<p>国务院发布《深入实施“人工智能+”行动的意见》，意见明确提出，以 2027 年实现人工智能与实体经济初步深度融合、2030 年基本建成智能化产业链与创新生态、2035 年进入智能经济和智能社会新阶段为总体目标，分六大行动领域推进：</p>
<p>（一）“人工智能+”科学技术</p>
<p>（二）“人工智能+”产业发展</p>
<p>（三）“人工智能+”消费提质</p>
<p>（四）“人工智能+”民生福祉</p>
<p>（五）“人工智能+”治理能力</p>
<p>（六）“人工智能+”全球合作</p>
<p>权威信源：https://www.gov.cn/zhengce/content/202508/content_7037861.htm | <a href="https://mp.weixin.qq.com/s?__biz=MzA4MDA0MzcwMA==&amp;mid=2652715054&amp;idx=1&amp;sn=da45545e14fef96179e6fb8bd951eb88&amp;scene=21#wechat_redirect">官方介绍</a>| <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504805&amp;idx=1&amp;sn=3ed6ba407e82c293a7cb916929493264&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7760720251015223600ovPyJwn1.png" />   
    </p>
<h4 id="-一份可能会改变未来-10-年的文件让所有-ai-从业者为之振奋-">&gt; “一份可能会改变未来 10 年的文件，让所有 AI 从业者为之振奋 💪”</h4>
<h1 id="8-月-22-日-1">8 月 22 日</h1>
<h2 id="dynamics-lab">Dynamics Lab</h2>
<h3 id="mirage-2-实时生成式世界引擎上传图片即可步入其中">Mirage 2 实时生成式世界引擎，上传图片即可步入其中</h3>
<p>Mirage 2 是 Dynamics Lab 开发的一款实时生成式世界引擎，具备通用性和高互动性。</p>
<p>用户只需上传一张图片，就可以将其转换为一个生动且可操作的互动世界，还可以分享链接邀请他人加入并共同游玩。此外，该引擎还支持通过文本输入实时修改世界场景，创造超现实的情景和动态事件。</p>
<p>这种生成式游戏机制突破了传统预设框架，让每位玩家成为世界的共同创造者。尽管在动作控制精度和视觉稳定性方面仍有局限，但它为生成式世界建模的创新开辟了新的可能性。</p>
<p>使用入口：前往 Dynamics Lab 官网体验（demo.dynamicslab.ai/chaos）。</p>
<p>权威信源：https://blog.dynamicslab.ai</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1130520251015223600E73rkDfs.png" />   
    </p>
<h4 id="--mirage-2-比-genie-3-更早实现了可玩性生成式世界模型在这个月也开始井喷-">&gt; “ Mirage 2 比 Genie 3 更早实现了可玩性，生成式世界模型在这个月也开始井喷 🌋”</h4>
<h2 id="深势科技x上海交通大学x上海算法创新院">深势科技 X 上海交通大学 X 上海算法创新院</h2>
<h3 id="scimaster-全球首个通用科研智能体基于-x-master-开源框架打造">SciMaster 全球首个通用科研智能体，基于 X-Master 开源框架打造</h3>
<p>SciMaster 是一款科研智能体，基于通用科学基座大模型 Innovator 构建，目标是成为一位专家级的科研助手。它具备深度调研与复杂问题拆解能力，可灵活调用网络搜索、文献检索等多种工具，自主完成子任务规划与执行，并生成内容翔实的调研报告。</p>
<p>该智能体采用自研的 X-Master 框架，其核心机制在于模拟人类研究者的工作流程，通过「内部推理-工具调用-结果整合-迭代优化」的循环过程进行研究。用户还可以通过思维链编辑功能主动介入其推理逻辑，实现人机协同科研。</p>
<p>使用入口：X-Master 开源；前往 Github 获取代码（github.com/sjtu-sai-agents/X-Master）；论文（arxiv.org/abs/2507.05241）。前往 SciMaster 官网体验（scimaster.bohrium.com）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzI4MzQzNDAxNQ==&amp;mid=2247509973&amp;idx=1&amp;sn=a586259c8dba6219ae699ea28c7c0ff1&amp;scene=21#wechat_redirect">官方介绍-SciMaster</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzYyMTA0MDY5MQ==&amp;mid=2247483697&amp;idx=1&amp;sn=f723e491b869159ea5e4dd31cbd086be&amp;scene=21#wechat_redirect">X-Master</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2593720251015223601ZQixjBeg.png" />   
    </p>
<h2 id="阿里巴巴-3">阿里巴巴</h2>
<h3 id="qoder-智能体编程平台支持-10-万文件检索">Qoder 智能体编程平台，支持 10 万文件检索</h3>
<p>Qoder 是阿里巴巴新推出的一款智能体编程平台，集成了全球顶尖的编程模型，并围绕上下文工程能力进行了深度优化。其内置的代码检索引擎可一次性检索多达 10 万个文件，显著提升对大型代码库的整体分析效率。</p>
<p>Qoder 提供了 Ask Mode（问答）、Agent Mode（智能体）以及全新的 Quest Mode（自主编程）三种核心模式。其中，在 Quest Mode 下，Agent 可以扮演全栈工程师的角色，将模糊的需求转化为清晰的设计规范并独立完成开发，开发者只需在最终阶段验收即可。</p>
<p>使用入口：前往 Qoder 官网下载（qoder.com）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzE5ODI2NzI5Nw==&amp;mid=2247483698&amp;idx=1&amp;sn=d7bc38360731e8da530e5e67ef5ebfa6&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6037220251015223601jZRgVJlX.png" />   
    </p>
<h4 id="-阿里又又又推出了一个-ai-coding-产品为什么不在一个产品上继续打磨呢-">&gt; “阿里又又又推出了一个 AI Coding 产品，为什么不在一个产品上继续打磨呢 ❓”</h4>
<h2 id="metaxmidjourney">Meta X Midjourney</h2>
<h3 id="建立技术合作伙伴关系">建立技术合作伙伴关系</h3>
<p>Meta 宣布与 Midjourney 建立技术合作伙伴关系，Meta 将获得 Midjourney 在图像与视频生成方面的美学技术授权，并将其整合至未来的 AI 模型与产品中。</p>
<p>此次合作属于 Meta 对 Super intelligence 项目重大投资的一部分，旨在提升其生成内容的质量与表现力。Midjourney 作为以高质量视觉生成工具闻名的研究实验室，将继续保持独立运营。</p>
<p>权威信源：https://x.com/alexandr_wang/status/1958983843169673367</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3404920251015223601whO6esil.png" />   
    </p>
<h4 id="-令人意外的是meta-并没有买下-midjourney是不是超预算了-">&gt; “令人意外的是，Meta 并没有买下 Midjourney，是不是超预算了 💸”</h4>
<h1 id="8-月-24-日-1">8 月 24 日</h1>
<h2 id="xai">xAI</h2>
<h3 id="grok-2grok-25基础模型开源预告-grok-3-即将开源">Grok 2（Grok 2.5）基础模型开源，预告 Grok 3 即将开源</h3>
<p>Elon Musk 在社交媒体宣布，xAI 正式开源 Grok 2.5 模型。根据其开源协议，使用者可将其用于非商业及符合规定的商业用途，但禁止用于训练其他基础模型。此外，他还预告 Grok 3 预计将在未来 6 个月内正式开源。</p>
<p>说明：Hugging Face 仓库名与提供给社区下载的文件均为 grok‑2。这是因为 Grok 2.5 只是基于这些权重经过进一步微调、优化后得到的版本，其核心仍然是 Grok 2 模型的权重，所以开源时使用了 grok‑2 这一标识。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/xai-org/grok-2）。</p>
<p>权威信源：https://x.com/elonmusk/status/1959379349322313920</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/4043120251015223601iH3CQThY.png" />   
    </p>
<h4 id="-马斯克的大模型开源进展跟火星移民计划的一样慢悠悠的-">&gt; “马斯克的大模型开源进展，跟火星移民计划的一样慢悠悠的 😅”</h4>
<h1 id="8-月-25-日-1">8 月 25 日</h1>
<h2 id="群核科技">群核科技</h2>
<h3 id="spatiallm-15-空间语言模型--spatialgen-多视角图像生成模型">SpatiallM 1.5 空间语言模型 &amp;&amp; SpatialGen 多视角图像生成模型</h3>
<p>群核科技发布了两款空间大模型：SpatialLM 1.5 和 SpatialGen。</p>
<p>SpatialLM 1.5 是一款空间语言模型，能理解文本指令并输出包含空间结构、物体关系等物理参数的「空间语言」，从而端到端地生成可交互的 3D 场景。其生成的场景富含物理正确的结构化信息，可用于解决机器人训练中数据稀缺的难题。</p>
<p>SpatialGen 是一款基于扩散模型的多视角图像生成模型，能根据文字、参考图和 3D 布局，生成具有时空一致性的多视角图像，并支持生成 3D 高斯场景和渲染漫游视频，让用户能够沉浸式地在生成的场景中自由「穿梭」。</p>
<p>使用入口：SpatialGen 开源；前往 HugingFace 获取模型（huggingface.co/manycore-research/SpatialGen-1.0）；前往 Github 获取代码（github.com/manycore-research/SpatialGen）。SpatialLM 1.5 将在年内以 SpatialLM-Chat 形式完成开源。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzkzNDg3MzExMQ==&amp;mid=2247485087&amp;idx=1&amp;sn=4f1d0fa67d7218c359b3a06204649927&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6419520251015223601YyyOXPdw.jpeg" />   
    </p>
<h2 id="nvidia-3">NVIDIA</h2>
<h3 id="jetson-thor-开发套件为通用机器人解锁实时推理">Jetson Thor 开发套件，为通用机器人解锁实时推理</h3>
<p>NVIDIA 正式推出 Jetson AGX Thor 开发者套件和 Jetson T5000 模块，为通用机器人和物理 AI 解锁实时推理能力。该套件搭载 NVIDIA Blackwell GPU 架构，配备 128GB 内存，AI 算力高达 2070 FP4 TFLOPS，性能较前代 Jetson AGX Orin 提升 7.5 倍。</p>
<p>借助 Blackwell MIG 技术与 14 核 Arm Neoverse-V3AE CPU，Jetson Thor 可高效运行低延迟实时任务，并广泛支持生成式 AI 及视觉-语言-动作模型（如 NVIDIA Isaac GR00T N1.5）。</p>
<p>其完整集成了 NVIDIA AI 软件栈，包括 Isaac for Robots 与 Metropolis for Visual Agents，可以实现从云到端侧的无缝开发体验，推动下一代人形机器人的发展。</p>
<p>权威信源：https://developer.nvidia.com/blog/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9515620251015223601OMgndSlG.png" />   
    </p>
<h4 id="-看参数非常适合跑语言模型期待这个开发套件未来可以变成可以购买的商品-">&gt; “看参数非常适合跑语言模型，期待这个开发套件未来可以变成可以购买的商品 🤖”</h4>
<h2 id="阿里巴巴-4">阿里巴巴</h2>
<h3 id="ai-钉钉-10全面迈入-ai-原生时代重构办公产品的形态">AI 钉钉 1.0，全面迈入 AI 原生时代，重构办公产品的形态</h3>
<p>AI 钉钉 1.0 版本全面升级，标志着钉钉正式迈入 AI 原生时代。该版本重新定义了 AI 时代人的工作交互、信息处理、知识搜索和应用创建方式，并一口气推出了钉钉 One、AI 搜问、AI 表格、AI 听记、智能硬件 DingTalk A1 等 10 余款 AI 产品。</p>
<ul>
<li>钉钉 One：全球首个 Agent 驱动的工作信息流，让工作处理如刷短视频一般高效直观。</li>
<li>AI 搜问：企业 AI 搜索引擎，可基于用户权限精准搜索聊天记录、文档及 CRM 等系统内容，直接生成汇总答案。</li>
<li>AI 表格：升级为应用创建平台，上线了 100+ 覆盖多模态处理能力的字段 Agent，帮助业务人员能轻松创建 AI 应用。</li>
<li>AI 听记：新一代语音智能工具，与智能硬件 DingTalk A1 协同工作，实现了会议纪要的自动生成与智能摘要。</li>
</ul>
<p>使用入口：前往 钉钉 体验。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzU3ODY3MTkzNA==&amp;mid=2247512193&amp;idx=1&amp;sn=0d409ed7ba68156563f10c8c6bb04f1c&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6909120251015223601EoDXbbnI.png" />   
    </p>
<h4 id="-头部的企业-im-都在做-ai可是不知道为什么我在使用中还是会忽略掉这些新功能-">&gt; “头部的企业 IM 都在做 AI，可是不知道为什么，我在使用中还是会忽略掉这些新功能 🙅♀️”</h4>
<h1 id="8-月-26-日-1">8 月 26 日</h1>
<h2 id="面壁智能-1">面壁智能</h2>
<h3 id="minicpm-v-45-端侧多模态模型实现高刷视频理解突破开源">MiniCPM-V 4.5 端侧多模态模型，实现「高刷」视频理解突破（开源）</h3>
<p>MiniCPM-V 4.5 是面壁智能最新开源的多模态旗舰模型。作为行业首个具备「高刷」视频理解能力的多模态模型，它在同等视觉 Token 开销下可接收 6 倍的视频帧数，实现了从看「PPT」到理解「动态画面」的重要跨越。</p>
<p>该模型在 MotionBench 等高刷视频理解榜单，以及图像理解、长视频分析与 OCR 等多个评测中，凭借仅 8B 的参数量达到同规模模型中的 SOTA 水平，部分性能甚至超越 72B 的 Qwen2.5-VL。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/openbmb/MiniCPM-V-4_5）；前往 Github 获取代码（github.com/OpenBMB/MiniCPM-o）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzg3Mzg2MTg2NQ==&amp;mid=2247495651&amp;idx=1&amp;sn=111d2164d92f3104c7170ac69646ab3f&amp;scene=21#wechat_redirect">官方介绍</a> | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504790&amp;idx=1&amp;sn=1d217f1ebabf60e376642aa012bf96eb&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/8070920251015223601jnsE6IkG.png" />   
    </p>
<h4 id="-挺适合本地部署一个用来做视频理解任务然后自动剪辑视频-">&gt; “挺适合本地部署一个用来做视频理解任务，然后自动剪辑视频 🎬”</h4>
<h2 id="characterai-1">Character.AI</h2>
<h3 id="pipsqueak-角色模型显著提升用户参与度与留存率">PipSqueak 角色模型，显著提升用户参与度与留存率</h3>
<p>PipSqueak 是 Character.AI 最新推出的一款角色模型，具备乐观勇敢的鲜明形象和「小身材大能量」的独特设定，能够输出更长篇、更细腻且人设一致性极高的对话内容，在多轮互动中展现出优秀的记忆力和连续性，显著提升了文本生成的质量与沉浸感。</p>
<p>在社区测试中，搭载该模型的用户平均使用时长提升了 22% ，会话数量增长 13% ，轻度用户的留存率也提高了 14% ；这些数据表明，PipSqueak 能够更好地与用户产生共鸣，提供更具吸引力和高质量的互动内容。</p>
<p>为促进开放协作与技术共享，Character.AI 还开源了其核心训练技术 pipeling-sft，一个微调 MoE 大语言模型的可扩展框架，让微调过程更简单、更快速、更稳定。</p>
<p>使用入口：开源；前往 Github 获取 pipeling-sft（github.com/character-ai/pipelining-sft）。前往 Character.AI 官网体验（character.ai/character/BybV9si2/pipsqueak-silly-chaos-creator）。</p>
<p>权威信源：https://blog.character.ai/breaking-news-our-open-source-models-are-a-lot-of-fun | https://blog.character.ai/character-ai-open-sources-pipeling-sft-a-scalable-framework-for-fine-tuning-moe-llms-like-deepseek-v3</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6914620251015223602lQEPkBjS.png" />   
    </p>
<h2 id="ai2">Ai2</h2>
<h3 id="asta-智能体研究助手系统加速科学发现开源">Asta 智能体研究助手系统，加速科学发现（开源）</h3>
<p>Asta 是由艾伦人工智能研究所 (Ai2) 推出的智能体研究助手的完整系统，专为加速科学发现而设计，整个系统由 Asta、AstaBench 和 Asta resources 三个部分组成，目标是通过提供值得信赖且功能强大的 AI 助手来辅助（而非取代）人类研究员。</p>
<p>首次发布的功能包括查找论文、总结文献和分析数据（测试版），未来计划增加实验复现、假设生成等高级技能。</p>
<ul>
<li>Asta 模型专注于科学研究场景，能够对复杂任务进行自主规划、执行与迭代，并确保所有输出可追溯至源头，具备高度的透明度与可复现性。</li>
<li>AstaBench 是一套综合基准测试框架，用于评估与比较科学智能体的能力，推动该领域的透明度和标准化。</li>
<li>Asta resources 是一套为 AI 开发者提供的开源软件组件和工具，帮助他们构建、测试和完善自己的科学 AI 智能体。</li>
</ul>
<p>使用入口：前往 Asta 官网体验（asta.allen.ai/chat）；或者前往获取 AstaBench（allenai.org/asta/bench）；或者前往获取 Asta resources（allenai.org/asta/resources）。</p>
<p>权威信源：https://allenai.org/blog/asta</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/1266920251015223602K202tIqd.png" />   
    </p>
<h2 id="google-5">Google</h2>
<h3 id="gemini-25-flash-image-图像编辑模型角色一致性与创意构图能力增强nano-banana-">Gemini 2.5 Flash Image 图像编辑模型，角色一致性与创意构图能力增强（nano banana 🍌）</h3>
<p>Gemini 2.5 Flash Image（nano banana）是 Gemini 原生图像编辑模型的一次重大升级，显著提升了角色一致性能力，能够在不同姿势、光照与风格中保持人物、宠物或物体的外观高度相似。</p>
<p>该版本引入了多项创新功能，包括将特定艺术风格从一张图像迁移至另一张，支持融合最多三张输入图像的创意元素，并可依据图像内容推断某一时刻之前或之后的情景。</p>
<p>用户能够更轻松地实现换装、更换场景，将多张照片合成，进行多轮编辑，或将某种设计风格应用于其他物体。</p>
<p>使用入口：前往 Google Gemini 官网体验（gemini.google.com）或者下载 Gemini App；或者前往 Google AI Studio 体验（aistudio.google.com）。</p>
<p>权威信源：https://blog.google/products/gemini/updated-image-editing-model | <a href="https://mp.weixin.qq.com/s?__biz=MzkzNDQxOTU2MQ==&amp;mid=2247504963&amp;idx=1&amp;sn=7e6827cef79178cd73116bf28b21f584&amp;scene=21#wechat_redirect">赛博禅心</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2383320251015223602p1Q4uicT.png" />   
    </p>
<h4 id="-这个模型在一致性上又有了新的突破ai-图片编辑不再是玩具而是工具了-">&gt; “这个模型在一致性上又有了新的突破，AI 图片编辑不再是玩具，而是工具了 🎨”</h4>
<h2 id="heygen">HeyGen</h2>
<h3 id="avatar-iv-数字人模型精准复刻真人神态与动作">Avatar IV 数字人模型，精准复刻真人神态与动作</h3>
<p>Avatar IV 是 HeyGen 自主研发并投入应用的数字人模型。用户仅需提供一段短视频，就可以快速生成高度还原本人身体语言、面部表情与表达风格的个人数字分身。</p>
<p>该模型不仅能精准理解并镜像用户细微的动作、自然的情感节奏和全身动态，还可以依据不同脚本类型智能调整表演方式，确保在不同场景中呈现真实、一致的表达效果。借助 Avatar IV，用户无需亲自参与拍摄，即可高效创作出外观、声音和感觉都酷似真人的视频内容。</p>
<p>使用入口：前往 HeyGen 官网体验（heygen.com）。</p>
<p>权威信源：https://help.heygen.com/en/articles/12089286-create-your-first-digital-twin-with-avatar-iv</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/2710820251015223602Z0TdjAo3.png" />   
    </p>
<h4 id="-作为最早做数字人的公司现在的领先幅度已经越来越小-">&gt; “作为最早做数字人的公司，现在的领先幅度已经越来越小 💢”</h4>
<h2 id="sync">sync</h2>
<h3 id="lipsync-2-pro-唇形同步模型支持-4k-高分辨率">lipsync-2-pro 唇形同步模型，支持 4K 高分辨率</h3>
<p>lipsync-2-pro 是目前最先进的视频唇形同步模型，能够对任意视频中的人物语音进行自由编辑，并生成与全新音频完美匹配的唇形动作。</p>
<p>在编辑过程中，它不仅能够保持原始视频的极高还原度，还能保留诸如雀斑、胡须、自然牙齿等细腻面部特征。用户可在几分钟内实现录音室级别的高质量同步效果。</p>
<p>使用入口：前往 sync. 官网体验（sync.so）。</p>
<p>权威信源：https://sync.so/lipsync-2-pro</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3852520251015223602RQX4fJof.png" />   
    </p>
<h2 id="阿里巴巴-5">阿里巴巴</h2>
<h3 id="wan22-s2v-多模态视频生成模型音频驱动生成电影级数字人">Wan2.2-S2V 多模态视频生成模型，音频驱动生成电影级数字人</h3>
<p>Wan2.2-S2V 是通义万相推出的一款多模态视频生成模型，能够通过单张图片和一段音频生成电影级数字人视频，单次生成时长达到分钟级别，整体性能处于行业先进水平。</p>
<p>该模型支持真人、卡通、动物等多种图像类型，兼容肖像、半身及全身等多种画幅，不仅可以实现高度自然的面部表情、精准的唇形同步和流畅的身体动作，还允许用户通过文本 Prompt 对主体动作与背景变化进行细化控制，增强表演效果。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/Wan-AI/Wan2.2-S2V-14B）；前往 Github 获取代码（github.com/Wan-Video/Wan2.2）。前往 通义万相 官网体验（tongyi.aliyun.com/wanxiang/generate）；或者调用 API（bailian.console.aliyun.com/?tab=api#/api/?type=model&amp;url=2978215）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk2NDYyNzEyMw==&amp;mid=2247484188&amp;idx=1&amp;sn=08ee8dfc4f4c88bebb38ceffb630ef12&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/8310720251015223603wNEzggos.png" />   
    </p>
<h4 id="-通义每次开源基本代表这个领域的门槛被真正打下来了-">&gt; “通义每次开源，基本代表这个领域的门槛被真正打下来了 🧱”</h4>
<h2 id="阿里巴巴-6">阿里巴巴</h2>
<h3 id="dingtalk-ai钉钉首款智能硬件支持实时转写与智能总结">DingTalk AI，钉钉首款智能硬件，支持实时转写与智能总结</h3>
<p>AI 钉钉 1.0 正式推出了语音智能工具「AI 听记」及其配套的智能硬件 DingTalk A1，软硬件深度协同，能够将语音实时转写为文本，并基于大模型进行语义分析和智能摘要，自动生成会议纪要。</p>
<ul>
<li>AI 听记内置了 36 类场景模板，适用于会议、采访、咨询等多种场合，同时支持企业自定义设置。</li>
<li>DingTalk A1 搭载 6 麦克风阵列和骨传导技术，实现 8 米超远距离高清拾音，并提供 45 小时续航。此外，它还可以唤起超过 10 种角色的钉钉助理，并与钉钉待办、日程等应用无缝衔接。</li>
</ul>
<p>使用入口：前往 淘宝/天猫 搜索 钉钉官方旗舰店 购买。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=MzA5Mzg0NDIxMg==&amp;mid=2247512717&amp;idx=1&amp;sn=85bf1fc522b1f58dab955f0abf7e9348&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3371420251015223603UbgXPxid.png" />   
    </p>
<h4 id="-又一个-plaud-的竞争对手这次是来自阿里-1">&gt; “又一个 Plaud 的竞争对手，这次是来自阿里 ➕1”</h4>
<h1 id="8-月-27-日-1">8 月 27 日</h1>
<h2 id="爱诗科技-aisphere">爱诗科技 AIsphere</h2>
<h3 id="pixverse-v5-视频生成模型更稳更真更灵动">PixVerse V5 视频生成模型，更稳，更真，更灵动</h3>
<p>PixVerse V5 是爱诗科技新一代的视频生成模型，该版本在动态效果、视觉质量、一致性保持与指令遵循等多个方面实现了综合提升，能够显著改善用户在高频生成场景中的视频表现。</p>
<p>根据独立测评平台 Artificial Analysis 测试结果，PixVerse V5 在图生视频（Image to Video）项目中排名全球前二，在文生视频（Text to Video）项目中位列前三，保持在全球第一梯队。</p>
<p>使用入口：前往 拍我AI 官网体验（pai.video）。</p>
<p>权威信源：<a href="https://mp.weixin.qq.com/s?__biz=Mzk0NzUwNDEwOA==&amp;mid=2247488958&amp;idx=1&amp;sn=cf85ffc8f328d44ce3472dc588c8a933&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3346520251015223603he03zooc.png" />   
    </p>
<h2 id="anthropic-4">Anthropic</h2>
<h3 id="claude-浏览器插件直接在浏览器中执行操作的智能体">Claude 浏览器插件，直接在浏览器中执行操作的智能体</h3>
<p>Claude for Chrome 是一款浏览器插件，让 Claude 直接在浏览器里工作，代表用户执行点击按钮、填写表单等操作。这一功能将 Claude 从传统的聊天界面延伸至整个浏览器环境，从而更无缝地融入用户的工作流，完成管理日历、起草邮件、处理费用报告等任务。</p>
<p>Anthropic 目前面向 1000 名 Max 套餐订阅者优先发布了预览版本，希望通过实际使用反馈进一步完善产品功能，并加强安全和隐私保护措施。</p>
<p>使用入口：前往加入 WaitList（claude.ai/chrome）。</p>
<p>权威信源：https://www.anthropic.com/news/claude-for-chrome</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9000220251015223603aZZnckmS.png" />   
    </p>
<h4 id="-claude-这个浏览器插件会不会直接干掉了那些-ai-浏览器呢-">&gt; “Claude 这个浏览器插件，会不会直接干掉了那些 AI 浏览器呢 ⚡”</h4>
<h2 id="plaud">Plaud</h2>
<h3 id="plaud-note-pro-智能笔记设备再升级智能双模录音与要点标记按钮成亮点">Plaud Note Pro 智能笔记设备再升级，智能双模录音与要点标记按钮成亮点</h3>
<p>Plaud Note Pro 是 Plaud 智能笔记设备的升级版，支持录音、转写和内容摘要，并能在通话录音和现场会议录音之间自动切换。</p>
<p>新版本增加了两个麦克风将拾音范围扩展至 5 米，搭载了一面 1 英寸显示屏，还新增了一个实时标记按钮，用于在录音过程中快速标记关键内容。</p>
<p>配套 App 也将于 10 月份迎来更新，开始支持文本和图片的多模态输入，并允许用户就录制或上传的内容进行提问。</p>
<p>使用入口：前往 Plaud Note Pro 官网了解详情（plaud.ai/pages/plaud-note-pro）。</p>
<p>权威信源：https://www.plaud.ai/pages/plaud-note-pro</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/21010202510152236033eGIl8iL.png" />   
    </p>
<h4 id="-ai-录音笔的原版终于迎来更新但整体看来它并未展现出仿制品更为独特的优势-">&gt; “AI 录音笔的原版终于迎来更新，但整体看来，它并未展现出仿制品更为独特的优势 🙅♀️”</h4>
<h1 id="8-月-28-日-1">8 月 28 日</h1>
<h2 id="microsoft-1">Microsoft</h2>
<h3 id="mai-voice-1-语音生成模型--mai-1-preview-基础模型微软-ai-的独立宣言">MAI-Voice-1 语音生成模型 &amp;&amp; MAI-1-preview 基础模型，微软 AI 的独立宣言</h3>
<p>MAI 发布了两款全链路自研模型 —— MAI-Voice-1 和 MAI-1-preview，实现了从算法、算力到数据的全面自主创新，显著减少了对如 OpenAI 等外部模型的依赖，极大提升了技术自主权。</p>
<ul>
<li>MAI-Voice-1 是一款语音生成模型，在单个 GPU 上不到一秒内生成一分钟的音频，其语音表达自然且情感丰富，是目前最高效的语音系统之一。已作为 Copilot Audio Expressions 在 Copilot Labs 中提供试用。</li>
<li>MAI-1-preview 是微软首个端到端训练的基础模型，主要服务于文本交互场景。目前已在 LMArena 平台上进行公开测试，未来将逐步集成至 Copilot 中处理部分文本生成任务，替代原有依赖 OpenAI GPT 模型的部分功能。</li>
</ul>
<p>使用入口：前往 Copilot Audio Expressions 官网体验 MAI-Voice-1 模型（copilot.microsoft.com/labs/audio-expression）；前往申请 MAI-1-preview 模型 API（forms.microsoft.com/pages/responsepage.aspx?id=v4j5cvGGr0GRqy180BHbRyRliS0ly-JEvgSpwo3yWyhUQkdTQktBUkFaWERHR1JFRjgwMlZUUkQxTC4u&amp;route=shorturl）。</p>
<p>权威信源：https://copilot.microsoft.com/labs/experiments/audio-expression</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7255520251015223603xJJHbTq6.png" />   
    </p>
<h4 id="-microsoft-aimai是微软于-2024-年成立的消费级人工智能事业部致力于整合并推动-copilotbing-和-edge-等面向个人用户的-ai-产品与研发进程">&gt; “Microsoft AI（MAI）是微软于 2024 年成立的消费级人工智能事业部，致力于整合并推动 Copilot、Bing 和 Edge 等面向个人用户的 AI 产品与研发进程。</h4>
<h4 id="该部门于-2024-年-3-月正式成立由前-deepmind-联合创始人inflection-ai-创始人-mustafa-suleyman-担任首任执行副总裁兼首席执行官直接向-satya-nadella-汇报-原来如此">该部门于 2024 年 3 月正式成立，由前 DeepMind 联合创始人、Inflection AI 创始人 Mustafa Suleyman 担任首任执行副总裁兼首席执行官，直接向 Satya Nadella 汇报 （原来如此🧐”</h4>
<h2 id="腾讯-6">腾讯</h2>
<h3 id="hunyuan-foley-视频音效生成模型为无声视频精准配音开源">Hunyuan-Foley 视频音效生成模型，为无声视频精准配音（开源）</h3>
<p>HunyuanVideo-Foley 是一款端到端的视频音效生成模型。能够依据输入的视频内容与相应文本描述，自动生成与之高度匹配的音效，从而弥补了生成视频仅有画面而缺乏声音的短板。</p>
<p>它广泛适配各类题材，包括人物、动物、自然景观等，可同时理解视觉与文本信息，并生成层次丰富、组合多样的复合音效。</p>
<p>使用入口：开源；前往 HugingFace 获取模型（huggingface.co/tencent/HunyuanVideo-Foley）；前往 Github 获取代码（github.com/Tencent-Hunyuan/HunyuanVideo-Foley）。前往 腾讯混元 官网体验（hunyuan.tencent.com/video/en?tabIndex=0）。</p>
<p>权威信源：https://szczesnys.github.io/hunyuanvideo-foley | <a href="https://mp.weixin.qq.com/s?__biz=MzkwODU2OTQyNQ==&amp;mid=2247495869&amp;idx=1&amp;sn=c9b2fac2fed26b6d4402eaa21f98d63d&amp;scene=21#wechat_redirect">官方介绍</a></p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/7273120251015223603SsSWs6gY.png" />   
    </p>
<h4 id="-无法生成人声离-veo3-音效能力还是有很大差距-">&gt; “无法生成人声，离 Veo3 音效能力还是有很大差距 🤙”</h4>
<h2 id="openai-2">OpenAI</h2>
<h3 id="codex-智能编程助手实现跨平台无缝协作">Codex 智能编程助手，实现跨平台无缝协作</h3>
<p>OpenAI 旗下的编程辅助工具 Codex 近日完成重要升级，推出了适用于 VS Code、Cursor 和 Windsurf 的 IDE 插件，并重构了 Codex CLI 命令行工具。</p>
<p>此次更新实现了云端与本地开发环境之间的任务无缝切换，使 Codex 成为一个真正统一的编程智能体。现在，开发者可以在 IDE、终端、云端及 GitHub 等多个平台上流畅使用 Codex 进行协同编码，所有功能均通过用户的 ChatGPT 账户实现互联互通。</p>
<p>使用入口：前往 OpenAI Codex 官网体验（chatgpt.com/codex）。</p>
<p>权威信源：https://developers.openai.com/codex</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/6471220251015223604bAbHhQrn.png" />   
    </p>
<h4 id="-claude-code-太成功了openai-也按耐不住出手了-">&gt; “Claude Code 太成功了，OpenAI 也按耐不住出手了 👊”</h4>
<h2 id="time100-ai-2025">TIME100 AI 2025</h2>
<h3 id="全球人工智能领域最具影响力的百大人物">全球人工智能领域最具影响力的百大人物</h3>
<p>TIME100 AI 2025 是《时代》杂志发布的年度权威榜单，旨在评选全球人工智能领域最具影响力的 100 位人物。</p>
<p>2025 年榜单共分为 Leaders（领袖）、Innovators（创新者）、Shapers（塑造者）和 Thinkers（思想家）四大类别，每类各约 25 人。入选者覆盖人工智能领域的科研、产业、政策及文化等多个层面，全面呈现推动 AI 发展与治理的关键力量。</p>
<p>权威信源：https://time.com/collections/time100-ai-2025</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/9470220251015223604wA2TuEpm.png" />   
    </p>
<h4 id="-梁文锋入选了一日声名遍天下-">&gt; “梁文锋入选了。一日声名遍天下 🔊”</h4>
<h1 id="8-月-29-日-1">8 月 29 日</h1>
<h2 id="xai-1">xAI</h2>
<h3 id="grok-code-fast-1-编程推理模型专为智能体编程优化">Grok Code Fast 1 编程推理模型，专为智能体编程优化</h3>
<p>Grok Code Fast 1 是 xAI 推出的一款推理模型，专为智能体编程工作流设计，有效解决了现有模型在推理和工具调用循环中速度缓慢的问题。</p>
<p>它已熟练掌握包括 grep、终端操作及文件编辑在内的多种常用工具，并特别擅长 TypeScript、Python、Java 和 Rust 等主流编程语言，可独立完成从零构建项目到精准修复错误等多种开发需求。</p>
<p>使用入口：前往调用 API（console.x.ai）。</p>
<p>权威信源：https://x.ai/news/grok-code-fast-1</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3635320251015223604FcIz28gR.png" />   
    </p>
<h4 id="-grok-也迫不及待的加入了-ai-coding-的战场-">&gt; “Grok 也迫不及待的加入了 AI Coding 的战场 👩💻”</h4>
<h2 id="microsoft-2">Microsoft</h2>
<h3 id="copilot-上线深度研究功能自动化研究并生成结构化报告">Copilot 上线深度研究功能，自动化研究并生成结构化报告</h3>
<p>Microsoft Copilot 推出 Deep Research（深度研究）功能，基于先进的推理模型，能够自动从网络获取并分析大量信息，在 5 到 10 分钟内生成一份内容扎实、结构清晰的多页调研报告。报告不仅涵盖关键发现，还提供格式规范的引文，方便用户追溯来源，有效保障信息的准确性与透明度。</p>
<p>使用入口：前往 Microsoft Copilot 官网体验（copilot.microsoft.com/discover）。</p>
<p>权威信源：https://www.microsoft.com/en-us/microsoft-copilot/for-individuals/do-more-with-ai/general-ai/copilot-deep-research-expands-learning</p>
<p>
        <img class="mx-auto" alt="Image" src="https://api.995120.cn/ecgdata/other/2025-10-15/3461520251015223604rHdjL6hY.png" />   
    </p>
<h1 id="8-月-31-日-1">8 月 31 日</h1>
<h2 id="perplexity">Perplexity</h2>
<h3 id="study-mode学习模式个性化引导式学习与进度测验">Study Mode（学习模式），个性化引导式学习与进度测验</h3>
<p>Perplexity 推出了 Study Mode（学习模式），能够根据用户的知识水平，动态调整回答内容与难度，并借助阶段小测验持续追踪用户的掌握进度。</p>
<p>在该模式下，Perplexity 不会直接给出答案，而是提出引导性问题和分步解析，帮助学生自己发现解决方案。此外，学习模式还支持生成专题测验和知识卡片，帮助巩固学科知识点。</p>
<p>使用入口：前往 Perplexity 官网体验（perplexity.ai）。目前向所有已验证学生身份的用户开放。</p>
<p>权威信源：https://www.perplexity.ai/help-center/en/articles/12120542-what-is-study-mode</p>

        </div>

        
<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://index.zshipu.com/ai002/">知识铺</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://index.zshipu.com/ai002/post/20251015/%E6%9C%9F%E5%BE%85%E5%B4%A9%E5%A1%8CGPT-5%E8%BE%93%E7%BB%99%E4%BA%86%E9%A6%99%E8%95%89%E8%B5%9B%E5%8D%9A%E6%9C%88%E5%88%8A-2509/">https://index.zshipu.com/ai002/post/20251015/%E6%9C%9F%E5%BE%85%E5%B4%A9%E5%A1%8CGPT-5%E8%BE%93%E7%BB%99%E4%BA%86%E9%A6%99%E8%95%89%E8%B5%9B%E5%8D%9A%E6%9C%88%E5%88%8A-2509/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
        <li><strong>免责声明：</strong>本页面内容均来源于站内编辑发布，部分信息来源互联网，并不意味着本站赞同其观点或者证实其内容的真实性，如涉及版权等问题，请立即联系客服进行更改或删除，保证您的合法权益。转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。也可以邮件至 sblig@126.com</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/ai002/post/20251015/%E4%BB%80%E4%B9%88%E6%98%AF%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%BC%8F-Perplexity-%E5%B8%AE%E5%8A%A9%E4%B8%AD%E5%BF%83---What-is-Study-Mode-Perplexity-Help-Center/">什么是学习模式？ Perplexity 帮助中心 --- What is Study Mode  Perplexity Help Center --知识铺</a></li>
        
        <li><a href="/ai002/post/20251015/CLI-Agent%E7%A0%94%E7%A9%B6%E7%AC%94%E8%AE%B0%E6%88%91%E4%BB%AC%E8%BF%99%E4%B8%80%E4%BB%A3%E6%83%B3%E5%90%AC%E4%BB%80%E4%B9%88%E9%83%BD%E6%98%AF%E8%87%AA%E5%B7%B1%E7%BC%96%E7%9A%84/">CLI Agent研究笔记——我们这一代想听什么都是自己编的 --知识铺</a></li>
        
        <li><a href="/ai002/post/20251015/AI%E8%B5%84%E8%AE%AF%E6%97%A5%E6%8A%A5-20251014-%E9%80%9A%E4%B9%89%E5%8D%83%E9%97%AE%E5%92%8C%E8%B1%86%E5%8C%85%E6%9C%80%E8%BF%91%E9%83%BD%E6%82%84%E6%82%84%E4%B8%8A%E7%BA%BF%E4%BA%86%E8%AE%B0%E5%BF%86%E5%8A%9F%E8%83%BD%E5%86%85%E6%B5%8B/">AI资讯日报 20251014 通义千问和豆包最近都悄悄上线了记忆功能内测 --知识铺</a></li>
        
        <li><a href="/ai002/post/20251015/Suno-V5%E9%80%9F%E8%AF%84%E6%9B%B4%E5%BC%BA%E4%BA%86%E4%B9%9F%E6%9B%B4%E5%8D%95%E4%BE%9D%E7%BA%AF%E4%BA%86/">Suno V5速评：更强了，也更“单依纯”了。 --知识铺</a></li>
        
        <li><a href="/ai002/post/20251015/%E6%9C%9F%E8%B4%A7Suno-v5%E5%B0%86%E8%87%B3AI%E9%9F%B3%E4%B9%90%E5%88%9B%E4%BD%9C%E8%BF%8E%E6%9D%A5%E4%B8%8B%E4%B8%80%E9%98%B6%E6%AE%B5%E5%8D%87%E7%BA%A7/">期货｜Suno v5将至，AI音乐创作迎来“下一阶段”升级？ --知识铺</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            没有标签
            
        </div>
    </article>
    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "zshipu/zshipu-index"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2025 <a href="https://index.zshipu.com/ai002/">知识铺的博客 By 知识铺</a>
        
        | <a rel="nofollow" target="_blank" href="https://beian.miit.gov.cn/">浙 ICP 备19032823号-1</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/ai002/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://index.zshipu.com/ai002/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://index.zshipu.com/ai002/">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E4%B8%AD%E5%8E%9F%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%93%E9%A2%98%E5%90%8ER1%E6%97%B6%E4%BB%A3DeepSeek%E5%8F%91%E5%B1%95%E7%9A%84%E4%B8%89%E5%A4%A7%E9%98%B6%E6%AE%B5%E8%8A%AF%E7%89%87_%E6%96%B0%E6%B5%AA%E8%B4%A2%E7%BB%8F_%E6%96%B0%E6%B5%AA%E7%BD%91/" title="【中原计算机】人工智能专题：后R1时代，DeepSeek发展的三大阶段芯片_新浪财经_新浪网 --知识铺">【中原计算机】人工智能专题：后R1时代，DeepSeek发展的三大阶段芯片_新浪财经_新浪网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E8%8B%B9%E6%9E%9CCOO%E4%B8%8A%E4%BB%BB%E5%90%8E%E9%A6%96%E6%AC%A1%E5%88%B0%E5%8D%8E%E8%B5%B0%E8%AE%BF%E6%9E%9C%E9%93%BE%E4%B9%9D%E6%88%90%E5%88%B6%E9%80%A0%E9%87%87%E7%94%A8%E5%8F%AF%E5%86%8D%E7%94%9F%E8%83%BD%E6%BA%90%E8%8B%B9%E6%9E%9C_%E6%96%B0%E6%B5%AA%E8%B4%A2%E7%BB%8F_%E6%96%B0%E6%B5%AA%E7%BD%91/" title="苹果COO上任后首次到华走访“果链”，九成制造采用可再生能源苹果_新浪财经_新浪网 --知识铺">苹果COO上任后首次到华走访“果链”，九成制造采用可再生能源苹果_新浪财经_新浪网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E5%AF%B9%E6%A0%87%E8%8B%B9%E6%9E%9C-Vision-Pro%E4%B8%89%E6%98%9F-Project-Moohan-%E6%B7%B7%E5%90%88%E7%8E%B0%E5%AE%9E%E5%A4%B4%E6%98%BE%E5%8F%91%E5%B8%83%E4%BC%9A%E5%AE%9A%E6%A1%A3-10-%E6%9C%88-22-%E6%97%A5%E4%B8%89%E6%98%9F%E8%8B%B9%E6%9E%9C_%E6%96%B0%E6%B5%AA%E7%A7%91%E6%8A%80_%E6%96%B0%E6%B5%AA%E7%BD%91/" title="对标苹果 Vision Pro，三星 Project Moohan 混合现实头显发布会定档 10 月 22 日三星苹果_新浪科技_新浪网 --知识铺">对标苹果 Vision Pro，三星 Project Moohan 混合现实头显发布会定档 10 月 22 日三星苹果_新浪科技_新浪网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E4%B8%89%E6%98%9FProject-Moohan%E6%B7%B7%E5%90%88%E7%8E%B0%E5%AE%9E%E5%A4%B4%E6%98%BE%E5%8F%91%E5%B8%83%E4%BC%9A%E5%AE%9A%E6%A1%A310%E6%9C%8822%E6%97%A5_%E5%87%A4%E5%87%B0%E7%BD%91/" title="三星Project Moohan混合现实头显发布会定档10月22日_凤凰网 --知识铺">三星Project Moohan混合现实头显发布会定档10月22日_凤凰网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E4%B8%89%E6%98%9F%E5%AE%A3%E5%B8%83%E4%B8%8B%E5%91%A8%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0Galaxy-XR%E5%A4%B4%E6%98%BE%E8%AE%BE%E5%A4%87%E4%B8%89%E6%98%9Fgalaxy%E4%B8%89%E6%98%9F%E7%94%B5%E5%AD%90_%E6%96%B0%E6%B5%AA%E7%A7%91%E6%8A%80_%E6%96%B0%E6%B5%AA%E7%BD%91/" title="三星宣布下周发布全新Galaxy XR头显设备三星galaxy三星电子_新浪科技_新浪网 --知识铺">三星宣布下周发布全新Galaxy XR头显设备三星galaxy三星电子_新浪科技_新浪网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E4%B8%89%E6%98%9F%E5%B0%86%E4%BA%8E10%E6%9C%8821%E6%97%A5%E5%8F%91%E5%B8%83Project-Moohan-XR%E5%A4%B4%E6%98%BE/" title="三星将于10月21日发布Project Moohan XR头显 --知识铺">三星将于10月21日发布Project Moohan XR头显 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/WPP%E4%B8%8E%E8%B0%B7%E6%AD%8C%E8%BE%BE%E6%88%904%E4%BA%BF%E7%BE%8E%E5%85%83AI%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B4%E5%85%B3%E7%B3%BB/" title="WPP与谷歌达成4亿美元AI合作伙伴关系 --知识铺">WPP与谷歌达成4亿美元AI合作伙伴关系 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E8%B1%AA%E4%BC%8A%E7%89%B9%E6%8F%90%E5%87%BA%E7%9B%91%E7%AE%A1AI%E7%9A%84%E7%90%86%E7%94%B1%E5%92%8C%E6%A0%B8%E5%BF%83%E8%AE%BA%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88/" title="豪伊特提出监管AI的理由和核心论点是什么 --知识铺">豪伊特提出监管AI的理由和核心论点是什么 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E8%AF%BA%E8%B4%9D%E5%B0%94%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%AE%B6%E8%B1%AA%E4%BC%8A%E7%89%B9%E5%9B%A0%E6%8B%85%E5%BF%A7%E5%A4%B1%E4%B8%9A%E9%97%AE%E9%A2%98%E5%91%BC%E5%90%81%E7%9B%91%E7%AE%A1%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="诺贝尔经济学家豪伊特因担忧失业问题呼吁监管人工智能 --知识铺">诺贝尔经济学家豪伊特因担忧失业问题呼吁监管人工智能 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20251015/%E8%8B%B9%E6%9E%9CM5%E8%8A%AF%E7%89%87%E5%8F%91%E5%B8%83AI%E6%80%A7%E8%83%BD%E7%8B%82%E9%A3%994%E5%80%8D%E4%B8%89%E5%A4%A7%E8%AE%BE%E5%A4%87%E9%A6%96%E5%8F%91%E9%A2%84%E8%AE%A2_%E6%89%8B%E6%9C%BA%E6%96%B0%E6%B5%AA%E7%BD%91/" title="苹果M5芯片发布：AI性能狂飙4倍，三大设备首发预订_手机新浪网 --知识铺">苹果M5芯片发布：AI性能狂飙4倍，三大设备首发预订_手机新浪网 --知识铺</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【2019双12】ALL IN CLoud 低至1折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1_rYHo7P2gK0jSZPxXXacQpXa-690-388.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="助力产业智慧升级，云服务器首年88元起，更有千元代金券礼包免费领！" target="_blank" style="color:red">
                
                    <img src="https://upload-dianshi-1255598498.file.myqcloud.com/345-7c71532bd4935fbdd9a67c1a71e577b1767b805c.200%E7%89%88%E6%9C%ACB.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【渠道专享低折扣】11月特惠 限时2折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1hblJl7Y2gK0jSZFgXXc5OFXa-750-400.jpg">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title"><a href='/ai002/categories/'>分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/ai002/tags/'>标签</a></h3>
<div class="tagcloud">
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://blog.zshipu.com//" title="知识铺的博客">知识铺的博客</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://index.zshipu.com/ai002/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>