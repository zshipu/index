<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>概述 - LangChain 框架 (4) --知识铺 | 知识铺的博客</title>
    <meta property="og:title" content="概述 - LangChain 框架 (4) --知识铺 - 知识铺的博客">
    <meta property="og:type" content="article">
    
    <meta property="article:published_time" content='2026-01-08T09:02:08&#43;08:00'>
    
    
    <meta property="article:modified_time" content='2026-01-08T09:02:08&#43;08:00'>
    
    <meta name="Keywords" content="golang,go语言,go语言笔记,知识铺,java,android,博客,项目管理,python,软件架构,公众号,小程序">
    <meta name="description" content="概述 - LangChain 框架 (4) --知识铺">
    
    <meta name="author" content="知识铺">
    <meta property="og:url" content="https://index.zshipu.com/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-4/">
    <link rel="shortcut icon" href='/ai002/favicon.ico' type="image/x-icon">

    <link rel="stylesheet" href='/ai002/css/normalize.css'>
    <link rel="stylesheet" href='/ai002/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    <script data-ad-client="ca-pub-2874221941555456" async
        src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    

    

    
    
    
    <script>(function (w, d, s, l, i) {
            w[l] = w[l] || []; w[l].push({
                'gtm.start':
                    new Date().getTime(), event: 'gtm.js'
            }); var f = d.getElementsByTagName(s)[0],
                j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
                    'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-WLWJSST');</script>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BY5XJ2PJ93"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-BY5XJ2PJ93');
    </script>
    
</head>

<body>

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WLWJSST"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://index.zshipu.com/ai002">
                        知识铺的博客
                    </a>
                
                <p class="description">专注于Android、Java、Go语言(golang)、移动互联网、项目管理、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://index.zshipu.com/ai002">首页</a>
                    
                    <a  href="https://index.zshipu.com/ai001/" title="AI技术">AI技术</a>
                    
                    <a  href="https://index.zshipu.com" title="总站">总站</a>
                    
                    <a  href="https://index.zshipu.com/ai002/archives/" title="归档">归档</a>
                    
                    <a  href="https://index.zshipu.com/ai002/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#内存httpslanggraphcomcnconceptsmemory1htmlmemory-permanent-link">内存<a href="https://langgraph.com.cn/concepts/memory.1.html#memory" title="Permanent link">¶</a></a></li>
    <li><a href="#什么是内存httpslanggraphcomcnconceptsmemory1htmlwhat-is-memory-permanent-link">什么是内存？<a href="https://langgraph.com.cn/concepts/memory.1.html#what-is-memory" title="Permanent link">¶</a></a></li>
    <li><a href="#短期记忆httpslanggraphcomcnconceptsmemory1htmlshort-term-memory-permanent-link">短期记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#short-term-memory" title="Permanent link">¶</a></a>
      <ul>
        <li><a href="#管理长对话历史记录httpslanggraphcomcnconceptsmemory1htmlmanaging-long-conversation-history-permanent-link">管理长对话历史记录<a href="https://langgraph.com.cn/concepts/memory.1.html#managing-long-conversation-history" title="Permanent link">¶</a></a></li>
        <li><a href="#编辑消息列表httpslanggraphcomcnconceptsmemory1htmlediting-message-lists-permanent-link">编辑消息列表<a href="https://langgraph.com.cn/concepts/memory.1.html#editing-message-lists" title="Permanent link">¶</a></a></li>
        <li><a href="#总结过往对话httpslanggraphcomcnconceptsmemory1htmlsummarizing-past-conversations-permanent-link">总结过往对话<a href="https://langgraph.com.cn/concepts/memory.1.html#summarizing-past-conversations" title="Permanent link">¶</a></a></li>
        <li><a href="#知道何时移除消息httpslanggraphcomcnconceptsmemory1htmlknowing-when-to-remove-messages-permanent-link">知道<strong>何时</strong>移除消息<a href="https://langgraph.com.cn/concepts/memory.1.html#knowing-when-to-remove-messages" title="Permanent link">¶</a></a></li>
      </ul>
    </li>
    <li><a href="#长期记忆httpslanggraphcomcnconceptsmemory1htmllong-term-memory-permanent-link">长期记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#long-term-memory" title="Permanent link">¶</a></a>
      <ul>
        <li><a href="#存储记忆httpslanggraphcomcnconceptsmemory1htmlstoring-memories-permanent-link">存储记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#storing-memories" title="Permanent link">¶</a></a></li>
        <li><a href="#长期记忆的思考框架httpslanggraphcomcnconceptsmemory1htmlframework-for-thinking-about-long-term-memory-permanent-link">长期记忆的思考框架<a href="https://langgraph.com.cn/concepts/memory.1.html#framework-for-thinking-about-long-term-memory" title="Permanent link">¶</a></a></li>
      </ul>
    </li>
    <li><a href="#记忆类型httpslanggraphcomcnconceptsmemory1htmlmemory-types-permanent-link">记忆类型<a href="https://langgraph.com.cn/concepts/memory.1.html#memory-types" title="Permanent link">¶</a></a>
      <ul>
        <li><a href="#语义记忆httpslanggraphcomcnconceptsmemory1htmlsemantic-memory-permanent-link">语义记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#semantic-memory" title="Permanent link">¶</a></a></li>
        <li><a href="#情景记忆httpslanggraphcomcnconceptsmemory1htmlepisodic-memory-permanent-link">情景记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#episodic-memory" title="Permanent link">¶</a></a></li>
        <li><a href="#程序记忆httpslanggraphcomcnconceptsmemory1htmlprocedural-memory-permanent-link">程序记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#procedural-memory" title="Permanent link">¶</a></a></li>
      </ul>
    </li>
    <li><a href="#写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-permanent-link">写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories" title="Permanent link">¶</a></a>
      <ul>
        <li><a href="#在热路径中写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-in-the-hot-path-permanent-link">在热路径中写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories-in-the-hot-path" title="Permanent link">¶</a></a></li>
        <li><a href="#在后台写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-in-the-background-permanent-link">在后台写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories-in-the-background" title="Permanent link">¶</a></a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">概述 - LangChain 框架 (4) --知识铺</h1>
        </header>
        <date class="post-meta meta-date">
            2026年1月8日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <p><a href="https://github.com/langchain-ai/langgraph/edit/main/docs/docs/concepts/memory.md" title="Edit this page"></a></p>
<h2 id="内存httpslanggraphcomcnconceptsmemory1htmlmemory-permanent-link">内存<a href="https://langgraph.com.cn/concepts/memory.1.html#memory" title="Permanent link">¶</a></h2>
<h2 id="什么是内存httpslanggraphcomcnconceptsmemory1htmlwhat-is-memory-permanent-link">什么是内存？<a href="https://langgraph.com.cn/concepts/memory.1.html#what-is-memory" title="Permanent link">¶</a></h2>
<p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10410470/">内存</a>是一种认知功能，它使人们能够存储、检索和使用信息来理解他们的现在和未来。想想看，与一个总是忘记你告诉他们的事情、需要不断重复的同事共事是多么令人沮丧！随着AI代理承担涉及大量用户交互的更复杂任务，为它们配备内存对于效率和用户满意度同样至关重要。通过内存，代理可以从反馈中学习并适应用户的偏好。本指南涵盖了基于召回范围的两种内存类型</p>
<p><strong>短期记忆</strong>，或<a href="https://langgraph.com.cn/concepts/persistence.1.html#threads">线程</a>范围的记忆，可以随时<strong>从</strong>单个用户对话线程中召回。LangGraph将短期记忆作为代理<a href="https://langgraph.com.cn/concepts/low_level.1.html#state">状态</a>的一部分进行管理。状态通过<a href="https://langgraph.com.cn/concepts/persistence.1.html#checkpoints">检查点</a>持久化到数据库中，以便线程可以随时恢复。短期记忆在图被调用或步骤完成时更新，并在每个步骤开始时读取状态。</p>
<p><strong>长期记忆</strong>在对话线程<strong>之间共享</strong>。它可以在_任何时候_和<strong>任何线程中</strong>召回。记忆可以限定在任何自定义命名空间，而不仅仅是单个线程ID。LangGraph提供<a href="https://langgraph.com.cn/concepts/persistence.1.html#memory-store">存储</a>（<a href="https://langgraph.com.cn/reference/store/index.html#langgraph.store.base.BaseStore">参考文档</a>）来让你保存和召回长期记忆。</p>
<p>这两种记忆对于你的应用程序都非常重要，需要理解并实现。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/1710120260108160849omhhgtkt.png" />   
    </p>
<h2 id="短期记忆httpslanggraphcomcnconceptsmemory1htmlshort-term-memory-permanent-link">短期记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#short-term-memory" title="Permanent link">¶</a></h2>
<p>短期记忆允许你的应用程序记住单个<a href="https://langgraph.com.cn/concepts/persistence.1.html#threads">线程</a>或对话中的先前交互。<a href="https://langgraph.com.cn/concepts/persistence.1.html#threads">线程</a>在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。</p>
<p>LangGraph将短期记忆作为代理状态的一部分进行管理，通过线程范围的检查点持久化。这种状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。</p>
<p>由于对话历史是表示短期记忆最常见的形式，在下一节中，我们将介绍在消息列表变得<strong>很长</strong>时管理对话历史的技术。如果你想坚持高层概念，请继续阅读<a href="https://langgraph.com.cn/concepts/memory.1.html#long-term-memory">长期记忆</a>部分。</p>
<h3 id="管理长对话历史记录httpslanggraphcomcnconceptsmemory1htmlmanaging-long-conversation-history-permanent-link">管理长对话历史记录<a href="https://langgraph.com.cn/concepts/memory.1.html#managing-long-conversation-history" title="Permanent link">¶</a></h3>
<p>长对话对当今的LLM构成了挑战。完整的历史记录甚至可能无法完全放入LLM的上下文窗口中，导致不可恢复的错误。即使你的LLM技术上支持完整的上下文长度，大多数LLM在长上下文下表现仍然不佳。它们会被过时或偏离主题的内容“分散注意力”，同时响应时间变慢，成本也更高。</p>
<p>管理短期记忆是平衡<a href="https://en.wikipedia.org/wiki/Precision_and_recall#:~:text=Precision%20can%20be%20seen%20as,irrelevant%20ones%20are%20also%20returned">精确度与召回率</a>与应用程序其他性能要求（延迟和成本）之间的练习。一如既往，批判性地思考如何为你的LLM表示信息并查看你的数据非常重要。我们将在下面介绍一些管理消息列表的常用技术，并希望为你提供足够的上下文，以便你为应用程序选择最佳的权衡方案</p>
<ul>
<li><a href="https://langgraph.com.cn/concepts/memory.1.html#editing-message-lists">编辑消息列表</a>：如何考虑在传递给语言模型之前修剪和过滤消息列表。</li>
<li><a href="https://langgraph.com.cn/concepts/memory.1.html#summarizing-past-conversations">总结过往对话</a>：当你不仅仅想过滤消息列表时，一种常用的技术。</li>
</ul>
<h3 id="编辑消息列表httpslanggraphcomcnconceptsmemory1htmlediting-message-lists-permanent-link">编辑消息列表<a href="https://langgraph.com.cn/concepts/memory.1.html#editing-message-lists" title="Permanent link">¶</a></h3>
<p>聊天模型使用<a href="https://python.langchain.ac.cn/docs/concepts/#messages">消息</a>接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限，并且包含大量token的消息列表可能成本高昂，许多应用程序可以通过使用手动删除或忘记过时信息的技术而受益。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/8823420260108160850YqpvMijY.png" />   
    </p>
<p>最直接的方法是从列表中删除旧消息（类似于<a href="https://en.wikipedia.org/wiki/Page_replacement_algorithm#Least_recently_used">最近最少使用缓存</a>）。</p>
<p>在LangGraph中，从列表中删除内容的典型技术是从节点返回一个更新，告诉系统删除列表的某些部分。你可以定义这种更新的样式，但一种常见的方法是让你返回一个对象或字典，指定要保留哪些值。</p>
<pre tabindex="0"><code>&lt;span id=&#34;__span-0-1&#34;&gt;def manage_list(existing: list, updates: Union[list, dict]):
&lt;span id=&#34;__span-0-2&#34;&gt;    if isinstance(updates, list):
&lt;span id=&#34;__span-0-3&#34;&gt;        # Normal case, add to the history
&lt;span id=&#34;__span-0-4&#34;&gt;        return existing + updates
&lt;span id=&#34;__span-0-5&#34;&gt;    elif isinstance(updates, dict) and updates[&#34;type&#34;] == &#34;keep&#34;:
&lt;span id=&#34;__span-0-6&#34;&gt;        # You get to decide what this looks like.
&lt;span id=&#34;__span-0-7&#34;&gt;        # For example, you could simplify and just accept a string &#34;DELETE&#34;
&lt;span id=&#34;__span-0-8&#34;&gt;        # and clear the entire list.
&lt;span id=&#34;__span-0-9&#34;&gt;        return existing[updates[&#34;from&#34;]:updates[&#34;to&#34;]]
&lt;span id=&#34;__span-0-10&#34;&gt;    # etc. We define how to interpret updates
&lt;span id=&#34;__span-0-11&#34;&gt;
&lt;span id=&#34;__span-0-12&#34;&gt;class State(TypedDict):
&lt;span id=&#34;__span-0-13&#34;&gt;    my_list: Annotated[list, manage_list]
&lt;span id=&#34;__span-0-14&#34;&gt;
&lt;span id=&#34;__span-0-15&#34;&gt;def my_node(state: State):
&lt;span id=&#34;__span-0-16&#34;&gt;    return {
&lt;span id=&#34;__span-0-17&#34;&gt;        # We return an update for the field &#34;my_list&#34; saying to
&lt;span id=&#34;__span-0-18&#34;&gt;        # keep only values from index -5 to the end (deleting the rest)
&lt;span id=&#34;__span-0-19&#34;&gt;        &#34;my_list&#34;: {&#34;type&#34;: &#34;keep&#34;, &#34;from&#34;: -5, &#34;to&#34;: None}
&lt;span id=&#34;__span-0-20&#34;&gt;    }
</code></pre><p>只要在&quot;my_list&quot;键下返回更新，LangGraph就会调用<code>manage_list</code> &ldquo;<a href="https://langgraph.com.cn/concepts/low_level.1.html#reducers">reducer</a>&ldquo;函数。在该函数中，我们定义接受哪些类型的更新。通常，消息会被添加到现有列表中（对话会增长）；但是，我们也添加了对接受字典的支持，该字典允许你&quot;保留&quot;状态的某些部分。这允许你通过编程方式删除旧的消息上下文。</p>
<p>另一种常见的方法是让你返回一个“移除”对象的列表，该列表指定要删除的所有消息的ID。如果你在LangGraph中使用LangChain消息和<a href="https://langgraph.com.cn/reference/graphs/index.html#langgraph.graph.message.add_messages"><code>add_messages</code></a> reducer（或<code>MessagesState</code>，它使用相同的基础功能），你可以使用<code>RemoveMessage</code>来完成此操作。</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->API参考：<!-- raw HTML omitted -->RemoveMessage<!-- raw HTML omitted --> | <!-- raw HTML omitted -->AIMessage<!-- raw HTML omitted --> | <!-- raw HTML omitted -->add_messages<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<pre tabindex="0"><code>&lt;code tabindex=&#34;0&#34;&gt;&lt;span id=&#34;__span-1-1&#34;&gt;from langchain_core.messages import RemoveMessage, AIMessage
&lt;span id=&#34;__span-1-2&#34;&gt;from langgraph.graph import add_messages
&lt;span id=&#34;__span-1-3&#34;&gt;# ... other imports
&lt;span id=&#34;__span-1-4&#34;&gt;
&lt;span id=&#34;__span-1-5&#34;&gt;class State(TypedDict):
&lt;span id=&#34;__span-1-6&#34;&gt;    # add_messages will default to upserting messages by ID to the existing list
&lt;span id=&#34;__span-1-7&#34;&gt;    # if a RemoveMessage is returned, it will delete the message in the list by ID
&lt;span id=&#34;__span-1-8&#34;&gt;    messages: Annotated[list, add_messages]
&lt;span id=&#34;__span-1-9&#34;&gt;
&lt;span id=&#34;__span-1-10&#34;&gt;def my_node_1(state: State):
&lt;span id=&#34;__span-1-11&#34;&gt;    # Add an AI message to the `messages` list in the state
&lt;span id=&#34;__span-1-12&#34;&gt;    return {&#34;messages&#34;: [AIMessage(content=&#34;Hi&#34;)]}
&lt;span id=&#34;__span-1-13&#34;&gt;
&lt;span id=&#34;__span-1-14&#34;&gt;def my_node_2(state: State):
&lt;span id=&#34;__span-1-15&#34;&gt;    # Delete all but the last 2 messages from the `messages` list in the state
&lt;span id=&#34;__span-1-16&#34;&gt;    delete_messages = [RemoveMessage(id=m.id) for m in state[&#39;messages&#39;][:-2]]
&lt;span id=&#34;__span-1-17&#34;&gt;    return {&#34;messages&#34;: delete_messages}
</code></pre><p>在上面的示例中，<code>add_messages</code> reducer允许我们将新消息<a href="https://langgraph.com.cn/concepts/low_level.1.html#serialization">追加</a>到<code>messages</code>状态键，如<code>my_node_1</code>中所示。当它看到一个<code>RemoveMessage</code>时，它将从列表中删除该ID的消息（然后<code>RemoveMessage</code>将被丢弃）。有关LangChain特定消息处理的更多信息，请查看<a href="https://langgraph.com.cn/how-tos/memory/delete-messages/index.html">此关于使用<code>RemoveMessage</code>的操作指南</a>。</p>
<p>有关示例用法，请参阅此操作<a href="https://langgraph.com.cn/how-tos/memory/manage-conversation-history/index.html">指南</a>以及我们<a href="https://github.com/langchain-ai/langchain-academy/tree/main/module-2">LangChain Academy</a>课程的模块2。</p>
<h3 id="总结过往对话httpslanggraphcomcnconceptsmemory1htmlsummarizing-past-conversations-permanent-link">总结过往对话<a href="https://langgraph.com.cn/concepts/memory.1.html#summarizing-past-conversations" title="Permanent link">¶</a></h3>
<p>如上所示，修剪或移除消息的问题在于，我们可能会因为消息队列的淘汰而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/6179220260108160850MO1X1dd1.png" />   
    </p>
<p>可以使用简单的提示和编排逻辑来实现此目的。例如，在LangGraph中，我们可以扩展<a href="https://langgraph.com.cn/concepts/low_level.1.html#working-with-messages-in-graph-state">MessagesState</a>以包含一个<code>summary</code>键。</p>
<pre tabindex="0"><code>&lt;span id=&#34;__span-2-1&#34;&gt;from langgraph.graph import MessagesState
&lt;span id=&#34;__span-2-2&#34;&gt;class State(MessagesState):
&lt;span id=&#34;__span-2-3&#34;&gt;    summary: str
</code></pre><p>然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。这个<code>summarize_conversation</code>节点可以在<code>messages</code>状态键中积累一定数量的消息后被调用。</p>
<pre tabindex="0"><code>&lt;span id=&#34;__span-3-1&#34;&gt;def summarize_conversation(state: State):
&lt;span id=&#34;__span-3-2&#34;&gt;
&lt;span id=&#34;__span-3-3&#34;&gt;    # First, we get any existing summary
&lt;span id=&#34;__span-3-4&#34;&gt;    summary = state.get(&#34;summary&#34;, &#34;&#34;)
&lt;span id=&#34;__span-3-5&#34;&gt;
&lt;span id=&#34;__span-3-6&#34;&gt;    # Create our summarization prompt
&lt;span id=&#34;__span-3-7&#34;&gt;    if summary:
&lt;span id=&#34;__span-3-8&#34;&gt;
&lt;span id=&#34;__span-3-9&#34;&gt;        # A summary already exists
&lt;span id=&#34;__span-3-10&#34;&gt;        summary_message = (
&lt;span id=&#34;__span-3-11&#34;&gt;            f&#34;This is a summary of the conversation to date: {summary}\n\n&#34;
&lt;span id=&#34;__span-3-12&#34;&gt;            &#34;Extend the summary by taking into account the new messages above:&#34;
&lt;span id=&#34;__span-3-13&#34;&gt;        )
&lt;span id=&#34;__span-3-14&#34;&gt;
&lt;span id=&#34;__span-3-15&#34;&gt;    else:
&lt;span id=&#34;__span-3-16&#34;&gt;        summary_message = &#34;Create a summary of the conversation above:&#34;
&lt;span id=&#34;__span-3-17&#34;&gt;
&lt;span id=&#34;__span-3-18&#34;&gt;    # Add prompt to our history
&lt;span id=&#34;__span-3-19&#34;&gt;    messages = state[&#34;messages&#34;] + [HumanMessage(content=summary_message)]
&lt;span id=&#34;__span-3-20&#34;&gt;    response = model.invoke(messages)
&lt;span id=&#34;__span-3-21&#34;&gt;
&lt;span id=&#34;__span-3-22&#34;&gt;    # Delete all but the 2 most recent messages
&lt;span id=&#34;__span-3-23&#34;&gt;    delete_messages = [RemoveMessage(id=m.id) for m in state[&#34;messages&#34;][:-2]]
&lt;span id=&#34;__span-3-24&#34;&gt;    return {&#34;summary&#34;: response.content, &#34;messages&#34;: delete_messages}
</code></pre><p>有关示例用法，请参阅<a href="https://langgraph.com.cn/how-tos/memory/add-summary-conversation-history/index.html">此处</a>的此操作指南，以及我们<a href="https://github.com/langchain-ai/langchain-academy/tree/main/module-2">LangChain Academy</a>课程的模块2。</p>
<h3 id="知道何时移除消息httpslanggraphcomcnconceptsmemory1htmlknowing-when-to-remove-messages-permanent-link">知道<strong>何时</strong>移除消息<a href="https://langgraph.com.cn/concepts/memory.1.html#knowing-when-to-remove-messages" title="Permanent link">¶</a></h3>
<p>大多数LLM都有一个最大支持的上下文窗口（以token计）。一个决定何时截断消息的简单方法是计算消息历史中的token数量，并在接近该限制时进行截断。简单的截断很容易自行实现，尽管有一些“陷阱”。一些模型API进一步限制了消息类型的顺序（必须以人类消息开始，不能有连续的相同类型的消息等）。如果你正在使用LangChain，你可以使用<a href="https://python.langchain.ac.cn/docs/how_to/trim_messages/#trimming-based-on-token-count"><code>trim_messages</code></a>实用程序，并指定要从列表中保留的token数量，以及用于处理边界的<code>strategy</code>（例如，保留最后<code>max_tokens</code>）。</p>
<p>下面是一个例子。</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->API参考：<!-- raw HTML omitted -->trim_messages<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<pre tabindex="0"><code>&lt;span id=&#34;__span-4-1&#34;&gt;from langchain_core.messages import trim_messages
&lt;span id=&#34;__span-4-2&#34;&gt;trim_messages(
&lt;span id=&#34;__span-4-3&#34;&gt;    messages,
&lt;span id=&#34;__span-4-4&#34;&gt;    # Keep the last &amp;lt;= n_count tokens of the messages.
&lt;span id=&#34;__span-4-5&#34;&gt;    strategy=&#34;last&#34;,
&lt;span id=&#34;__span-4-6&#34;&gt;    # Remember to adjust based on your model
&lt;span id=&#34;__span-4-7&#34;&gt;    # or else pass a custom token_encoder
&lt;span id=&#34;__span-4-8&#34;&gt;    token_counter=ChatOpenAI(model=&#34;gpt-4&#34;),
&lt;span id=&#34;__span-4-9&#34;&gt;    # Remember to adjust based on the desired conversation
&lt;span id=&#34;__span-4-10&#34;&gt;    # length
&lt;span id=&#34;__span-4-11&#34;&gt;    max_tokens=45,
&lt;span id=&#34;__span-4-12&#34;&gt;    # Most chat models expect that chat history starts with either:
&lt;span id=&#34;__span-4-13&#34;&gt;    # (1) a HumanMessage or
&lt;span id=&#34;__span-4-14&#34;&gt;    # (2) a SystemMessage followed by a HumanMessage
&lt;span id=&#34;__span-4-15&#34;&gt;    start_on=&#34;human&#34;,
&lt;span id=&#34;__span-4-16&#34;&gt;    # Most chat models expect that chat history ends with either:
&lt;span id=&#34;__span-4-17&#34;&gt;    # (1) a HumanMessage or
&lt;span id=&#34;__span-4-18&#34;&gt;    # (2) a ToolMessage
&lt;span id=&#34;__span-4-19&#34;&gt;    end_on=(&#34;human&#34;, &#34;tool&#34;),
&lt;span id=&#34;__span-4-20&#34;&gt;    # Usually, we want to keep the SystemMessage
&lt;span id=&#34;__span-4-21&#34;&gt;    # if it&#39;s present in the original history.
&lt;span id=&#34;__span-4-22&#34;&gt;    # The SystemMessage has special instructions for the model.
&lt;span id=&#34;__span-4-23&#34;&gt;    include_system=True,
&lt;span id=&#34;__span-4-24&#34;&gt;)
</code></pre><h2 id="长期记忆httpslanggraphcomcnconceptsmemory1htmllong-term-memory-permanent-link">长期记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#long-term-memory" title="Permanent link">¶</a></h2>
<p>LangGraph中的长期记忆允许系统在不同的对话或会话中保留信息。与<strong>线程范围</strong>的短期记忆不同，长期记忆保存在自定义的“命名空间”中。</p>
<h3 id="存储记忆httpslanggraphcomcnconceptsmemory1htmlstoring-memories-permanent-link">存储记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#storing-memories" title="Permanent link">¶</a></h3>
<p>LangGraph将长期记忆作为JSON文档存储在<a href="https://langgraph.com.cn/concepts/persistence.1.html#memory-store">存储</a>中（<a href="https://langgraph.com.cn/reference/store/index.html#langgraph.store.base.BaseStore">参考文档</a>）。每个记忆都组织在一个自定义的<code>namespace</code>（类似于文件夹）和一个独特的<code>key</code>（像文件名）之下。命名空间通常包括用户或组织ID或其他标签，以便于组织信息。这种结构实现了记忆的层次化组织。通过内容过滤器支持跨命名空间搜索。请参阅下面的示例。</p>
<pre tabindex="0"><code>&lt;code tabindex=&#34;0&#34;&gt;&lt;span id=&#34;__span-5-1&#34;&gt;from langgraph.store.memory import InMemoryStore
&lt;span id=&#34;__span-5-2&#34;&gt;
&lt;span id=&#34;__span-5-3&#34;&gt;
&lt;span id=&#34;__span-5-4&#34;&gt;def embed(texts: list[str]) -&amp;gt; list[list[float]]:
&lt;span id=&#34;__span-5-5&#34;&gt;    # Replace with an actual embedding function or LangChain embeddings object
&lt;span id=&#34;__span-5-6&#34;&gt;    return [[1.0, 2.0] * len(texts)]
&lt;span id=&#34;__span-5-7&#34;&gt;
&lt;span id=&#34;__span-5-8&#34;&gt;
&lt;span id=&#34;__span-5-9&#34;&gt;# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.
&lt;span id=&#34;__span-5-10&#34;&gt;store = InMemoryStore(index={&#34;embed&#34;: embed, &#34;dims&#34;: 2})
&lt;span id=&#34;__span-5-11&#34;&gt;user_id = &#34;my-user&#34;
&lt;span id=&#34;__span-5-12&#34;&gt;application_context = &#34;chitchat&#34;
&lt;span id=&#34;__span-5-13&#34;&gt;namespace = (user_id, application_context)
&lt;span id=&#34;__span-5-14&#34;&gt;store.put(
&lt;span id=&#34;__span-5-15&#34;&gt;    namespace,
&lt;span id=&#34;__span-5-16&#34;&gt;    &#34;a-memory&#34;,
&lt;span id=&#34;__span-5-17&#34;&gt;    {
&lt;span id=&#34;__span-5-18&#34;&gt;        &#34;rules&#34;: [
&lt;span id=&#34;__span-5-19&#34;&gt;            &#34;User likes short, direct language&#34;,
&lt;span id=&#34;__span-5-20&#34;&gt;            &#34;User only speaks English &amp;amp; python&#34;,
&lt;span id=&#34;__span-5-21&#34;&gt;        ],
&lt;span id=&#34;__span-5-22&#34;&gt;        &#34;my-key&#34;: &#34;my-value&#34;,
&lt;span id=&#34;__span-5-23&#34;&gt;    },
&lt;span id=&#34;__span-5-24&#34;&gt;)
&lt;span id=&#34;__span-5-25&#34;&gt;# get the &#34;memory&#34; by ID
&lt;span id=&#34;__span-5-26&#34;&gt;item = store.get(namespace, &#34;a-memory&#34;)
&lt;span id=&#34;__span-5-27&#34;&gt;# search for &#34;memories&#34; within this namespace, filtering on content equivalence, sorted by vector similarity
&lt;span id=&#34;__span-5-28&#34;&gt;items = store.search(
&lt;span id=&#34;__span-5-29&#34;&gt;    namespace, filter={&#34;my-key&#34;: &#34;my-value&#34;}, query=&#34;language preferences&#34;
&lt;span id=&#34;__span-5-30&#34;&gt;)
</code></pre><h3 id="长期记忆的思考框架httpslanggraphcomcnconceptsmemory1htmlframework-for-thinking-about-long-term-memory-permanent-link">长期记忆的思考框架<a href="https://langgraph.com.cn/concepts/memory.1.html#framework-for-thinking-about-long-term-memory" title="Permanent link">¶</a></h3>
<p>长期记忆是一个复杂的挑战，没有一劳永逸的解决方案。然而，以下问题提供了一个结构化框架，帮助你探索不同的技术</p>
<p><strong>记忆的类型是什么？</strong></p>
<p>人类利用记忆来记住<a href="https://en.wikipedia.org/wiki/Semantic_memory">事实</a>、<a href="https://en.wikipedia.org/wiki/Episodic_memory">经验</a>和<a href="https://en.wikipedia.org/wiki/Procedural_memory">规则</a>。AI代理也可以以相同的方式使用记忆。例如，AI代理可以使用记忆来记住关于用户的具体事实以完成任务。我们将在<a href="https://langgraph.com.cn/concepts/memory.1.html#memory-types">下面的部分</a>中详细介绍几种记忆类型。</p>
<p><strong>你希望何时更新记忆？</strong></p>
<p>记忆可以作为代理应用程序逻辑的一部分进行更新（例如，“在热路径上”）。在这种情况下，代理通常在响应用户之前决定记住事实。或者，记忆可以作为后台任务进行更新（在后台/异步运行并生成记忆的逻辑）。我们将在<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories">下面的部分</a>中解释这些方法之间的权衡。</p>
<h2 id="记忆类型httpslanggraphcomcnconceptsmemory1htmlmemory-types-permanent-link">记忆类型<a href="https://langgraph.com.cn/concepts/memory.1.html#memory-types" title="Permanent link">¶</a></h2>
<p>不同的应用程序需要各种类型的记忆。尽管类比并不完美，但研究<a href="https://www.psychologytoday.com/us/basics/memory/types-of-memory?ref=blog.langchain.dev">人类记忆类型</a>可以提供深刻的见解。一些研究（例如，<a href="https://arxiv.org/pdf/2309.02427">CoALA论文</a>）甚至将这些人类记忆类型映射到了AI代理中使用的类型。</p>
<h3 id="语义记忆httpslanggraphcomcnconceptsmemory1htmlsemantic-memory-permanent-link">语义记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#semantic-memory" title="Permanent link">¶</a></h3>
<p><a href="https://en.wikipedia.org/wiki/Semantic_memory">语义记忆</a>，无论是对人类还是AI代理，都涉及特定事实和概念的保留。在人类中，它可能包括在学校学到的信息以及对概念及其关系的理解。对于AI代理，语义记忆通常用于通过记住过去交互中的事实或概念来个性化应用程序。</p>
<blockquote>
<p>注意：不要与“语义搜索”混淆，后者是使用“意义”（通常作为嵌入）查找相似内容的技术。语义记忆是心理学中的一个术语，指的是存储事实和知识，而语义搜索是根据意义而非精确匹配检索信息的方法。</p>
</blockquote>
<h4 id="个人资料httpslanggraphcomcnconceptsmemory1htmlprofile-permanent-link">个人资料<a href="https://langgraph.com.cn/concepts/memory.1.html#profile" title="Permanent link">¶</a></h4>
<p>语义记忆可以通过不同方式进行管理。例如，记忆可以是一个单一的、持续更新的“配置文件”，其中包含关于用户、组织或其他实体（包括代理本身）的范围明确且具体的信息。配置文件通常只是一个JSON文档，包含你为表示你的领域而选择的各种键值对。</p>
<p>在记忆配置文件时，你会希望确保每次都<strong>更新</strong>配置文件。因此，你会希望传入先前的配置文件并<a href="https://github.com/langchain-ai/memory-template">要求模型生成新的配置文件</a>（或应用于旧配置文件的某些<a href="https://github.com/hinthornw/trustcall">JSON补丁</a>）。随着配置文件变大，这可能会变得容易出错，并且可能受益于将配置文件拆分为多个文档或生成文档时进行<strong>严格</strong>解码，以确保记忆模式保持有效。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/3549720260108160851hlkm6thS.png" />   
    </p>
<h4 id="集合httpslanggraphcomcnconceptsmemory1htmlcollection-permanent-link">集合<a href="https://langgraph.com.cn/concepts/memory.1.html#collection" title="Permanent link">¶</a></h4>
<p>或者，记忆可以是一个文档集合，随着时间的推移不断更新和扩展。每个单独的记忆可以更狭窄地限定范围，更容易生成，这意味着你随着时间的推移<strong>丢失</strong>信息的可能性更小。LLM更容易为新信息生成_新_对象，而不是将新信息与现有配置文件进行协调。因此，文档集合往往会带来<a href="https://en.wikipedia.org/wiki/Precision_and_recall">更高的下游召回率</a>。</p>
<p>然而，这会增加内存更新的复杂性。模型现在必须_删除_或_更新_列表中的现有项目，这可能很棘手。此外，某些模型可能默认过度插入，而另一些模型可能默认过度更新。请参阅<a href="https://github.com/hinthornw/trustcall">Trustcall</a>包以了解一种管理此问题的方法，并考虑使用评估工具（例如，使用<a href="https://langsmith.langchain.ac.cn/tutorials/Developers/evaluation">LangSmith</a>）来帮助你调整行为。</p>
<p>处理文档集合也将复杂性转移到了列表的内存<strong>搜索</strong>上。<code>Store</code>目前支持<a href="https://langgraph.com.cn/reference/store/index.html#langgraph.store.base.SearchOp.query">语义搜索</a>和<a href="https://langgraph.com.cn/reference/store/index.html#langgraph.store.base.SearchOp.filter">按内容过滤</a>。</p>
<p>最后，使用记忆集合可能会给模型提供全面的上下文带来挑战。尽管单个记忆可能遵循特定的模式，但这种结构可能无法捕捉记忆之间的完整上下文或关系。因此，在使用这些记忆生成响应时，模型可能缺乏在统一配置文件方法中更容易获得的重要上下文信息。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/8442820260108160851fu2zJ6cL.png" />   
    </p>
<p>无论记忆管理方法如何，核心点是代理将使用语义记忆来<a href="https://python.langchain.ac.cn/docs/concepts/rag/">支撑其响应</a>，这通常会带来更个性化和相关的交互。</p>
<h3 id="情景记忆httpslanggraphcomcnconceptsmemory1htmlepisodic-memory-permanent-link">情景记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#episodic-memory" title="Permanent link">¶</a></h3>
<p><a href="https://en.wikipedia.org/wiki/Episodic_memory">情景记忆</a>，无论是对人类还是AI代理，都涉及回忆过去的事件或行动。<a href="https://arxiv.org/pdf/2309.02427">CoALA论文</a>对此作了很好的阐述：事实可以写入语义记忆，而_经验_可以写入情景记忆。对于AI代理，情景记忆通常用于帮助代理记住如何完成任务。</p>
<p>在实践中，情景记忆通常通过<a href="https://python.langchain.ac.cn/docs/concepts/few_shot_prompting/">少样本提示</a>来实现，代理通过过去的序列学习来正确执行任务。有时“展示”比“告知”更容易，LLM从示例中学习得很好。少样本学习让你通过用输入-输出示例更新提示来<a href="https://x.com/karpathy/status/1627366413840322562">“编程”</a>你的LLM，以说明预期的行为。虽然可以使用各种<a href="https://python.langchain.ac.cn/docs/concepts/#1-generating-examples">最佳实践</a>来生成少样本示例，但挑战通常在于根据用户输入选择最相关的示例。</p>
<p>请注意，记忆<a href="https://langgraph.com.cn/concepts/persistence.1.html#memory-store">存储</a>只是将数据存储为少样本示例的一种方式。如果你想让开发者有更多参与，或者将少样本更紧密地与你的评估工具联系起来，你还可以使用<a href="https://langsmith.langchain.ac.cn/evaluation/how_to_guides/datasets/index_datasets_for_dynamic_few_shot_example_selection">LangSmith数据集</a>来存储你的数据。然后，动态少样本示例选择器可以开箱即用地实现此目标。LangSmith会为你索引数据集，并能够根据关键词相似性（<a href="https://langsmith.langchain.ac.cn/how_to_guides/datasets/index_datasets_for_dynamic_few_shot_example_selection">使用类似BM25的算法</a>进行关键词相似性）检索与用户输入最相关的少样本示例。</p>
<p>有关LangSmith中动态少样本示例选择的示例用法，请参阅此操作<a href="https://www.youtube.com/watch?v=37VaU7e7t5o">视频</a>。此外，请参阅这篇<a href="https://blog.langchain.ac.cn/few-shot-prompting-to-improve-tool-calling-performance/">博客文章</a>，展示了如何使用少样本提示来提高工具调用性能，以及这篇<a href="https://blog.langchain.ac.cn/aligning-llm-as-a-judge-with-human-preferences/">博客文章</a>，如何使用少样本示例使LLM与人类偏好保持一致。</p>
<h3 id="程序记忆httpslanggraphcomcnconceptsmemory1htmlprocedural-memory-permanent-link">程序记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#procedural-memory" title="Permanent link">¶</a></h3>
<p><a href="https://en.wikipedia.org/wiki/Procedural_memory">程序记忆</a>，无论是对人类还是AI代理，都涉及记住执行任务所用的规则。在人类中，程序记忆就像内化的执行任务的知识，例如通过基本运动技能和平衡来骑自行车。另一方面，情景记忆涉及回忆特定经历，例如第一次成功不带辅助轮骑自行车，或者一次难忘的风景优美的自行车之旅。对于AI代理，程序记忆是模型权重、代理代码和代理提示的组合，它们共同决定了代理的功能。</p>
<p>在实践中，代理修改其模型权重或重写其代码是相当不常见的。然而，代理修改自己的提示则更为常见。</p>
<p>完善代理指令的一种有效方法是通过<a href="https://blog.langchain.ac.cn/reflection-agents/">“反思”</a>或元提示。这涉及用其当前指令（例如，系统提示）以及最近的对话或明确的用户反馈来提示代理。然后，代理根据这些输入完善自己的指令。这种方法对于难以预先指定指令的任务特别有用，因为它允许代理从其交互中学习和适应。</p>
<p>例如，我们构建了一个<a href="https://www.youtube.com/watch?v=Vn8A3BxfplE">推文生成器</a>，它使用外部反馈和提示重写来生成高质量的论文摘要，用于Twitter。在这种情况下，特定的摘要提示很难_先验_指定，但用户很容易批评生成的推文并提供如何改进摘要过程的反馈。</p>
<p>下面的伪代码展示了如何使用LangGraph内存<a href="https://langgraph.com.cn/concepts/persistence.1.html#memory-store">存储</a>实现这一点，使用存储来保存提示，<code>update_instructions</code>节点获取当前提示（以及从与用户对话中捕获的<code>state[&quot;messages&quot;]</code>中的反馈），更新提示，并将新提示保存回存储。然后，<code>call_model</code>从存储中获取更新的提示并使用它来生成响应。</p>
<pre tabindex="0"><code>&lt;code tabindex=&#34;0&#34;&gt;&lt;span id=&#34;__span-6-1&#34;&gt;# Node that *uses* the instructions
&lt;span id=&#34;__span-6-2&#34;&gt;def call_model(state: State, store: BaseStore):
&lt;span id=&#34;__span-6-3&#34;&gt;    namespace = (&#34;agent_instructions&#34;, )
&lt;span id=&#34;__span-6-4&#34;&gt;    instructions = store.get(namespace, key=&#34;agent_a&#34;)[0]
&lt;span id=&#34;__span-6-5&#34;&gt;    # Application logic
&lt;span id=&#34;__span-6-6&#34;&gt;    prompt = prompt_template.format(instructions=instructions.value[&#34;instructions&#34;])
&lt;span id=&#34;__span-6-7&#34;&gt;    ...
&lt;span id=&#34;__span-6-8&#34;&gt;
&lt;span id=&#34;__span-6-9&#34;&gt;# Node that updates instructions
&lt;span id=&#34;__span-6-10&#34;&gt;def update_instructions(state: State, store: BaseStore):
&lt;span id=&#34;__span-6-11&#34;&gt;    namespace = (&#34;instructions&#34;,)
&lt;span id=&#34;__span-6-12&#34;&gt;    current_instructions = store.search(namespace)[0]
&lt;span id=&#34;__span-6-13&#34;&gt;    # Memory logic
&lt;span id=&#34;__span-6-14&#34;&gt;    prompt = prompt_template.format(instructions=instructions.value[&#34;instructions&#34;], conversation=state[&#34;messages&#34;])
&lt;span id=&#34;__span-6-15&#34;&gt;    output = llm.invoke(prompt)
&lt;span id=&#34;__span-6-16&#34;&gt;    new_instructions = output[&#39;new_instructions&#39;]
&lt;span id=&#34;__span-6-17&#34;&gt;    store.put((&#34;agent_instructions&#34;,), &#34;agent_a&#34;, {&#34;instructions&#34;: new_instructions})
&lt;span id=&#34;__span-6-18&#34;&gt;    ...
</code></pre><p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/5206920260108160853EAdZ4HlE.png" />   
    </p>
<h2 id="写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-permanent-link">写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories" title="Permanent link">¶</a></h2>
<p>虽然<a href="https://medicine.yale.edu/news-article/sleeps-crucial-role-in-preserving-memory/">人类通常在睡眠期间形成长期记忆</a>，但AI代理需要不同的方法。代理何时以及如何创建新记忆？代理至少有两种主要方法来写入记忆：“热路径上”和“后台中”。</p>
<p>
        <img class="mx-auto" alt="" src="https://api.995120.cn/ecgdata/other/2026-01-08/1913320260108160853dUlJUerv.png" />   
    </p>
<h3 id="在热路径中写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-in-the-hot-path-permanent-link">在热路径中写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories-in-the-hot-path" title="Permanent link">¶</a></h3>
<p>在运行时创建记忆既有优点也有挑战。积极的一面是，这种方法允许实时更新，使新记忆立即可用于后续交互。它还实现了透明性，因为可以在创建和存储记忆时通知用户。</p>
<p>然而，这种方法也带来了挑战。如果代理需要一个新工具来决定提交什么内容到内存中，它可能会增加复杂性。此外，思考要保存到内存中的过程可能会影响代理的延迟。最后，代理必须在记忆创建和其其他职责之间进行多任务处理，这可能会影响所创建记忆的数量和质量。</p>
<p>例如，ChatGPT使用<a href="https://openai.com/index/memory-and-new-controls-for-chatgpt/">save_memories</a>工具将记忆作为内容字符串进行插入更新，并根据每条用户消息决定是否以及如何使用此工具。请参阅我们的<a href="https://github.com/langchain-ai/memory-agent">memory-agent</a>模板作为参考实现。</p>
<h3 id="在后台写入记忆httpslanggraphcomcnconceptsmemory1htmlwriting-memories-in-the-background-permanent-link">在后台写入记忆<a href="https://langgraph.com.cn/concepts/memory.1.html#writing-memories-in-the-background" title="Permanent link">¶</a></h3>
<p>将记忆创建作为单独的后台任务具有多种优势。它消除了主应用程序中的延迟，将应用程序逻辑与内存管理分离，并允许代理更专注地完成任务。这种方法还提供了灵活的内存创建时间安排，以避免重复工作。</p>
<p>然而，这种方法也有其自身的挑战。确定记忆写入的频率变得至关重要，因为不频繁的更新可能会导致其他线程缺少新的上下文。决定何时触发记忆形成也很重要。常见的策略包括在设定的时间段后安排（如果发生新事件则重新安排）、使用cron调度，或允许用户或应用程序逻辑手动触发。</p>
<p>请参阅我们的<a href="https://github.com/langchain-ai/memory-template">memory-service</a>模板作为参考实现。</p>

        </div>

        
<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://index.zshipu.com/ai002">知识铺</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://index.zshipu.com/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-4/">https://index.zshipu.com/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-4/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
        <li><strong>免责声明：</strong>本页面内容均来源于站内编辑发布，部分信息来源互联网，并不意味着本站赞同其观点或者证实其内容的真实性，如涉及版权等问题，请立即联系客服进行更改或删除，保证您的合法权益。转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。也可以邮件至 sblig@126.com</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-3/">概述 - LangChain 框架 (3) --知识铺</a></li>
        
        <li><a href="/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-2/">概述 - LangChain 框架 (2) --知识铺</a></li>
        
        <li><a href="/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-10/">概述 - LangChain 框架 (10) --知识铺</a></li>
        
        <li><a href="/ai002/post/20251125/%E6%A6%82%E8%BF%B0-LangChain-%E6%A1%86%E6%9E%B6-1/">概述 - LangChain 框架 (1) --知识铺</a></li>
        
        <li><a href="/ai002/post/20251125/%E6%A6%82%E8%A7%88-LangChain-%E6%A1%86%E6%9E%B6/">概览 - LangChain 框架 --知识铺</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            没有标签
            
        </div>
    </article>
    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "zshipu/zshipu-index"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2026 <a href="https://index.zshipu.com/ai002">知识铺的博客 By 知识铺</a>
        
        | <a rel="nofollow" target="_blank" href="https://beian.miit.gov.cn/">浙 ICP 备19032823号-1</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/ai002/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://index.zshipu.com/ai002/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://index.zshipu.com/ai002">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/agentskillsagentskills-Agent-Skills-%E7%9A%84%E8%A7%84%E8%8C%83%E5%92%8C%E6%96%87%E6%A1%A3---agentskillsagentskills-Specification-and-documentation-for-Agent-Skills/" title="agentskillsagentskills Agent Skills 的规范和文档 --- agentskillsagentskills Specification and documentation for Agent Skills --知识铺">agentskillsagentskills Agent Skills 的规范和文档 --- agentskillsagentskills Specification and documentation for Agent Skills --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/2026%E5%B9%B4AI%E5%BA%94%E7%94%A8%E6%8A%80%E6%9C%AF%E6%A0%88%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90Agent-Skill%E6%B8%90%E8%BF%9B%E5%BC%8F%E6%8A%AB%E9%9C%B2%E6%9E%B6%E6%9E%84%E4%BC%81%E4%B8%9A%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8Agent-Skill%E4%B8%BA%E9%80%9A%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%85%8D%E5%A4%87%E7%B2%BE%E5%87%86%E7%9A%84%E5%B2%97%E4%BD%8DSOP-%E8%85%BE%E8%AE%AF%E4%BA%91%E5%BC%80%E5%8F%91%E8%80%85%E7%A4%BE%E5%8C%BA-%E8%85%BE%E8%AE%AF%E4%BA%91/" title="2026年AI应用技术栈：深度剖析Agent Skill“渐进式披露”架构！企业如何利用Agent Skill，为通用大模型配备精准的“岗位SOP”？-腾讯云开发者社区-腾讯云 --知识铺">2026年AI应用技术栈：深度剖析Agent Skill“渐进式披露”架构！企业如何利用Agent Skill，为通用大模型配备精准的“岗位SOP”？-腾讯云开发者社区-腾讯云 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/%E5%BF%85%E8%97%8F%E5%B9%B2%E8%B4%A7%E5%A4%A7%E6%A8%A1%E5%9E%8BAgent%E6%8A%80%E8%83%BD%E5%8C%85Agent-Skills%E6%A0%87%E5%87%86%E5%8C%96%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3%E8%AE%A9AI%E5%BC%80%E5%8F%91%E5%83%8F%E6%90%AD%E7%A7%AF%E6%9C%A8%E4%B8%80%E6%A0%B7%E7%AE%80%E5%8D%95-CSDN%E5%8D%9A%E5%AE%A2/" title="【必藏干货】大模型Agent技能包：Agent Skills标准化框架详解，让AI开发像搭积木一样简单-CSDN博客 --知识铺">【必藏干货】大模型Agent技能包：Agent Skills标准化框架详解，让AI开发像搭积木一样简单-CSDN博客 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/Agent-Skills-%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97%E5%85%A5%E9%97%A8%E7%B2%BE%E9%80%9A%E9%A2%84%E6%B5%8B-%E7%9F%A5%E4%B9%8E/" title="Agent Skills 终极指南：入门、精通、预测 - 知乎 --知识铺">Agent Skills 终极指南：入门、精通、预测 - 知乎 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/%E9%AA%97%E4%BD%A0%E7%9A%84%E5%85%B6%E5%AE%9EAI%E6%A0%B9%E6%9C%AC%E4%B8%8D%E9%9C%80%E8%A6%81%E9%82%A3%E4%B9%88%E5%A4%9A%E6%8F%90%E7%A4%BA%E8%AF%8DAI_%E6%96%B0%E6%B5%AA%E7%A7%91%E6%8A%80_%E6%96%B0%E6%B5%AA%E7%BD%91/" title="骗你的！其实AI根本不需要那么多提示词AI_新浪科技_新浪网 --知识铺">骗你的！其实AI根本不需要那么多提示词AI_新浪科技_新浪网 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/%E7%AE%80%E5%8D%95%E5%BF%AB%E9%80%9F%E7%9A%84%E7%94%A8-Claude-Code-%E5%B8%AE%E4%BD%A0%E5%88%9B%E5%BB%BA-PPT-%E7%94%9F%E6%88%90-Skills_%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/" title="简单快速的用 Claude Code 帮你创建 PPT 生成 Skills_腾讯新闻 --知识铺">简单快速的用 Claude Code 帮你创建 PPT 生成 Skills_腾讯新闻 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/Skills%E5%B0%B1%E6%98%AF%E7%BB%99AI%E7%94%A8%E7%9A%84APP-302.AI%E5%A4%A7%E7%99%BD%E8%AF%9D%E8%81%8A%E4%B8%80%E8%81%8A-/" title="Skills就是给AI用的APP  302.AI大白话聊一聊 - --知识铺">Skills就是给AI用的APP  302.AI大白话聊一聊 - --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/%E7%BB%99AI%E8%A3%85%E4%B8%AA%E6%8A%80%E8%83%BD%E5%8C%85Skills%E6%98%AF%E4%BB%80%E4%B9%88_%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/" title="给AI装个技能包：Skills是什么_腾讯新闻 --知识铺">给AI装个技能包：Skills是什么_腾讯新闻 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/Skills%E7%9A%84%E5%AE%B9%E9%87%8F%E4%B8%8A%E9%99%90%E5%9C%A8%E5%93%AA%E9%87%8C2026%E5%8D%95Skills%E7%BB%84%E5%90%88%E8%BF%98%E6%98%AF%E5%A4%9AAgent%E5%A5%BDUCB%E6%9C%80%E6%96%B0_%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/" title="Skills的容量上限在哪里？2026单Skills组合还是多Agent好？｜UCB最新_腾讯新闻 --知识铺">Skills的容量上限在哪里？2026单Skills组合还是多Agent好？｜UCB最新_腾讯新闻 --知识铺</a>
    </li>
    
    <li>
        <a href="https://index.zshipu.com/ai002/post/20260112/%E6%9C%80%E8%BF%91%E8%81%8A%E7%88%86%E7%9A%84Skills-%E5%88%B0%E5%BA%95%E6%98%AF%E5%95%A5%E8%AF%B7%E7%94%A8%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%AF%9D%E5%91%8A%E8%AF%89%E6%88%91-%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/" title="最近聊爆的Skills 到底是啥？请用通俗易懂的话告诉我  人人都是产品经理 --知识铺">最近聊爆的Skills 到底是啥？请用通俗易懂的话告诉我  人人都是产品经理 --知识铺</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="https://pplx.ai/sblig3912" title="一起上 Comet，AI 工具免费用还送钱～" target="_blank" style="color:red">
                
                    <img src="https://cdn.jsdelivr.net/gh/zshipu/images/2025/202510250843697.png">
                
            </a>
        </li>
        
        <li>
            <a href="https://pplx.ai/sblig3912" title="邀请有礼 🎁 一起用 Comet，AI 助你更高效还送钱！" target="_blank" style="color:red">
                
                    <img src="https://cdn.jsdelivr.net/gh/zshipu/images/2025/202510250850822.png">
                
            </a>
        </li>
        
        <li>
            <a href="https://pplx.ai/sblig3912" title="AI 工具真香！我用的 Comet 免费送一个月 Pro～" target="_blank" style="color:red">
                
                    <img src="https://cdn.jsdelivr.net/gh/zshipu/images/2025/202510250851688.png">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title"><a href='/ai002/categories/'>分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/ai002/tags/'>标签</a></h3>
<div class="tagcloud">
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://blog.zshipu.com//" title="知识铺的博客">知识铺的博客</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://index.zshipu.com/ai002/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>