<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llama3 on 知识铺的博客</title>
    <link>https://index.zshipu.com/geek001/tags/Llama3/</link>
    <description>Recent content in Llama3 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 28 Aug 2024 08:40:34 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/geek001/tags/Llama3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mamba作者最新力作：将Llama3蒸馏成混合线性RNN！性能提升显著 --知识铺</title>
      <link>https://index.zshipu.com/geek001/post/20240828/Mamba%E4%BD%9C%E8%80%85%E6%9C%80%E6%96%B0%E5%8A%9B%E4%BD%9C%E5%B0%86Llama3%E8%92%B8%E9%A6%8F%E6%88%90%E6%B7%B7%E5%90%88%E7%BA%BF%E6%80%A7RNN%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E6%98%BE%E8%91%97--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Wed, 28 Aug 2024 08:40:34 +0000</pubDate>
      <guid>https://index.zshipu.com/geek001/post/20240828/Mamba%E4%BD%9C%E8%80%85%E6%9C%80%E6%96%B0%E5%8A%9B%E4%BD%9C%E5%B0%86Llama3%E8%92%B8%E9%A6%8F%E6%88%90%E6%B7%B7%E5%90%88%E7%BA%BF%E6%80%A7RNN%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E6%98%BE%E8%91%97--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>转载自：机器之心 Transformer 在深度学习领域取得巨大成功的关键是注意力机制。注意力机制让基于 Transformer 的模型关注与输入序列相关的部分，实现了更好的上下文理解。然而，注意力机制的缺点是计算开销大，会随输入规模而二次增长，Transformer 也因此难以处理非常长的文本。 前段时间，Mamba 的出现打破了</description>
    </item>
  </channel>
</rss>
