<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>大型语言模型 on GPT资讯  --  知识铺</title>
    <link>https://index.zshipu.com/gpt/tags/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 大型语言模型 on GPT资讯  --  知识铺</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 25 Mar 2024 09:09:40 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/gpt/tags/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>了解大型语言模型：初学者指南 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240326/LLMs/%E4%BA%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Mon, 25 Mar 2024 09:09:40 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240326/LLMs/%E4%BA%86%E8%A7%A3%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%AD%A6%E8%80%85%E6%8C%87%E5%8D%97--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>了解大型语言模型：初学者指南 维什瓦斯·阿查里亚 全栈工程师@Volansys |亚马逊AWS |天蓝色|博主| YouTuber 发布日期: 2024年3月25日 介绍 你曾经和一台能够理解你的机器交谈过吗？大型语言模型 (LLMs) 正在使这成为现实。这些人工智能奇迹正在改变我们与机器沟通的方式，模糊了人类语言和计算机代</description>
    </item>
    <item>
      <title>大型语言模型推动生成式人工智能前沿并改变多领域应用 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240326/LLMs/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E5%8A%A8%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%89%8D%E6%B2%BF%E5%B9%B6%E6%94%B9%E5%8F%98%E5%A4%9A%E9%A2%86%E5%9F%9F%E5%BA%94%E7%94%A8--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Mon, 25 Mar 2024 09:08:40 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240326/LLMs/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E5%8A%A8%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%89%8D%E6%B2%BF%E5%B9%B6%E6%94%B9%E5%8F%98%E5%A4%9A%E9%A2%86%E5%9F%9F%E5%BA%94%E7%94%A8--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>LLMs 已成为家喻户晓的名字，这要归功于他们在将生成式人工智能带到公众利益的前沿方面所发挥的作用，以及组织致力于在众多业务职能和领域采用人工智能的重点。用例。 在企业环境之外，随着生成式人工智能的新发展，LLMs 似乎是突然出现的。然而，包括 IBM 在内的许多公司花费了数年时间在不同级别实施 LL</description>
    </item>
    <item>
      <title>增强大型语言模型推理能力的多种方法研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:29:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
    <item>
      <title>增强大型语言模型推理能力的多种方法和框架研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:28:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
    <item>
      <title>思维图（GoT）助力大型语言模型解决复杂问题 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E6%80%9D%E7%BB%B4%E5%9B%BEGoT%E5%8A%A9%E5%8A%9B%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E5%A4%8D%E6%9D%82%E9%97%AE%E9%A2%98--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:25:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E6%80%9D%E7%BB%B4%E5%9B%BEGoT%E5%8A%A9%E5%8A%9B%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%E5%A4%8D%E6%9D%82%E9%97%AE%E9%A2%98--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>引言 为进一步提升大型语言模型（LLM）解决复杂问题的能力，今天给大家分享的这篇文章，作者提出了思维图（GoT），其性能超过了思维链（CoT）、思维树（ToT）。思维图（GoT）的关键思想是能够将LLM生成的信息建模为任意图，其中信息单位是顶点，边代表顶点之间的依赖关系。这种方法优</description>
    </item>
  </channel>
</rss>
