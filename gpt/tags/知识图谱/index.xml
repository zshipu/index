<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>知识图谱 on GPT资讯  --  知识铺</title>
    <link>https://index.zshipu.com/gpt/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</link>
    <description>Recent content in 知识图谱 on GPT资讯  --  知识铺</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 24 Mar 2024 17:29:58 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/gpt/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>增强大型语言模型推理能力的多种方法研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:29:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
    <item>
      <title>增强大型语言模型推理能力的多种方法和框架研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:28:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
  </channel>
</rss>
