<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>思维链提示 on GPT资讯  --  知识铺</title>
    <link>https://index.zshipu.com/gpt/tags/%E6%80%9D%E7%BB%B4%E9%93%BE%E6%8F%90%E7%A4%BA/</link>
    <description>Recent content in 思维链提示 on GPT资讯  --  知识铺</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 24 Mar 2024 17:29:58 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/gpt/tags/%E6%80%9D%E7%BB%B4%E9%93%BE%E6%8F%90%E7%A4%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>增强大型语言模型推理能力的多种方法研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:29:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
    <item>
      <title>增强大型语言模型推理能力的多种方法和框架研究 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:28:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E5%A2%9E%E5%BC%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%E5%92%8C%E6%A1%86%E6%9E%B6%E7%A0%94%E7%A9%B6--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>https://arxiv.org/pdf/2403.04121.pdf 虽然人类有时确实表现出通过自我批评纠正自己错误猜测的能力，但在LLMs的情况下，这种假设似乎没有基础。 https://arxiv.org/pdf/2403.14312v1.pdf 思想链（CoT）提示可以增强大型语言模型（LLMs）的推理能力，使其成为解决复杂推理任务的主要方法。现有的 CoT 综合方法通常专注于更简单的推理任务，从而导致低质量和不一致的 CoT 提示</description>
    </item>
    <item>
      <title>提示工程技术与应用示例 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/202403/prompt/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 15:07:22 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/202403/prompt/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>什么是提示工程？ 提示工程是设计和优化输入（提示）以指导生成式 AI 模型输出的过程。目标是创建清晰、简洁且能够引起 AI 所需响应的提示。 这在自然语言处理 （NLP） 等领域尤为重要，在这些领域中，输入的质量会显着影响生成内容的质量。 提示工程的类型 有几种类型的提示工程技术，每种技术都适用于不同的</description>
    </item>
  </channel>
</rss>
