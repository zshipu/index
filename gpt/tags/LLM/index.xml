<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on GPT资讯  --  知识铺</title>
    <link>https://index.zshipu.com/gpt/tags/LLM/</link>
    <description>Recent content in LLM on GPT资讯  --  知识铺</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 27 Mar 2024 15:40:08 +0000</lastBuildDate>
    <atom:link href="https://index.zshipu.com/gpt/tags/LLM/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Agent Operating System --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240328/LLM-Agent-Operating-System--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Wed, 27 Mar 2024 15:40:08 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240328/LLM-Agent-Operating-System--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>论文：LLM Agent Operating System（https://arxiv.org/pdf/2403.16971.pdf） 结论： AIOS大模型智能体操作系统，旨在解决集成和部署基于LLM的智能体时遇到的挑战。这些挑战包括在LLM上对智能体请求的调度和资源分配、在智能体与LLM之间保持上下文的困难，</description>
    </item>
    <item>
      <title>研究团队提出思维图GoT，通过图结构增强LLM推理能力 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/20240325/prompt/%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%E6%8F%90%E5%87%BA%E6%80%9D%E7%BB%B4%E5%9B%BEGoT%E9%80%9A%E8%BF%87%E5%9B%BE%E7%BB%93%E6%9E%84%E5%A2%9E%E5%BC%BALLM%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 17:26:58 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/20240325/prompt/%E7%A0%94%E7%A9%B6%E5%9B%A2%E9%98%9F%E6%8F%90%E5%87%BA%E6%80%9D%E7%BB%B4%E5%9B%BEGoT%E9%80%9A%E8%BF%87%E5%9B%BE%E7%BB%93%E6%9E%84%E5%A2%9E%E5%BC%BALLM%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>要让大型语言模型（LLM）充分发挥其能力，有效的 prompt 设计方案是必不可少的，为此甚至出现了 prompt engineering（提示工程）这一新兴领域。 在各种 prompt 设计方案中，思维链（CoT）凭借其强大的推理能力吸引了许多研究者和用户的眼球，基于其改进的 CoT-SC 以及更进一步的思维树（ToT）也收获了大量关</description>
    </item>
    <item>
      <title>大型语言模型与RAG的混合未来：实时数据与上下文长度的突破 --知识铺</title>
      <link>https://index.zshipu.com/gpt/post/202403/prompt/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERAG%E7%9A%84%E6%B7%B7%E5%90%88%E6%9C%AA%E6%9D%A5%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6%E7%9A%84%E7%AA%81%E7%A0%B4--%E7%9F%A5%E8%AF%86%E9%93%BA/</link>
      <pubDate>Sun, 24 Mar 2024 15:12:22 +0000</pubDate>
      <guid>https://index.zshipu.com/gpt/post/202403/prompt/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERAG%E7%9A%84%E6%B7%B7%E5%90%88%E6%9C%AA%E6%9D%A5%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E9%95%BF%E5%BA%A6%E7%9A%84%E7%AA%81%E7%A0%B4--%E7%9F%A5%E8%AF%86%E9%93%BA/</guid>
      <description>两年前 ChatGPT 出现后，每个人都纷纷加入。每个公司董事会/首席执行官都会询问他们的技术领导者“我们在人工智能方面正在做什么？” 我认为最初有两条路。根据您的数据微调您自己的LLM。这并不能真正扩展。微调LLM需要很长时间，而且价格昂贵。如果您需要 LLM 的实时更新，则无法执行此操作。 接下来，人们</description>
    </item>
  </channel>
</rss>
