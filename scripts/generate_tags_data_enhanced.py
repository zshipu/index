#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆæ ‡ç­¾æ•°æ®ç”Ÿæˆå™¨ - ä¸–ç•Œçº§Tagsç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. èšåˆæ‰€æœ‰åŸŸçš„æ ‡ç­¾æ•°æ®
2. æ™ºèƒ½åˆ†ç±»æ ‡ç­¾
3. è®¡ç®—æ ‡ç­¾å…³ç³»
4. ç”Ÿæˆè¶‹åŠ¿æ•°æ®
"""

import os
import sys
import io
import json
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
from html.parser import HTMLParser

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass


class ArticleMetaExtractor(HTMLParser):
    """æå–HTMLæ–‡ç« çš„å…ƒæ•°æ®"""
    def __init__(self):
        super().__init__()
        self.tags = []
        self.title = ''
        self.date = None
        self.in_title = False
        self.in_meta_keywords = False

    def handle_starttag(self, tag, attrs):
        attrs_dict = dict(attrs)

        if tag == 'title':
            self.in_title = True
        elif tag == 'meta':
            # æå–keywordsä½œä¸ºæ ‡ç­¾
            if attrs_dict.get('name') == 'keywords':
                keywords = attrs_dict.get('content', '')
                self.tags.extend([k.strip() for k in keywords.split(',') if k.strip()])
            # æå–å‘å¸ƒæ—¥æœŸ
            elif attrs_dict.get('property') == 'article:published_time':
                date_str = attrs_dict.get('content', '')
                try:
                    self.date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                except:
                    pass

    def handle_data(self, data):
        if self.in_title:
            self.title = data.strip()

    def handle_endtag(self, tag):
        if tag == 'title':
            self.in_title = False


# ==================== æ ‡ç­¾åˆ†ç±»é…ç½® ====================
TAG_CATEGORIES = {
    'AIæŠ€æœ¯': {
        'icon': 'ğŸ¤–',
        'color': '#667eea',
        'keywords': ['AI', 'äººå·¥æ™ºèƒ½', 'ChatGPT', 'GPT', 'OpenAI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ',
                    'LLM', 'å¤§æ¨¡å‹', 'Agent', 'Prompt', 'AIGC', 'AGI', 'ç¥ç»ç½‘ç»œ'],
        'description': 'äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€å¤§è¯­è¨€æ¨¡å‹ç›¸å…³æŠ€æœ¯æ ‡ç­¾'
    },
    'ç¼–ç¨‹å¼€å‘': {
        'icon': 'ğŸ’»',
        'color': '#48bb78',
        'keywords': ['Python', 'JavaScript', 'Java', 'Go', 'Rust', 'C++', 'TypeScript',
                    'React', 'Vue', 'Node.js', 'å‰ç«¯', 'åç«¯', 'Webå¼€å‘', 'ç¼–ç¨‹', 'å¼€å‘'],
        'description': 'ç¼–ç¨‹è¯­è¨€ã€å¼€å‘æ¡†æ¶ã€è½¯ä»¶å·¥ç¨‹ç›¸å…³æ ‡ç­¾'
    },
    'é‡‘èæŠ•èµ„': {
        'icon': 'ğŸ“ˆ',
        'color': '#f59e0b',
        'keywords': ['è‚¡ç¥¨', 'æŠ•èµ„', 'ç†è´¢', 'é‡‘è', 'äº¤æ˜“', 'Aè‚¡', 'åŸºé‡‘', 'è¯åˆ¸',
                    'é‡åŒ–', 'æŠ€æœ¯åˆ†æ', 'ä»·å€¼æŠ•èµ„'],
        'description': 'è‚¡ç¥¨ã€æŠ•èµ„ã€é‡‘èå¸‚åœºç›¸å…³æ ‡ç­¾'
    },
    'æ•°æ®ç§‘å­¦': {
        'icon': 'ğŸ“Š',
        'color': '#8b5cf6',
        'keywords': ['æ•°æ®åˆ†æ', 'æ•°æ®ç§‘å­¦', 'æ•°æ®æŒ–æ˜', 'Pandas', 'NumPy', 'å¯è§†åŒ–',
                    'SQL', 'æ•°æ®åº“', 'BigData', 'ç»Ÿè®¡'],
        'description': 'æ•°æ®åˆ†æã€æ•°æ®ç§‘å­¦ã€æ•°æ®åº“ç›¸å…³æ ‡ç­¾'
    },
    'å·¥å…·æ•ˆç‡': {
        'icon': 'ğŸ”§',
        'color': '#ec4899',
        'keywords': ['å·¥å…·', 'æ•ˆç‡', 'è‡ªåŠ¨åŒ–', 'Git', 'Docker', 'Linux', 'Shell',
                    'VSCode', 'IDE', 'æ’ä»¶', 'åŠå…¬'],
        'description': 'å¼€å‘å·¥å…·ã€æ•ˆç‡å·¥å…·ã€è‡ªåŠ¨åŒ–ç›¸å…³æ ‡ç­¾'
    },
    'äº‘è®¡ç®—': {
        'icon': 'â˜ï¸',
        'color': '#06b6d4',
        'keywords': ['äº‘è®¡ç®—', 'AWS', 'Azure', 'é˜¿é‡Œäº‘', 'è…¾è®¯äº‘', 'Kubernetes',
                    'å¾®æœåŠ¡', 'å®¹å™¨', 'DevOps', 'CI/CD'],
        'description': 'äº‘è®¡ç®—ã€å®¹å™¨ã€DevOpsç›¸å…³æ ‡ç­¾'
    },
    'å¥åº·åŒ»ç–—': {
        'icon': 'ğŸ¥',
        'color': '#10b981',
        'keywords': ['å¥åº·', 'åŒ»ç–—', 'å¿ƒç”µå›¾', 'ECG', 'åŒ»å­¦', 'è¯Šæ–­', 'ä¿å¥'],
        'description': 'å¥åº·ã€åŒ»ç–—ã€åŒ»å­¦æŠ€æœ¯ç›¸å…³æ ‡ç­¾'
    },
    'å­¦ä¹ æ•™è‚²': {
        'icon': 'ğŸ“š',
        'color': '#f97316',
        'keywords': ['å­¦ä¹ ', 'æ•™ç¨‹', 'æ•™è‚²', 'è¯¾ç¨‹', 'åŸ¹è®­', 'çŸ¥è¯†', 'æŠ€å·§',
                    'å…¥é—¨', 'è¿›é˜¶', 'æœ€ä½³å®è·µ'],
        'description': 'å­¦ä¹ èµ„æºã€æ•™ç¨‹ã€çŸ¥è¯†åˆ†äº«ç›¸å…³æ ‡ç­¾'
    },
    'å…¶ä»–': {
        'icon': 'ğŸ·ï¸',
        'color': '#6b7280',
        'keywords': [],
        'description': 'å…¶ä»–æœªåˆ†ç±»æ ‡ç­¾'
    }
}


def classify_tag(tag_name):
    """æ™ºèƒ½åˆ†ç±»æ ‡ç­¾"""
    tag_lower = tag_name.lower()

    # ç²¾ç¡®åŒ¹é…
    for category, config in TAG_CATEGORIES.items():
        for keyword in config['keywords']:
            if keyword.lower() in tag_lower or tag_lower in keyword.lower():
                return category

    # é»˜è®¤åˆ†ç±»
    return 'å…¶ä»–'


def scan_all_tags():
    """æ‰«ææ‰€æœ‰åŸŸçš„æ ‡ç­¾ç›®å½•"""
    print("\n" + "=" * 80)
    print("ğŸ·ï¸  æ‰«æå…¨ç«™æ ‡ç­¾æ•°æ®...")
    print("=" * 80)

    base_path = Path(__file__).parent.parent

    # æ‰€æœ‰éœ€è¦æ‰«æçš„tagsç›®å½•
    tags_dirs = [
        base_path / 'tags',
        base_path / 'ai' / 'tags',
        base_path / 'ai001' / 'tags',
        base_path / 'ai002' / 'tags',
        base_path / 'geek' / 'tags',
        base_path / 'geek001' / 'tags',
        base_path / 'geek002' / 'tags',
        base_path / 'stock' / 'tags',
        base_path / 'stock001' / 'tags',
        base_path / 'stock002' / 'tags',
        base_path / 'gpt' / 'tags',
        base_path / 'go' / 'tags',
        base_path / 'ecg' / 'tags',
    ]

    all_tags = {}  # {tag_name: {count, urls, domain, articles}}
    domain_stats = defaultdict(int)
    tag_articles = defaultdict(list)  # ç”¨äºè®¡ç®—æ ‡ç­¾å…±ç°

    for tags_dir in tags_dirs:
        if not tags_dir.exists():
            continue

        domain = tags_dir.parent.name if tags_dir.parent.name != base_path.name else 'root'
        print(f"\nğŸ“‚ æ‰«æåŸŸ: {domain}")
        print("-" * 80)

        # éå†æ ‡ç­¾ç›®å½•
        for tag_dir in sorted(tags_dir.iterdir()):
            if not tag_dir.is_dir() or tag_dir.name in ['page', '.']:
                continue

            tag_name = tag_dir.name

            # ç»Ÿè®¡æ–‡ç« æ•°
            article_count = 0
            article_paths = []

            # 1. æ ¹ç›®å½•ä¸‹çš„index.html
            if (tag_dir / 'index.html').exists():
                article_count += 1
                article_paths.append(str(tag_dir / 'index.html'))

            # 2. å­ç›®å½•ä¸­çš„æ–‡ç« 
            for item in tag_dir.iterdir():
                if item.is_dir() and item.name != 'page':
                    if (item / 'index.html').exists():
                        article_count += 1
                        article_paths.append(str(item / 'index.html'))

            if article_count > 0:
                if tag_name not in all_tags:
                    all_tags[tag_name] = {
                        'name': tag_name,
                        'count': 0,
                        'domains': set(),
                        'urls': set(),
                        'articles': []
                    }

                all_tags[tag_name]['count'] += article_count
                all_tags[tag_name]['domains'].add(domain)
                all_tags[tag_name]['urls'].add(f'/tags/{tag_name}/')
                all_tags[tag_name]['articles'].extend(article_paths)

                domain_stats[domain] += 1

                # è®°å½•æ ‡ç­¾çš„æ–‡ç« ç”¨äºè®¡ç®—å…±ç°
                tag_articles[tag_name].extend(article_paths)

                print(f"  âœ… {tag_name:40s}: {article_count:4d} ç¯‡")

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    tags_list = []
    for tag_name, data in all_tags.items():
        tags_list.append({
            'name': tag_name,
            'count': data['count'],
            'url': list(data['urls'])[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªURL
            'domains': list(data['domains']),
            'category': classify_tag(tag_name),
            'articles': data['articles'][:10]  # åªä¿ç•™å‰10ç¯‡ç”¨äºå±•ç¤º
        })

    # æŒ‰æ–‡ç« æ•°é‡æ’åº
    tags_list.sort(key=lambda x: x['count'], reverse=True)

    print("\n" + "=" * 80)
    print(f"ğŸ“Š æ‰«æå®Œæˆç»Ÿè®¡")
    print("=" * 80)
    print(f"æ€»æ ‡ç­¾æ•°: {len(tags_list)}")
    print(f"æ€»æ–‡ç« æ•°: {sum(t['count'] for t in tags_list)}")
    print("\nå„åŸŸæ ‡ç­¾æ•°:")
    for domain, count in sorted(domain_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {domain:15s}: {count:4d} ä¸ªæ ‡ç­¾")

    return tags_list, tag_articles


def calculate_tag_relations(tags_list, tag_articles, max_relations=10):
    """è®¡ç®—æ ‡ç­¾å…³ç³»ï¼ˆåŸºäºå…±ç°é¢‘ç‡ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ”— è®¡ç®—æ ‡ç­¾å…³ç³»...")
    print("=" * 80)

    # æ„å»ºæ–‡ç« åˆ°æ ‡ç­¾çš„æ˜ å°„
    article_to_tags = defaultdict(set)
    for tag_data in tags_list:
        tag_name = tag_data['name']
        for article in tag_data.get('articles', []):
            article_to_tags[article].add(tag_name)

    # è®¡ç®—æ ‡ç­¾å…±ç°é¢‘ç‡
    tag_cooccurrence = defaultdict(lambda: defaultdict(int))

    for article, tags in article_to_tags.items():
        tags_list_local = list(tags)
        for i, tag1 in enumerate(tags_list_local):
            for tag2 in tags_list_local[i+1:]:
                tag_cooccurrence[tag1][tag2] += 1
                tag_cooccurrence[tag2][tag1] += 1

    # ç”Ÿæˆå…³ç³»æ•°æ®
    relations = {}
    for tag_data in tags_list:
        tag_name = tag_data['name']

        if tag_name in tag_cooccurrence:
            # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†ï¼ˆå…±ç°æ¬¡æ•° / æ€»æ–‡ç« æ•°ï¼‰
            related = []
            for related_tag, cooccur_count in tag_cooccurrence[tag_name].items():
                score = cooccur_count / max(tag_data['count'], 1)
                related.append({
                    'tag': related_tag,
                    'score': round(score, 3),
                    'cooccurrence': cooccur_count
                })

            # æŒ‰å¾—åˆ†æ’åºï¼Œå–å‰Nä¸ª
            related.sort(key=lambda x: x['score'], reverse=True)
            relations[tag_name] = related[:max_relations]

    print(f"âœ… è®¡ç®—äº† {len(relations)} ä¸ªæ ‡ç­¾çš„å…³è”å…³ç³»")

    return relations


def categorize_tags(tags_list):
    """å°†æ ‡ç­¾æŒ‰åˆ†ç±»ç»„ç»‡"""
    print("\n" + "=" * 80)
    print("ğŸ“ ç»„ç»‡æ ‡ç­¾åˆ†ç±»...")
    print("=" * 80)

    categorized = defaultdict(list)
    category_stats = defaultdict(int)

    for tag in tags_list:
        category = tag['category']
        categorized[category].append(tag)
        category_stats[category] += 1

    # æ¯ä¸ªåˆ†ç±»æŒ‰æ–‡ç« æ•°æ’åº
    for category in categorized:
        categorized[category].sort(key=lambda x: x['count'], reverse=True)

    print("\nåˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
        icon = TAG_CATEGORIES[category]['icon']
        print(f"  {icon} {category:12s}: {count:4d} ä¸ªæ ‡ç­¾")

    return dict(categorized), category_stats


def generate_enhanced_json(tags_list, relations, categorized, category_stats):
    """ç”Ÿæˆå¢å¼ºç‰ˆJSONæ•°æ®æ–‡ä»¶"""
    print("\n" + "=" * 80)
    print("ğŸ“ ç”Ÿæˆå¢å¼ºç‰ˆæ•°æ®æ–‡ä»¶...")
    print("=" * 80)

    base_path = Path(__file__).parent.parent

    # 1. ä¸»æ•°æ®æ–‡ä»¶ - site-tags-enhanced.json
    main_data = {
        'generated_at': datetime.now().isoformat(),
        'version': '2.0',
        'total_tags': len(tags_list),
        'total_articles': sum(t['count'] for t in tags_list),
        'categories': {
            name: {
                'icon': config['icon'],
                'color': config['color'],
                'description': config['description'],
                'count': category_stats.get(name, 0)
            }
            for name, config in TAG_CATEGORIES.items()
        },
        'tags': [
            {
                'name': t['name'],
                'count': t['count'],
                'url': t['url'],
                'category': t['category'],
                'domains': t.get('domains', [])
            }
            for t in tags_list
        ]
    }

    with open(base_path / 'site-tags-enhanced.json', 'w', encoding='utf-8') as f:
        json.dump(main_data, f, ensure_ascii=False, indent=2)
    print("âœ… site-tags-enhanced.json (ä¸»æ•°æ®)")

    # 2. åˆ†ç±»æ•°æ® - tag-categories.json
    category_data = {}
    for category_name, tags in categorized.items():
        category_data[category_name] = {
            'icon': TAG_CATEGORIES[category_name]['icon'],
            'color': TAG_CATEGORIES[category_name]['color'],
            'description': TAG_CATEGORIES[category_name]['description'],
            'count': len(tags),
            'top_tags': [
                {'name': t['name'], 'count': t['count'], 'url': t['url']}
                for t in tags[:20]  # å‰20ä¸ª
            ]
        }

    with open(base_path / 'tag-categories.json', 'w', encoding='utf-8') as f:
        json.dump(category_data, f, ensure_ascii=False, indent=2)
    print("âœ… tag-categories.json (åˆ†ç±»æ•°æ®)")

    # 3. å…³ç³»æ•°æ® - tag-relations.json
    with open(base_path / 'tag-relations.json', 'w', encoding='utf-8') as f:
        json.dump(relations, f, ensure_ascii=False, indent=2)
    print("âœ… tag-relations.json (å…³ç³»æ•°æ®)")

    # 4. çƒ­é—¨æ ‡ç­¾ - tag-hot.json
    hot_tags = sorted(tags_list, key=lambda x: x['count'], reverse=True)[:100]
    with open(base_path / 'tag-hot.json', 'w', encoding='utf-8') as f:
        json.dump({
            'generated_at': datetime.now().isoformat(),
            'tags': [
                {'name': t['name'], 'count': t['count'], 'url': t['url'], 'category': t['category']}
                for t in hot_tags
            ]
        }, f, ensure_ascii=False, indent=2)
    print("âœ… tag-hot.json (çƒ­é—¨æ ‡ç­¾)")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“ˆ æ•°æ®ç»Ÿè®¡")
    print("=" * 80)
    print(f"æ€»æ ‡ç­¾æ•°: {len(tags_list)}")
    print(f"æ€»æ–‡ç« æ•°: {sum(t['count'] for t in tags_list)}")
    print(f"åˆ†ç±»æ•°: {len(categorized)}")
    print(f"å…³è”å…³ç³»: {len(relations)}")

    print("\nğŸ† TOP 20 çƒ­é—¨æ ‡ç­¾:")
    print("-" * 80)
    for i, tag in enumerate(tags_list[:20], 1):
        category_icon = TAG_CATEGORIES[tag['category']]['icon']
        print(f"{i:2d}. {category_icon} {tag['name']:40s}: {tag['count']:5d} ç¯‡")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("ğŸ·ï¸  çŸ¥è¯†é“º - å¢å¼ºç‰ˆæ ‡ç­¾æ•°æ®ç”Ÿæˆå™¨ v2.0")
    print("=" * 80)

    # 1. æ‰«ææ‰€æœ‰æ ‡ç­¾
    tags_list, tag_articles = scan_all_tags()

    if not tags_list:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾")
        return

    # 2. è®¡ç®—æ ‡ç­¾å…³ç³»
    relations = calculate_tag_relations(tags_list, tag_articles)

    # 3. åˆ†ç±»æ ‡ç­¾
    categorized, category_stats = categorize_tags(tags_list)

    # 4. ç”ŸæˆJSONæ–‡ä»¶
    generate_enhanced_json(tags_list, relations, categorized, category_stats)

    print("\n" + "=" * 80)
    print("âœ… å¢å¼ºç‰ˆæ ‡ç­¾æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - site-tags-enhanced.json (ä¸»æ•°æ®æ–‡ä»¶)")
    print("  - tag-categories.json (åˆ†ç±»æ•°æ®)")
    print("  - tag-relations.json (å…³ç³»å›¾è°±)")
    print("  - tag-hot.json (çƒ­é—¨æ ‡ç­¾)")
    print("=" * 80 + "\n")


if __name__ == '__main__':
    main()
